resources:
  tpu_type: v5p-8
  slice_count: 1

train_config:
  data:
    train_urls:
      - "gs://data-values-us-central-1/fineweb_edu_10bt_shuffled/fineweb_edu_10bt.chunk.00.jsonl"
    validation_urls:
      - "gs://data-values-us-central-1/fineweb_edu_10bt_shuffled/fineweb_edu_10bt.val.jsonl"
    cache_dir: "gs://data-values-us-central-1/fineweb_edu_10bt_shuffled/cache"
    #id: dlwh/wikitext_103_detokenized
    #id: Tristan/RedPajama-Data-V2-sample-100B-filtered-shuffled-tokenized-with-token-counts
  model:
    type: gpt2
    hidden_dim: 768
    num_heads: 12
    num_layers: 12
    seq_len: 128
    gradient_checkpointing: true
    layer_norm_epsilon: 1e-2
    qk_norm: true
  trainer:
    mp: p=f32,c=f32
    model_axis_size: 1
    fsdp_axis: "embed"
    # Within each slice: all 8 devices go to FSDP
    replica_ici_axis_size: 1
    # Across slices: 8-way DP
    replica_dcn_axis_size: 1
    per_device_parallelism: 64
    per_device_eval_parallelism: 64

    profiler_tpu_trace_mode: "TRACE_COMPUTE_AND_SYNC"
    profiler: false
    profiler_start_step: 2
    profiler_num_steps: 2
    backward_profiler: false
    backward_profiler_start_step: 4
    backward_profiler_num_steps: 2
    log_dir: "jax_profile_traces"

    train_batch_size: 2048
    num_train_steps: 5
    max_eval_batches: 1

    ray:
      auto_start_cluster: false

    tracker:
      - type: wandb
        project: "levanter"
        name: "tpu_test_s128"

    checkpointer:
      keep:
        - every: 1
      save_interval: 5m
      base_path: "gs://data-values-us-central-1/checkpoints/test_resume/"
      append_run_id_to_base_path: true


    load_debug_weights: false

    id: hello_v4
    #load_checkpoint_path: "/scr-ssd/sampark/levanter/checkpoints/gpt2_1k_yolo_ln_before"

    metagrad_checkpoint_frequency: 20

    # Enable logging of gradients, parameters, and Adam optimizer state (mu and nu)
    watch:
      watch_targets: ["grads", "params", "adam_mu", "adam_nu"]
      include_norms: true
      include_per_parameter_norms: true
      interval: 10

    jax_compilation_cache_dir: "jax_compilation_cache"

  out_dir: out_dir_test
  optimizer:
    lr_schedule: linear
    schedule_steps: 10000
    learning_rate: 1E-4
    weight_decay: 0.1
    warmup: 0.1