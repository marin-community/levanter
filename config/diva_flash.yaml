data:
  cache_dir: "gs://diva-flash/processed/llama"
  tokenizer: "meta-llama/Llama-3.2-1B-Instruct"
  processor: "openai/whisper-large-v3"
  configs:
    cv:
      id: mozilla-foundation/common_voice_17_0
      cache_dir: "gs://diva-flash/processed/llama/cv"
      name: "en"
      text_key: "sentence"
      train_split: "train"
      validation_split: "validation"
  train_weights:
    cv: 1.0
model:
  type: diva
  reference_encoder: "openai/whisper-large-v3"
  reference_decoder: "meta-llama/Llama-3.2-1B-Instruct"
use_hf_model_config: true
trainer:
  steps_per_eval: 500
  mp: p=f32,c=bf16
  model_axis_size: 1
  per_device_parallelism: -1
  train_batch_size: 512
  num_train_steps: 4300
  checkpointer:
    base_path: gs://diva-flash/cv-checkpoints
    save_interval: 60m
optimizer:
  #learning_rate: 5E-5
  learning_rate: 5e-4
  weight_decay: 0.1
  warmup: 0.01
hf_save_path: gs://diva-flash/librispeech-hf-checkpoints
diva_training: true
