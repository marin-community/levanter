module @jit__train_step attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {
  func.func public @main(%arg0: tensor<i32> {tf.aliasing_output = 1 : i32}, %arg1: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 2 : i32}, %arg2: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 3 : i32}, %arg3: tensor<2x32x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 4 : i32}, %arg4: tensor<2x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 5 : i32}, %arg5: tensor<2x4x8x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 6 : i32}, %arg6: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 7 : i32}, %arg7: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 8 : i32}, %arg8: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 9 : i32}, %arg9: tensor<2x32x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 10 : i32}, %arg10: tensor<2x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 11 : i32}, %arg11: tensor<2x128x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 12 : i32}, %arg12: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 13 : i32}, %arg13: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 14 : i32}, %arg14: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 15 : i32}, %arg15: tensor<50257x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 16 : i32}, %arg16: tensor<1024x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 17 : i32}, %arg17: tensor<i32> {tf.aliasing_output = 18 : i32}, %arg18: tensor<i32> {tf.aliasing_output = 20 : i32}, %arg19: tensor<i32> {tf.aliasing_output = 21 : i32}, %arg20: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 22 : i32}, %arg21: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 23 : i32}, %arg22: tensor<2x32x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 24 : i32}, %arg23: tensor<2x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 25 : i32}, %arg24: tensor<2x4x8x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 26 : i32}, %arg25: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 27 : i32}, %arg26: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 28 : i32}, %arg27: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 29 : i32}, %arg28: tensor<2x32x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 30 : i32}, %arg29: tensor<2x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 31 : i32}, %arg30: tensor<2x128x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 32 : i32}, %arg31: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 33 : i32}, %arg32: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 34 : i32}, %arg33: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 35 : i32}, %arg34: tensor<50257x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 36 : i32}, %arg35: tensor<1024x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 37 : i32}, %arg36: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 38 : i32}, %arg37: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 39 : i32}, %arg38: tensor<2x32x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 40 : i32}, %arg39: tensor<2x3x4x8xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 41 : i32}, %arg40: tensor<2x4x8x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 42 : i32}, %arg41: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 43 : i32}, %arg42: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 44 : i32}, %arg43: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 45 : i32}, %arg44: tensor<2x32x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 46 : i32}, %arg45: tensor<2x128xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 47 : i32}, %arg46: tensor<2x128x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 48 : i32}, %arg47: tensor<2x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 49 : i32}, %arg48: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 50 : i32}, %arg49: tensor<32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 51 : i32}, %arg50: tensor<50257x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 52 : i32}, %arg51: tensor<1024x32xf32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 53 : i32}, %arg52: tensor<2xui32> {mhlo.sharding = "{replicated}", tf.aliasing_output = 54 : i32}, %arg53: tensor<32x1024xi32> {mhlo.sharding = "{replicated}"}, %arg54: tensor<32x1024xi32> {mhlo.sharding = "{replicated}"}, %arg55: tensor<32x1024xi32> {mhlo.sharding = "{replicated}"}) -> (tensor<f32> {jax.result_info = "result[0][0]"}, tensor<i32> {jax.result_info = "result[0][1].step"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.ln_1.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.ln_1.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x3x4x8xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.attn.c_attn.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x3x4x8xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.attn.c_attn.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x4x8x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.attn.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.attn.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.ln_2.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.ln_2.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x128xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.mlp.c_fc.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x128xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.mlp.c_fc.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x128x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.mlp.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].model.transformer.blocks.stacked.mlp.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].model.transformer.ln_f.weight[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].model.transformer.ln_f.bias[0]", mhlo.sharding = "{replicated}"}, tensor<50257x32xf32> {jax.result_info = "result[0][1].model.embeddings.token_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<1024x32xf32> {jax.result_info = "result[0][1].model.embeddings.position_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<i32> {jax.result_info = "result[0][1].opt_state.count"}, tensor<f32> {jax.result_info = "result[0][1].opt_state.hyperparams['learning_rate']"}, tensor<i32> {jax.result_info = "result[0][1].opt_state.hyperparams_states['learning_rate'].count"}, tensor<i32> {jax.result_info = "result[0][1].opt_state.inner_state[1].count"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.ln_1.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.ln_1.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x3x4x8xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.attn.c_attn.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x3x4x8xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.attn.c_attn.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x4x8x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.attn.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.attn.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.ln_2.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.ln_2.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x128xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.mlp.c_fc.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x128xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.mlp.c_fc.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x128x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.mlp.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.blocks.stacked.mlp.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.ln_f.weight[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.transformer.ln_f.bias[0]", mhlo.sharding = "{replicated}"}, tensor<50257x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.embeddings.token_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<1024x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].mu.embeddings.position_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.ln_1.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.ln_1.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x3x4x8xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.attn.c_attn.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x3x4x8xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.attn.c_attn.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x4x8x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.attn.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.attn.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.ln_2.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.ln_2.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x32x128xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.mlp.c_fc.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x128xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.mlp.c_fc.bias[0]", mhlo.sharding = "{replicated}"}, tensor<2x128x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.mlp.c_proj.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.blocks.stacked.mlp.c_proj.bias[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.ln_f.weight[0]", mhlo.sharding = "{replicated}"}, tensor<32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.transformer.ln_f.bias[0]", mhlo.sharding = "{replicated}"}, tensor<50257x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.embeddings.token_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<1024x32xf32> {jax.result_info = "result[0][1].opt_state.inner_state[1].nu.embeddings.position_embeddings.weight[0]", mhlo.sharding = "{replicated}"}, tensor<2xui32> {jax.result_info = "result[0][1].training_key", mhlo.sharding = "{replicated}"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/embeddings.position_embeddings.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/embeddings.token_embeddings.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/total']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.attn.c_attn.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.attn.c_attn.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.attn.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.attn.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.ln_1.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.ln_1.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.ln_2.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.ln_2.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.mlp.c_fc.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.mlp.c_fc.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.mlp.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.0.mlp.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.attn.c_attn.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.attn.c_attn.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.attn.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.attn.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.ln_1.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.ln_1.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.ln_2.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.ln_2.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.mlp.c_fc.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.mlp.c_fc.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.mlp.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.blocks.1.mlp.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.ln_f.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['grad/norm/transformer.ln_f.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/embeddings.position_embeddings.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/embeddings.token_embeddings.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/total']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.attn.c_attn.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.attn.c_attn.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.attn.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.attn.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.ln_1.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.ln_1.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.ln_2.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.ln_2.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.mlp.c_fc.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.mlp.c_fc.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.mlp.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.0.mlp.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.attn.c_attn.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.attn.c_attn.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.attn.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.attn.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.ln_1.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.ln_1.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.ln_2.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.ln_2.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.mlp.c_fc.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.mlp.c_fc.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.mlp.c_proj.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.blocks.1.mlp.c_proj.weight']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.ln_f.bias']"}, tensor<f32> {jax.result_info = "result[0][2][0]['params/norm/transformer.ln_f.weight']"}) {
    %0 = call @_threefry_split(%arg52) : (tensor<2xui32>) -> tensor<2x2xui32>
    %1 = stablehlo.slice %0 [0:1, 0:2] : (tensor<2x2xui32>) -> tensor<1x2xui32>
    %2 = stablehlo.reshape %1 : (tensor<1x2xui32>) -> tensor<2xui32>
    %3 = call @_threefry_split(%2) : (tensor<2xui32>) -> tensor<2x2xui32>
    %4 = stablehlo.slice %3 [1:2, 0:2] : (tensor<2x2xui32>) -> tensor<1x2xui32>
    %5 = stablehlo.reshape %4 : (tensor<1x2xui32>) -> tensor<2xui32>
    %6:2 = call @_take(%arg15, %arg53) : (tensor<50257x32xf32>, tensor<32x1024xi32>) -> (tensor<32x1024x32xf32>, tensor<32x1024x1xi32>)
    %7 = stablehlo.iota dim = 0 : tensor<1024xi32>
    %c = stablehlo.constant dense<1> : tensor<i32>
    %8 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i32>) -> tensor<1024xi32>
    %9 = stablehlo.multiply %7, %8 : tensor<1024xi32>
    %c_0 = stablehlo.constant dense<0> : tensor<i32>
    %10 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<i32>) -> tensor<1024xi32>
    %11 = stablehlo.add %9, %10 : tensor<1024xi32>
    %12:2 = call @_take_0(%arg16, %11) : (tensor<1024x32xf32>, tensor<1024xi32>) -> (tensor<1024x32xf32>, tensor<1024x1xi32>)
    %13 = stablehlo.broadcast_in_dim %12#0, dims = [1, 2] : (tensor<1024x32xf32>) -> tensor<32x1024x32xf32>
    %14 = stablehlo.add %6#0, %13 : tensor<32x1024x32xf32>
    %15 = call @_threefry_split(%5) : (tensor<2xui32>) -> tensor<2x2xui32>
    %c_1 = stablehlo.constant dense<0> : tensor<i32>
    %16:3 = call @_var(%c_1) : (tensor<i32>) -> (tensor<f32>, tensor<i1>, tensor<32x1024xf32>)
    %17 = call @_take_3(%c_1) : (tensor<i32>) -> tensor<1xi32>
    %c_2 = stablehlo.constant dense<1> : tensor<i32>
    %18 = call @_take_3(%c_2) : (tensor<i32>) -> tensor<1xi32>
    %c_3 = stablehlo.constant dense<2> : tensor<i32>
    %19 = call @_take_3(%c_3) : (tensor<i32>) -> tensor<1xi32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %20 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %21 = stablehlo.custom_call @Sharding(%20) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %22 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
    %23 = stablehlo.custom_call @Sharding(%22) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024xf32>) -> tensor<32x4x1024xf32>
    %24:3 = call @_var(%c_1) : (tensor<i32>) -> (tensor<f32>, tensor<i1>, tensor<32x1024xf32>)
    %cst_4 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %25 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<2x32x1024x32xf32>
    %c_5 = stablehlo.constant dense<0> : tensor<i32>
    %26:27 = stablehlo.while(%iterArg = %arg1, %iterArg_71 = %arg2, %iterArg_72 = %arg3, %iterArg_73 = %arg4, %iterArg_74 = %arg5, %iterArg_75 = %arg6, %iterArg_76 = %arg7, %iterArg_77 = %arg8, %iterArg_78 = %arg9, %iterArg_79 = %arg10, %iterArg_80 = %arg11, %iterArg_81 = %arg12, %iterArg_82 = %16#0, %iterArg_83 = %16#1, %iterArg_84 = %16#2, %iterArg_85 = %17, %iterArg_86 = %18, %iterArg_87 = %19, %iterArg_88 = %arg55, %iterArg_89 = %21, %iterArg_90 = %23, %iterArg_91 = %24#0, %iterArg_92 = %24#1, %iterArg_93 = %24#2, %iterArg_94 = %c_5, %iterArg_95 = %14, %iterArg_96 = %25) : tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<32x1024xi32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<i32>, tensor<32x1024x32xf32>, tensor<2x32x1024x32xf32>
     cond {
      %c_97 = stablehlo.constant dense<2> : tensor<i32>
      %766 = stablehlo.compare  LT, %iterArg_94, %c_97,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      stablehlo.return %766 : tensor<i1>
    } do {
      %c_97 = stablehlo.constant dense<0> : tensor<i32>
      %766 = stablehlo.dynamic_slice %iterArg, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %767 = stablehlo.reshape %766 : (tensor<1x32xf32>) -> tensor<32xf32>
      %768 = stablehlo.dynamic_slice %iterArg_71, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %769 = stablehlo.reshape %768 : (tensor<1x32xf32>) -> tensor<32xf32>
      %770 = stablehlo.dynamic_slice %iterArg_72, %iterArg_94, %c_97, %c_97, %c_97, %c_97, sizes = [1, 32, 3, 4, 8] : (tensor<2x32x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x32x3x4x8xf32>
      %771 = stablehlo.reshape %770 : (tensor<1x32x3x4x8xf32>) -> tensor<32x3x4x8xf32>
      %772 = stablehlo.dynamic_slice %iterArg_73, %iterArg_94, %c_97, %c_97, %c_97, sizes = [1, 3, 4, 8] : (tensor<2x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x3x4x8xf32>
      %773 = stablehlo.reshape %772 : (tensor<1x3x4x8xf32>) -> tensor<3x4x8xf32>
      %774 = stablehlo.dynamic_slice %iterArg_74, %iterArg_94, %c_97, %c_97, %c_97, sizes = [1, 4, 8, 32] : (tensor<2x4x8x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x4x8x32xf32>
      %775 = stablehlo.reshape %774 : (tensor<1x4x8x32xf32>) -> tensor<4x8x32xf32>
      %776 = stablehlo.dynamic_slice %iterArg_75, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %777 = stablehlo.reshape %776 : (tensor<1x32xf32>) -> tensor<32xf32>
      %778 = stablehlo.dynamic_slice %iterArg_76, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %779 = stablehlo.reshape %778 : (tensor<1x32xf32>) -> tensor<32xf32>
      %780 = stablehlo.dynamic_slice %iterArg_77, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %781 = stablehlo.reshape %780 : (tensor<1x32xf32>) -> tensor<32xf32>
      %782 = stablehlo.dynamic_slice %iterArg_78, %iterArg_94, %c_97, %c_97, sizes = [1, 32, 128] : (tensor<2x32x128xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x32x128xf32>
      %783 = stablehlo.reshape %782 : (tensor<1x32x128xf32>) -> tensor<32x128xf32>
      %784 = stablehlo.dynamic_slice %iterArg_79, %iterArg_94, %c_97, sizes = [1, 128] : (tensor<2x128xf32>, tensor<i32>, tensor<i32>) -> tensor<1x128xf32>
      %785 = stablehlo.reshape %784 : (tensor<1x128xf32>) -> tensor<128xf32>
      %786 = stablehlo.dynamic_slice %iterArg_80, %iterArg_94, %c_97, %c_97, sizes = [1, 128, 32] : (tensor<2x128x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x128x32xf32>
      %787 = stablehlo.reshape %786 : (tensor<1x128x32xf32>) -> tensor<128x32xf32>
      %788 = stablehlo.dynamic_slice %iterArg_81, %iterArg_94, %c_97, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %789 = stablehlo.reshape %788 : (tensor<1x32xf32>) -> tensor<32xf32>
      %790:2 = func.call @None(%iterArg_82, %iterArg_83, %iterArg_84, %iterArg_85, %iterArg_86, %iterArg_87, %iterArg_88, %iterArg_89, %iterArg_90, %iterArg_91, %iterArg_92, %iterArg_93, %iterArg_95, %767, %769, %771, %773, %775, %777, %779, %781, %783, %785, %787, %789) : (tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<32x1024xi32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x3x4x8xf32>, tensor<3x4x8xf32>, tensor<4x8x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x128xf32>, tensor<128xf32>, tensor<128x32xf32>, tensor<32xf32>) -> (tensor<32x1024x32xf32>, tensor<32x1024x32xf32>)
      %791 = stablehlo.broadcast_in_dim %790#1, dims = [1, 2, 3] : (tensor<32x1024x32xf32>) -> tensor<1x32x1024x32xf32>
      %792 = stablehlo.dynamic_update_slice %iterArg_96, %791, %iterArg_94, %c_97, %c_97, %c_97 : (tensor<2x32x1024x32xf32>, tensor<1x32x1024x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x32x1024x32xf32>
      %c_98 = stablehlo.constant dense<1> : tensor<i32>
      %793 = stablehlo.add %iterArg_94, %c_98 : tensor<i32>
      stablehlo.return %iterArg, %iterArg_71, %iterArg_72, %iterArg_73, %iterArg_74, %iterArg_75, %iterArg_76, %iterArg_77, %iterArg_78, %iterArg_79, %iterArg_80, %iterArg_81, %iterArg_82, %iterArg_83, %iterArg_84, %iterArg_85, %iterArg_86, %iterArg_87, %iterArg_88, %iterArg_89, %iterArg_90, %iterArg_91, %iterArg_92, %iterArg_93, %793, %790#0, %792 : tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<32x1024xi32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>, tensor<i32>, tensor<32x1024x32xf32>, tensor<2x32x1024x32xf32>
    }
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %27 = stablehlo.reduce(%26#25 init: %cst_6) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %cst_7 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %28 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %29 = stablehlo.divide %27, %28 : tensor<32x1024xf32>
    %30:4 = call @_var_9(%26#25, %c_1) : (tensor<32x1024x32xf32>, tensor<i32>) -> (tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>)
    %cst_8 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %31 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %32 = stablehlo.add %30#0, %31 : tensor<32x1024xf32>
    %33 = stablehlo.rsqrt %32 : tensor<32x1024xf32>
    %34 = stablehlo.divide %33, %32 : tensor<32x1024xf32>
    %cst_9 = stablehlo.constant dense<-5.000000e-01> : tensor<f32>
    %35 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %36 = stablehlo.multiply %35, %34 : tensor<32x1024xf32>
    %37 = stablehlo.broadcast_in_dim %29, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %38 = stablehlo.transpose %37, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %39 = stablehlo.subtract %26#25, %38 : tensor<32x1024x32xf32>
    %40 = stablehlo.broadcast_in_dim %33, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %41 = stablehlo.transpose %40, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %42 = stablehlo.multiply %39, %41 : tensor<32x1024x32xf32>
    %43 = stablehlo.broadcast_in_dim %arg13, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %44 = stablehlo.multiply %43, %42 : tensor<32x1024x32xf32>
    %45 = stablehlo.broadcast_in_dim %arg14, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %46 = stablehlo.add %44, %45 : tensor<32x1024x32xf32>
    %47 = stablehlo.dot_general %46, %arg15, contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<50257x32xf32>) -> tensor<32x1024x50257xf32>
    %48 = stablehlo.custom_call @Sharding(%47) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x50257xf32>) -> tensor<32x1024x50257xf32>
    %49 = call @_roll_static(%arg53) : (tensor<32x1024xi32>) -> tensor<32x1024xi32>
    %50 = call @_one_hot(%49) : (tensor<32x1024xi32>) -> tensor<32x1024x50257xf32>
    %51 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %c_10 = stablehlo.constant dense<-1> : tensor<i32>
    %c_11 = stablehlo.constant dense<1024> : tensor<i32>
    %52 = stablehlo.add %c_10, %c_11 : tensor<i32>
    %53 = stablehlo.convert %52 : tensor<i32>
    %54 = stablehlo.broadcast_in_dim %53, dims = [] : (tensor<i32>) -> tensor<1xi32>
    %cst_12 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %55 = "stablehlo.scatter"(%51, %54, %cst_12) <{indices_are_sorted = true, scatter_dimension_numbers = #stablehlo.scatter<inserted_window_dims = [0], scatter_dims_to_operand_dims = [0]>, unique_indices = true}> ({
    ^bb0(%arg56: tensor<f32>, %arg57: tensor<f32>):
      stablehlo.return %arg57 : tensor<f32>
    }) : (tensor<1024xf32>, tensor<1xi32>, tensor<f32>) -> tensor<1024xf32>
    %56 = stablehlo.custom_call @Sharding(%55) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<1024xf32>) -> tensor<1024xf32>
    %57 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024xf32>
    %58 = stablehlo.subtract %57, %56 : tensor<1024xf32>
    %59 = stablehlo.broadcast_in_dim %58, dims = [1] : (tensor<1024xf32>) -> tensor<32x1024xf32>
    %60 = stablehlo.convert %arg54 : (tensor<32x1024xi32>) -> tensor<32x1024xf32>
    %61 = stablehlo.multiply %60, %59 : tensor<32x1024xf32>
    %cst_13 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %62 = stablehlo.reduce(%48 init: %cst_13) applies stablehlo.maximum across dimensions = [2] : (tensor<32x1024x50257xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %cst_14 = stablehlo.constant dense<0xFF800000> : tensor<f32>
    %63 = stablehlo.broadcast_in_dim %cst_14, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %64 = stablehlo.maximum %63, %62 : tensor<32x1024xf32>
    %65 = stablehlo.is_finite %64 : (tensor<32x1024xf32>) -> tensor<32x1024xi1>
    %66 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %67 = stablehlo.select %65, %64, %66 : tensor<32x1024xi1>, tensor<32x1024xf32>
    %68 = stablehlo.broadcast_in_dim %67, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %69 = stablehlo.broadcast_in_dim %68, dims = [0, 1, 2] : (tensor<32x1024x1xf32>) -> tensor<32x1024x50257xf32>
    %70 = stablehlo.subtract %48, %69 : tensor<32x1024x50257xf32>
    %71 = stablehlo.exponential %70 : tensor<32x1024x50257xf32>
    %cst_15 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %72 = stablehlo.reduce(%71 init: %cst_15) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x50257xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %73 = stablehlo.abs %72 : tensor<32x1024xf32>
    %74 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<f32>
    %75 = stablehlo.broadcast_in_dim %74, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %76 = stablehlo.compare  GE, %72, %75,  FLOAT : (tensor<32x1024xf32>, tensor<32x1024xf32>) -> tensor<32x1024xi1>
    %77 = stablehlo.log %73 : tensor<32x1024xf32>
    %78 = stablehlo.add %77, %67 : tensor<32x1024xf32>
    %79 = stablehlo.broadcast_in_dim %78, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<50257x32x1024xf32>
    %80 = stablehlo.transpose %79, dims = [1, 2, 0] : (tensor<50257x32x1024xf32>) -> tensor<32x1024x50257xf32>
    %81 = stablehlo.subtract %80, %48 : tensor<32x1024x50257xf32>
    %82 = stablehlo.dot_general %50, %81, batching_dims = [0, 1] x [0, 1], contracting_dims = [2] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x50257xf32>, tensor<32x1024x50257xf32>) -> tensor<32x1024xf32>
    %83 = stablehlo.custom_call @Sharding(%82) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %cst_16 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %84 = stablehlo.broadcast_in_dim %cst_16, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %85 = stablehlo.compare  NE, %61, %84,  FLOAT : (tensor<32x1024xf32>, tensor<32x1024xf32>) -> tensor<32x1024xi1>
    %86 = stablehlo.convert %85 : tensor<32x1024xi1>
    %87 = stablehlo.convert %86 : (tensor<32x1024xi1>) -> tensor<32x1024xi32>
    %88 = stablehlo.convert %87 : (tensor<32x1024xi32>) -> tensor<32x1024xf32>
    %cst_17 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %89 = stablehlo.reduce(%88 init: %cst_17) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024xf32>, tensor<f32>) -> tensor<f32>
    %90 = call @_where_11(%86, %83, %cst) : (tensor<32x1024xi1>, tensor<32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %cst_18 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %91 = stablehlo.reduce(%90 init: %cst_18) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024xf32>, tensor<f32>) -> tensor<f32>
    %92 = stablehlo.divide %91, %89 : tensor<f32>
    %93 = stablehlo.add %92, %cst : tensor<f32>
    %94 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<f32>
    %95 = stablehlo.divide %94, %89 : tensor<f32>
    %96 = stablehlo.broadcast_in_dim %95, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %97 = call @_where_12(%86, %96) : (tensor<32x1024xi1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %98 = stablehlo.custom_call @Sharding(%97) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %99 = stablehlo.dot_general %98, %50, batching_dims = [0, 1] x [0, 1], contracting_dims = [] x [], precision = [DEFAULT, DEFAULT] : (tensor<32x1024xf32>, tensor<32x1024x50257xf32>) -> tensor<32x1024x50257xf32>
    %100 = stablehlo.negate %99 : tensor<32x1024x50257xf32>
    %101 = stablehlo.transpose %99, dims = [2, 0, 1] : (tensor<32x1024x50257xf32>) -> tensor<50257x32x1024xf32>
    %cst_19 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %102 = stablehlo.reduce(%101 init: %cst_19) applies stablehlo.add across dimensions = [0] : (tensor<50257x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %103 = stablehlo.divide %102, %73 : tensor<32x1024xf32>
    %104 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %105 = stablehlo.select %76, %104, %103 : tensor<32x1024xi1>, tensor<32x1024xf32>
    %106 = stablehlo.select %76, %103, %104 : tensor<32x1024xi1>, tensor<32x1024xf32>
    %107 = stablehlo.negate %105 : tensor<32x1024xf32>
    %108 = stablehlo.add %106, %107 : tensor<32x1024xf32>
    %109 = stablehlo.broadcast_in_dim %108, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x50257xf32>
    %110 = stablehlo.multiply %109, %71 : tensor<32x1024x50257xf32>
    %111 = stablehlo.add %100, %110 : tensor<32x1024x50257xf32>
    %112 = stablehlo.custom_call @Sharding(%111) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x50257xf32>) -> tensor<32x1024x50257xf32>
    %113 = stablehlo.dot_general %112, %46, contracting_dims = [0, 1] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x50257xf32>, tensor<32x1024x32xf32>) -> tensor<50257x32xf32>
    %114 = stablehlo.dot_general %112, %arg15, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x50257xf32>, tensor<50257x32xf32>) -> tensor<32x1024x32xf32>
    %cst_20 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %115 = stablehlo.reduce(%114 init: %cst_20) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %116 = stablehlo.multiply %43, %114 : tensor<32x1024x32xf32>
    %117 = stablehlo.multiply %114, %42 : tensor<32x1024x32xf32>
    %118 = stablehlo.multiply %39, %116 : tensor<32x1024x32xf32>
    %119 = stablehlo.multiply %116, %41 : tensor<32x1024x32xf32>
    %120 = stablehlo.transpose %118, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_21 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %121 = stablehlo.reduce(%120 init: %cst_21) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %122 = stablehlo.multiply %121, %36 : tensor<32x1024xf32>
    %123 = call @_var_13(%30#1, %30#2, %30#3, %122) : (tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %124 = stablehlo.negate %119 : tensor<32x1024x32xf32>
    %125 = stablehlo.add %123, %119 : tensor<32x1024x32xf32>
    %126 = stablehlo.transpose %124, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_22 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %127 = stablehlo.reduce(%126 init: %cst_22) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %128 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %129 = stablehlo.divide %127, %128 : tensor<32x1024xf32>
    %130 = stablehlo.broadcast_in_dim %129, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %131 = stablehlo.add %125, %130 : tensor<32x1024x32xf32>
    %cst_23 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %132 = stablehlo.broadcast_in_dim %cst_23, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %cst_24 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %133 = stablehlo.broadcast_in_dim %cst_24, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %cst_25 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %134 = stablehlo.broadcast_in_dim %cst_25, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %cst_26 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %135 = stablehlo.broadcast_in_dim %cst_26, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %cst_27 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %136 = stablehlo.broadcast_in_dim %cst_27, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %cst_28 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %137 = stablehlo.broadcast_in_dim %cst_28, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %cst_29 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %138 = stablehlo.broadcast_in_dim %cst_29, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %cst_30 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %139 = stablehlo.broadcast_in_dim %cst_30, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %cst_31 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %140 = stablehlo.broadcast_in_dim %cst_31, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %cst_32 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %141 = stablehlo.broadcast_in_dim %cst_32, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %cst_33 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %142 = stablehlo.broadcast_in_dim %cst_33, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %cst_34 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %143 = stablehlo.broadcast_in_dim %cst_34, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %c_35 = stablehlo.constant dense<0> : tensor<i32>
    %144:28 = stablehlo.while(%iterArg = %26#26, %iterArg_71 = %arg1, %iterArg_72 = %arg2, %iterArg_73 = %arg3, %iterArg_74 = %arg4, %iterArg_75 = %arg5, %iterArg_76 = %arg6, %iterArg_77 = %arg7, %iterArg_78 = %arg8, %iterArg_79 = %arg9, %iterArg_80 = %arg10, %iterArg_81 = %arg11, %iterArg_82 = %15, %iterArg_83 = %arg55, %iterArg_84 = %c_35, %iterArg_85 = %131, %iterArg_86 = %132, %iterArg_87 = %133, %iterArg_88 = %134, %iterArg_89 = %135, %iterArg_90 = %136, %iterArg_91 = %137, %iterArg_92 = %138, %iterArg_93 = %139, %iterArg_94 = %140, %iterArg_95 = %141, %iterArg_96 = %142, %iterArg_97 = %143) : tensor<2x32x1024x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x2xui32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x1024x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>
     cond {
      %c_98 = stablehlo.constant dense<2> : tensor<i32>
      %766 = stablehlo.compare  LT, %iterArg_84, %c_98,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      stablehlo.return %766 : tensor<i1>
    } do {
      %c_98 = stablehlo.constant dense<2> : tensor<i32>
      %766 = stablehlo.subtract %c_98, %iterArg_84 : tensor<i32>
      %c_99 = stablehlo.constant dense<1> : tensor<i32>
      %767 = stablehlo.subtract %766, %c_99 : tensor<i32>
      %c_100 = stablehlo.constant dense<0> : tensor<i32>
      %768 = stablehlo.dynamic_slice %iterArg, %767, %c_100, %c_100, %c_100, sizes = [1, 32, 1024, 32] : (tensor<2x32x1024x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x32x1024x32xf32>
      %769 = stablehlo.reshape %768 : (tensor<1x32x1024x32xf32>) -> tensor<32x1024x32xf32>
      %770 = stablehlo.dynamic_slice %iterArg_71, %767, %c_100, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %771 = stablehlo.reshape %770 : (tensor<1x32xf32>) -> tensor<32xf32>
      %772 = stablehlo.dynamic_slice %iterArg_72, %767, %c_100, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %773 = stablehlo.reshape %772 : (tensor<1x32xf32>) -> tensor<32xf32>
      %774 = stablehlo.dynamic_slice %iterArg_73, %767, %c_100, %c_100, %c_100, %c_100, sizes = [1, 32, 3, 4, 8] : (tensor<2x32x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x32x3x4x8xf32>
      %775 = stablehlo.reshape %774 : (tensor<1x32x3x4x8xf32>) -> tensor<32x3x4x8xf32>
      %776 = stablehlo.dynamic_slice %iterArg_74, %767, %c_100, %c_100, %c_100, sizes = [1, 3, 4, 8] : (tensor<2x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x3x4x8xf32>
      %777 = stablehlo.reshape %776 : (tensor<1x3x4x8xf32>) -> tensor<3x4x8xf32>
      %778 = stablehlo.dynamic_slice %iterArg_75, %767, %c_100, %c_100, %c_100, sizes = [1, 4, 8, 32] : (tensor<2x4x8x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x4x8x32xf32>
      %779 = stablehlo.reshape %778 : (tensor<1x4x8x32xf32>) -> tensor<4x8x32xf32>
      %780 = stablehlo.dynamic_slice %iterArg_76, %767, %c_100, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %781 = stablehlo.reshape %780 : (tensor<1x32xf32>) -> tensor<32xf32>
      %782 = stablehlo.dynamic_slice %iterArg_77, %767, %c_100, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %783 = stablehlo.reshape %782 : (tensor<1x32xf32>) -> tensor<32xf32>
      %784 = stablehlo.dynamic_slice %iterArg_78, %767, %c_100, sizes = [1, 32] : (tensor<2x32xf32>, tensor<i32>, tensor<i32>) -> tensor<1x32xf32>
      %785 = stablehlo.reshape %784 : (tensor<1x32xf32>) -> tensor<32xf32>
      %786 = stablehlo.dynamic_slice %iterArg_79, %767, %c_100, %c_100, sizes = [1, 32, 128] : (tensor<2x32x128xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x32x128xf32>
      %787 = stablehlo.reshape %786 : (tensor<1x32x128xf32>) -> tensor<32x128xf32>
      %788 = stablehlo.dynamic_slice %iterArg_80, %767, %c_100, sizes = [1, 128] : (tensor<2x128xf32>, tensor<i32>, tensor<i32>) -> tensor<1x128xf32>
      %789 = stablehlo.reshape %788 : (tensor<1x128xf32>) -> tensor<128xf32>
      %790 = stablehlo.dynamic_slice %iterArg_81, %767, %c_100, %c_100, sizes = [1, 128, 32] : (tensor<2x128x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<1x128x32xf32>
      %791 = stablehlo.reshape %790 : (tensor<1x128x32xf32>) -> tensor<128x32xf32>
      %792 = stablehlo.dynamic_slice %iterArg_82, %767, %c_100, sizes = [1, 2] : (tensor<2x2xui32>, tensor<i32>, tensor<i32>) -> tensor<1x2xui32>
      %793 = stablehlo.reshape %792 : (tensor<1x2xui32>) -> tensor<2xui32>
      %794:13 = func.call @None_15(%iterArg_83, %iterArg_85, %769, %771, %773, %775, %777, %779, %781, %783, %785, %787, %789, %791, %793) : (tensor<32x1024xi32>, tensor<32x1024x32xf32>, tensor<32x1024x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x3x4x8xf32>, tensor<3x4x8xf32>, tensor<4x8x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x128xf32>, tensor<128xf32>, tensor<128x32xf32>, tensor<2xui32>) -> (tensor<32x1024x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x3x4x8xf32>, tensor<3x4x8xf32>, tensor<4x8x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x128xf32>, tensor<128xf32>, tensor<128x32xf32>, tensor<32xf32>)
      %795 = stablehlo.broadcast_in_dim %794#1, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %796 = stablehlo.dynamic_update_slice %iterArg_86, %795, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %797 = stablehlo.broadcast_in_dim %794#2, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %798 = stablehlo.dynamic_update_slice %iterArg_87, %797, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %799 = stablehlo.broadcast_in_dim %794#3, dims = [1, 2, 3, 4] : (tensor<32x3x4x8xf32>) -> tensor<1x32x3x4x8xf32>
      %800 = stablehlo.dynamic_update_slice %iterArg_88, %799, %767, %c_100, %c_100, %c_100, %c_100 : (tensor<2x32x3x4x8xf32>, tensor<1x32x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x32x3x4x8xf32>
      %801 = stablehlo.broadcast_in_dim %794#4, dims = [1, 2, 3] : (tensor<3x4x8xf32>) -> tensor<1x3x4x8xf32>
      %802 = stablehlo.dynamic_update_slice %iterArg_89, %801, %767, %c_100, %c_100, %c_100 : (tensor<2x3x4x8xf32>, tensor<1x3x4x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x3x4x8xf32>
      %803 = stablehlo.broadcast_in_dim %794#5, dims = [1, 2, 3] : (tensor<4x8x32xf32>) -> tensor<1x4x8x32xf32>
      %804 = stablehlo.dynamic_update_slice %iterArg_90, %803, %767, %c_100, %c_100, %c_100 : (tensor<2x4x8x32xf32>, tensor<1x4x8x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x4x8x32xf32>
      %805 = stablehlo.broadcast_in_dim %794#6, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %806 = stablehlo.dynamic_update_slice %iterArg_91, %805, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %807 = stablehlo.broadcast_in_dim %794#7, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %808 = stablehlo.dynamic_update_slice %iterArg_92, %807, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %809 = stablehlo.broadcast_in_dim %794#8, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %810 = stablehlo.dynamic_update_slice %iterArg_93, %809, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %811 = stablehlo.broadcast_in_dim %794#9, dims = [1, 2] : (tensor<32x128xf32>) -> tensor<1x32x128xf32>
      %812 = stablehlo.dynamic_update_slice %iterArg_94, %811, %767, %c_100, %c_100 : (tensor<2x32x128xf32>, tensor<1x32x128xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x32x128xf32>
      %813 = stablehlo.broadcast_in_dim %794#10, dims = [1] : (tensor<128xf32>) -> tensor<1x128xf32>
      %814 = stablehlo.dynamic_update_slice %iterArg_95, %813, %767, %c_100 : (tensor<2x128xf32>, tensor<1x128xf32>, tensor<i32>, tensor<i32>) -> tensor<2x128xf32>
      %815 = stablehlo.broadcast_in_dim %794#11, dims = [1, 2] : (tensor<128x32xf32>) -> tensor<1x128x32xf32>
      %816 = stablehlo.dynamic_update_slice %iterArg_96, %815, %767, %c_100, %c_100 : (tensor<2x128x32xf32>, tensor<1x128x32xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<2x128x32xf32>
      %817 = stablehlo.broadcast_in_dim %794#12, dims = [1] : (tensor<32xf32>) -> tensor<1x32xf32>
      %818 = stablehlo.dynamic_update_slice %iterArg_97, %817, %767, %c_100 : (tensor<2x32xf32>, tensor<1x32xf32>, tensor<i32>, tensor<i32>) -> tensor<2x32xf32>
      %819 = stablehlo.add %iterArg_84, %c_99 : tensor<i32>
      stablehlo.return %iterArg, %iterArg_71, %iterArg_72, %iterArg_73, %iterArg_74, %iterArg_75, %iterArg_76, %iterArg_77, %iterArg_78, %iterArg_79, %iterArg_80, %iterArg_81, %iterArg_82, %iterArg_83, %819, %794#0, %796, %798, %800, %802, %804, %806, %808, %810, %812, %814, %816, %818 : tensor<2x32x1024x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x2xui32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x1024x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>
    }
    %cst_36 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %145 = stablehlo.reduce(%144#15 init: %cst_36) applies stablehlo.add across dimensions = [0] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<1024x32xf32>
    %146 = call @_take_28(%12#1, %145) : (tensor<1024x1xi32>, tensor<1024x32xf32>) -> tensor<1024x32xf32>
    %147 = call @_take_29(%6#1, %144#15) : (tensor<32x1024x1xi32>, tensor<32x1024x32xf32>) -> tensor<50257x32xf32>
    %148 = stablehlo.add %113, %147 : tensor<50257x32xf32>
    %cst_37 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %149 = stablehlo.reduce(%117 init: %cst_37) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %150 = stablehlo.subtract %arg18, %c_0 : tensor<i32>
    %151 = call @clip(%150, %c_1, %c_2) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %152 = stablehlo.convert %151 : (tensor<i32>) -> tensor<f32>
    %153 = stablehlo.divide %152, %cst_12 : tensor<f32>
    %154 = stablehlo.subtract %cst_12, %153 : tensor<f32>
    %cst_38 = stablehlo.constant dense<-6.000000e-04> : tensor<f32>
    %155 = stablehlo.multiply %cst_38, %154 : tensor<f32>
    %cst_39 = stablehlo.constant dense<6.000000e-04> : tensor<f32>
    %156 = stablehlo.add %155, %cst_39 : tensor<f32>
    %157 = stablehlo.compare  LT, %arg18, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %158 = stablehlo.subtract %arg18, %c : tensor<i32>
    %159 = stablehlo.convert %158 : (tensor<i32>) -> tensor<f32>
    %cst_40 = stablehlo.constant dense<9.900000e+01> : tensor<f32>
    %160 = stablehlo.minimum %159, %cst_40 : tensor<f32>
    %cst_41 = stablehlo.constant dense<3.14159274> : tensor<f32>
    %161 = stablehlo.multiply %cst_41, %160 : tensor<f32>
    %162 = stablehlo.divide %161, %cst_40 : tensor<f32>
    %163 = stablehlo.cosine %162 : tensor<f32>
    %cst_42 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %164 = stablehlo.add %cst_42, %163 : tensor<f32>
    %cst_43 = stablehlo.constant dense<5.000000e-01> : tensor<f32>
    %165 = stablehlo.multiply %cst_43, %164 : tensor<f32>
    %166 = stablehlo.power %165, %cst_42 : tensor<f32>
    %cst_44 = stablehlo.constant dense<0.899999976> : tensor<f32>
    %167 = stablehlo.multiply %cst_44, %166 : tensor<f32>
    %cst_45 = stablehlo.constant dense<1.000000e-01> : tensor<f32>
    %168 = stablehlo.add %167, %cst_45 : tensor<f32>
    %cst_46 = stablehlo.constant dense<6.000000e-04> : tensor<f32>
    %169 = stablehlo.multiply %cst_46, %168 : tensor<f32>
    %170 = call @_where_30(%157, %156, %169) : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32>
    %c_47 = stablehlo.constant dense<2147483647> : tensor<i32>
    %171 = stablehlo.compare  LT, %arg18, %c_47,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %172 = stablehlo.add %arg18, %c : tensor<i32>
    %173 = call @_where_31(%171, %172, %c_47) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %174 = stablehlo.negate %170 : tensor<f32>
    %175 = stablehlo.multiply %144#16, %144#16 : tensor<2x32xf32>
    %cst_48 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %176 = stablehlo.reduce(%175 init: %cst_48) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %177 = stablehlo.add %cst, %176 : tensor<f32>
    %178 = stablehlo.multiply %144#17, %144#17 : tensor<2x32xf32>
    %cst_49 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %179 = stablehlo.reduce(%178 init: %cst_49) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %180 = stablehlo.add %177, %179 : tensor<f32>
    %181 = stablehlo.multiply %144#18, %144#18 : tensor<2x32x3x4x8xf32>
    %cst_50 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %182 = stablehlo.reduce(%181 init: %cst_50) applies stablehlo.add across dimensions = [0, 1, 2, 3, 4] : (tensor<2x32x3x4x8xf32>, tensor<f32>) -> tensor<f32>
    %183 = stablehlo.add %180, %182 : tensor<f32>
    %184 = stablehlo.multiply %144#19, %144#19 : tensor<2x3x4x8xf32>
    %cst_51 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %185 = stablehlo.reduce(%184 init: %cst_51) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<2x3x4x8xf32>, tensor<f32>) -> tensor<f32>
    %186 = stablehlo.add %183, %185 : tensor<f32>
    %187 = stablehlo.multiply %144#20, %144#20 : tensor<2x4x8x32xf32>
    %cst_52 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %188 = stablehlo.reduce(%187 init: %cst_52) applies stablehlo.add across dimensions = [0, 1, 2, 3] : (tensor<2x4x8x32xf32>, tensor<f32>) -> tensor<f32>
    %189 = stablehlo.add %186, %188 : tensor<f32>
    %190 = stablehlo.multiply %144#21, %144#21 : tensor<2x32xf32>
    %cst_53 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %191 = stablehlo.reduce(%190 init: %cst_53) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %192 = stablehlo.add %189, %191 : tensor<f32>
    %193 = stablehlo.multiply %144#22, %144#22 : tensor<2x32xf32>
    %cst_54 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %194 = stablehlo.reduce(%193 init: %cst_54) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %195 = stablehlo.add %192, %194 : tensor<f32>
    %196 = stablehlo.multiply %144#23, %144#23 : tensor<2x32xf32>
    %cst_55 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %197 = stablehlo.reduce(%196 init: %cst_55) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %198 = stablehlo.add %195, %197 : tensor<f32>
    %199 = stablehlo.multiply %144#24, %144#24 : tensor<2x32x128xf32>
    %cst_56 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %200 = stablehlo.reduce(%199 init: %cst_56) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<2x32x128xf32>, tensor<f32>) -> tensor<f32>
    %201 = stablehlo.add %198, %200 : tensor<f32>
    %202 = stablehlo.multiply %144#25, %144#25 : tensor<2x128xf32>
    %cst_57 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %203 = stablehlo.reduce(%202 init: %cst_57) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x128xf32>, tensor<f32>) -> tensor<f32>
    %204 = stablehlo.add %201, %203 : tensor<f32>
    %205 = stablehlo.multiply %144#26, %144#26 : tensor<2x128x32xf32>
    %cst_58 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %206 = stablehlo.reduce(%205 init: %cst_58) applies stablehlo.add across dimensions = [0, 1, 2] : (tensor<2x128x32xf32>, tensor<f32>) -> tensor<f32>
    %207 = stablehlo.add %204, %206 : tensor<f32>
    %208 = stablehlo.multiply %144#27, %144#27 : tensor<2x32xf32>
    %cst_59 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %209 = stablehlo.reduce(%208 init: %cst_59) applies stablehlo.add across dimensions = [0, 1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<f32>
    %210 = stablehlo.add %207, %209 : tensor<f32>
    %211 = stablehlo.multiply %149, %149 : tensor<32xf32>
    %cst_60 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %212 = stablehlo.reduce(%211 init: %cst_60) applies stablehlo.add across dimensions = [0] : (tensor<32xf32>, tensor<f32>) -> tensor<f32>
    %213 = stablehlo.add %210, %212 : tensor<f32>
    %214 = stablehlo.multiply %115, %115 : tensor<32xf32>
    %cst_61 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %215 = stablehlo.reduce(%214 init: %cst_61) applies stablehlo.add across dimensions = [0] : (tensor<32xf32>, tensor<f32>) -> tensor<f32>
    %216 = stablehlo.add %213, %215 : tensor<f32>
    %217 = stablehlo.multiply %148, %148 : tensor<50257x32xf32>
    %cst_62 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %218 = stablehlo.reduce(%217 init: %cst_62) applies stablehlo.add across dimensions = [0, 1] : (tensor<50257x32xf32>, tensor<f32>) -> tensor<f32>
    %219 = stablehlo.add %216, %218 : tensor<f32>
    %220 = stablehlo.multiply %146, %146 : tensor<1024x32xf32>
    %cst_63 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %221 = stablehlo.reduce(%220 init: %cst_63) applies stablehlo.add across dimensions = [0, 1] : (tensor<1024x32xf32>, tensor<f32>) -> tensor<f32>
    %222 = stablehlo.add %219, %221 : tensor<f32>
    %223 = stablehlo.sqrt %222 : tensor<f32>
    %224 = stablehlo.compare  LT, %223, %cst_12,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %225 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %226 = stablehlo.divide %144#16, %225 : tensor<2x32xf32>
    %227 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %228 = stablehlo.multiply %226, %227 : tensor<2x32xf32>
    %229 = stablehlo.select %224, %144#16, %228 : tensor<i1>, tensor<2x32xf32>
    %230 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %231 = stablehlo.divide %144#17, %230 : tensor<2x32xf32>
    %232 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %233 = stablehlo.multiply %231, %232 : tensor<2x32xf32>
    %234 = stablehlo.select %224, %144#17, %233 : tensor<i1>, tensor<2x32xf32>
    %235 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %236 = stablehlo.divide %144#18, %235 : tensor<2x32x3x4x8xf32>
    %237 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %238 = stablehlo.multiply %236, %237 : tensor<2x32x3x4x8xf32>
    %239 = stablehlo.select %224, %144#18, %238 : tensor<i1>, tensor<2x32x3x4x8xf32>
    %240 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %241 = stablehlo.divide %144#19, %240 : tensor<2x3x4x8xf32>
    %242 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %243 = stablehlo.multiply %241, %242 : tensor<2x3x4x8xf32>
    %244 = stablehlo.select %224, %144#19, %243 : tensor<i1>, tensor<2x3x4x8xf32>
    %245 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %246 = stablehlo.divide %144#20, %245 : tensor<2x4x8x32xf32>
    %247 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %248 = stablehlo.multiply %246, %247 : tensor<2x4x8x32xf32>
    %249 = stablehlo.select %224, %144#20, %248 : tensor<i1>, tensor<2x4x8x32xf32>
    %250 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %251 = stablehlo.divide %144#21, %250 : tensor<2x32xf32>
    %252 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %253 = stablehlo.multiply %251, %252 : tensor<2x32xf32>
    %254 = stablehlo.select %224, %144#21, %253 : tensor<i1>, tensor<2x32xf32>
    %255 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %256 = stablehlo.divide %144#22, %255 : tensor<2x32xf32>
    %257 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %258 = stablehlo.multiply %256, %257 : tensor<2x32xf32>
    %259 = stablehlo.select %224, %144#22, %258 : tensor<i1>, tensor<2x32xf32>
    %260 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %261 = stablehlo.divide %144#23, %260 : tensor<2x32xf32>
    %262 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %263 = stablehlo.multiply %261, %262 : tensor<2x32xf32>
    %264 = stablehlo.select %224, %144#23, %263 : tensor<i1>, tensor<2x32xf32>
    %265 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %266 = stablehlo.divide %144#24, %265 : tensor<2x32x128xf32>
    %267 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %268 = stablehlo.multiply %266, %267 : tensor<2x32x128xf32>
    %269 = stablehlo.select %224, %144#24, %268 : tensor<i1>, tensor<2x32x128xf32>
    %270 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %271 = stablehlo.divide %144#25, %270 : tensor<2x128xf32>
    %272 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %273 = stablehlo.multiply %271, %272 : tensor<2x128xf32>
    %274 = stablehlo.select %224, %144#25, %273 : tensor<i1>, tensor<2x128xf32>
    %275 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %276 = stablehlo.divide %144#26, %275 : tensor<2x128x32xf32>
    %277 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %278 = stablehlo.multiply %276, %277 : tensor<2x128x32xf32>
    %279 = stablehlo.select %224, %144#26, %278 : tensor<i1>, tensor<2x128x32xf32>
    %280 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %281 = stablehlo.divide %144#27, %280 : tensor<2x32xf32>
    %282 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %283 = stablehlo.multiply %281, %282 : tensor<2x32xf32>
    %284 = stablehlo.select %224, %144#27, %283 : tensor<i1>, tensor<2x32xf32>
    %285 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %286 = stablehlo.divide %149, %285 : tensor<32xf32>
    %287 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %288 = stablehlo.multiply %286, %287 : tensor<32xf32>
    %289 = stablehlo.select %224, %149, %288 : tensor<i1>, tensor<32xf32>
    %290 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %291 = stablehlo.divide %115, %290 : tensor<32xf32>
    %292 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %293 = stablehlo.multiply %291, %292 : tensor<32xf32>
    %294 = stablehlo.select %224, %115, %293 : tensor<i1>, tensor<32xf32>
    %295 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %296 = stablehlo.divide %148, %295 : tensor<50257x32xf32>
    %297 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %298 = stablehlo.multiply %296, %297 : tensor<50257x32xf32>
    %299 = stablehlo.select %224, %148, %298 : tensor<i1>, tensor<50257x32xf32>
    %300 = stablehlo.broadcast_in_dim %223, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %301 = stablehlo.divide %146, %300 : tensor<1024x32xf32>
    %302 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %303 = stablehlo.multiply %301, %302 : tensor<1024x32xf32>
    %304 = stablehlo.select %224, %146, %303 : tensor<i1>, tensor<1024x32xf32>
    %cst_64 = stablehlo.constant dense<1.000000e-01> : tensor<f32>
    %305 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %306 = stablehlo.multiply %305, %229 : tensor<2x32xf32>
    %cst_65 = stablehlo.constant dense<0.899999976> : tensor<f32>
    %307 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %308 = stablehlo.multiply %307, %arg20 : tensor<2x32xf32>
    %309 = stablehlo.add %306, %308 : tensor<2x32xf32>
    %310 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %311 = stablehlo.multiply %310, %234 : tensor<2x32xf32>
    %312 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %313 = stablehlo.multiply %312, %arg21 : tensor<2x32xf32>
    %314 = stablehlo.add %311, %313 : tensor<2x32xf32>
    %315 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %316 = stablehlo.multiply %315, %239 : tensor<2x32x3x4x8xf32>
    %317 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %318 = stablehlo.multiply %317, %arg22 : tensor<2x32x3x4x8xf32>
    %319 = stablehlo.add %316, %318 : tensor<2x32x3x4x8xf32>
    %320 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %321 = stablehlo.multiply %320, %244 : tensor<2x3x4x8xf32>
    %322 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %323 = stablehlo.multiply %322, %arg23 : tensor<2x3x4x8xf32>
    %324 = stablehlo.add %321, %323 : tensor<2x3x4x8xf32>
    %325 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %326 = stablehlo.multiply %325, %249 : tensor<2x4x8x32xf32>
    %327 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %328 = stablehlo.multiply %327, %arg24 : tensor<2x4x8x32xf32>
    %329 = stablehlo.add %326, %328 : tensor<2x4x8x32xf32>
    %330 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %331 = stablehlo.multiply %330, %254 : tensor<2x32xf32>
    %332 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %333 = stablehlo.multiply %332, %arg25 : tensor<2x32xf32>
    %334 = stablehlo.add %331, %333 : tensor<2x32xf32>
    %335 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %336 = stablehlo.multiply %335, %259 : tensor<2x32xf32>
    %337 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %338 = stablehlo.multiply %337, %arg26 : tensor<2x32xf32>
    %339 = stablehlo.add %336, %338 : tensor<2x32xf32>
    %340 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %341 = stablehlo.multiply %340, %264 : tensor<2x32xf32>
    %342 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %343 = stablehlo.multiply %342, %arg27 : tensor<2x32xf32>
    %344 = stablehlo.add %341, %343 : tensor<2x32xf32>
    %345 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %346 = stablehlo.multiply %345, %269 : tensor<2x32x128xf32>
    %347 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %348 = stablehlo.multiply %347, %arg28 : tensor<2x32x128xf32>
    %349 = stablehlo.add %346, %348 : tensor<2x32x128xf32>
    %350 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %351 = stablehlo.multiply %350, %274 : tensor<2x128xf32>
    %352 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %353 = stablehlo.multiply %352, %arg29 : tensor<2x128xf32>
    %354 = stablehlo.add %351, %353 : tensor<2x128xf32>
    %355 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %356 = stablehlo.multiply %355, %279 : tensor<2x128x32xf32>
    %357 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %358 = stablehlo.multiply %357, %arg30 : tensor<2x128x32xf32>
    %359 = stablehlo.add %356, %358 : tensor<2x128x32xf32>
    %360 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %361 = stablehlo.multiply %360, %284 : tensor<2x32xf32>
    %362 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %363 = stablehlo.multiply %362, %arg31 : tensor<2x32xf32>
    %364 = stablehlo.add %361, %363 : tensor<2x32xf32>
    %365 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %366 = stablehlo.multiply %365, %289 : tensor<32xf32>
    %367 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %368 = stablehlo.multiply %367, %arg32 : tensor<32xf32>
    %369 = stablehlo.add %366, %368 : tensor<32xf32>
    %370 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %371 = stablehlo.multiply %370, %294 : tensor<32xf32>
    %372 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %373 = stablehlo.multiply %372, %arg33 : tensor<32xf32>
    %374 = stablehlo.add %371, %373 : tensor<32xf32>
    %375 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %376 = stablehlo.multiply %375, %299 : tensor<50257x32xf32>
    %377 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %378 = stablehlo.multiply %377, %arg34 : tensor<50257x32xf32>
    %379 = stablehlo.add %376, %378 : tensor<50257x32xf32>
    %380 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %381 = stablehlo.multiply %380, %304 : tensor<1024x32xf32>
    %382 = stablehlo.broadcast_in_dim %cst_65, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %383 = stablehlo.multiply %382, %arg35 : tensor<1024x32xf32>
    %384 = stablehlo.add %381, %383 : tensor<1024x32xf32>
    %385 = stablehlo.multiply %229, %229 : tensor<2x32xf32>
    %cst_66 = stablehlo.constant dense<5.000000e-02> : tensor<f32>
    %386 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %387 = stablehlo.multiply %386, %385 : tensor<2x32xf32>
    %cst_67 = stablehlo.constant dense<0.949999988> : tensor<f32>
    %388 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %389 = stablehlo.multiply %388, %arg36 : tensor<2x32xf32>
    %390 = stablehlo.add %387, %389 : tensor<2x32xf32>
    %391 = stablehlo.multiply %234, %234 : tensor<2x32xf32>
    %392 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %393 = stablehlo.multiply %392, %391 : tensor<2x32xf32>
    %394 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %395 = stablehlo.multiply %394, %arg37 : tensor<2x32xf32>
    %396 = stablehlo.add %393, %395 : tensor<2x32xf32>
    %397 = stablehlo.multiply %239, %239 : tensor<2x32x3x4x8xf32>
    %398 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %399 = stablehlo.multiply %398, %397 : tensor<2x32x3x4x8xf32>
    %400 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %401 = stablehlo.multiply %400, %arg38 : tensor<2x32x3x4x8xf32>
    %402 = stablehlo.add %399, %401 : tensor<2x32x3x4x8xf32>
    %403 = stablehlo.multiply %244, %244 : tensor<2x3x4x8xf32>
    %404 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %405 = stablehlo.multiply %404, %403 : tensor<2x3x4x8xf32>
    %406 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %407 = stablehlo.multiply %406, %arg39 : tensor<2x3x4x8xf32>
    %408 = stablehlo.add %405, %407 : tensor<2x3x4x8xf32>
    %409 = stablehlo.multiply %249, %249 : tensor<2x4x8x32xf32>
    %410 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %411 = stablehlo.multiply %410, %409 : tensor<2x4x8x32xf32>
    %412 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %413 = stablehlo.multiply %412, %arg40 : tensor<2x4x8x32xf32>
    %414 = stablehlo.add %411, %413 : tensor<2x4x8x32xf32>
    %415 = stablehlo.multiply %254, %254 : tensor<2x32xf32>
    %416 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %417 = stablehlo.multiply %416, %415 : tensor<2x32xf32>
    %418 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %419 = stablehlo.multiply %418, %arg41 : tensor<2x32xf32>
    %420 = stablehlo.add %417, %419 : tensor<2x32xf32>
    %421 = stablehlo.multiply %259, %259 : tensor<2x32xf32>
    %422 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %423 = stablehlo.multiply %422, %421 : tensor<2x32xf32>
    %424 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %425 = stablehlo.multiply %424, %arg42 : tensor<2x32xf32>
    %426 = stablehlo.add %423, %425 : tensor<2x32xf32>
    %427 = stablehlo.multiply %264, %264 : tensor<2x32xf32>
    %428 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %429 = stablehlo.multiply %428, %427 : tensor<2x32xf32>
    %430 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %431 = stablehlo.multiply %430, %arg43 : tensor<2x32xf32>
    %432 = stablehlo.add %429, %431 : tensor<2x32xf32>
    %433 = stablehlo.multiply %269, %269 : tensor<2x32x128xf32>
    %434 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %435 = stablehlo.multiply %434, %433 : tensor<2x32x128xf32>
    %436 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %437 = stablehlo.multiply %436, %arg44 : tensor<2x32x128xf32>
    %438 = stablehlo.add %435, %437 : tensor<2x32x128xf32>
    %439 = stablehlo.multiply %274, %274 : tensor<2x128xf32>
    %440 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %441 = stablehlo.multiply %440, %439 : tensor<2x128xf32>
    %442 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %443 = stablehlo.multiply %442, %arg45 : tensor<2x128xf32>
    %444 = stablehlo.add %441, %443 : tensor<2x128xf32>
    %445 = stablehlo.multiply %279, %279 : tensor<2x128x32xf32>
    %446 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %447 = stablehlo.multiply %446, %445 : tensor<2x128x32xf32>
    %448 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %449 = stablehlo.multiply %448, %arg46 : tensor<2x128x32xf32>
    %450 = stablehlo.add %447, %449 : tensor<2x128x32xf32>
    %451 = stablehlo.multiply %284, %284 : tensor<2x32xf32>
    %452 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %453 = stablehlo.multiply %452, %451 : tensor<2x32xf32>
    %454 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %455 = stablehlo.multiply %454, %arg47 : tensor<2x32xf32>
    %456 = stablehlo.add %453, %455 : tensor<2x32xf32>
    %457 = stablehlo.multiply %289, %289 : tensor<32xf32>
    %458 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %459 = stablehlo.multiply %458, %457 : tensor<32xf32>
    %460 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %461 = stablehlo.multiply %460, %arg48 : tensor<32xf32>
    %462 = stablehlo.add %459, %461 : tensor<32xf32>
    %463 = stablehlo.multiply %294, %294 : tensor<32xf32>
    %464 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %465 = stablehlo.multiply %464, %463 : tensor<32xf32>
    %466 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %467 = stablehlo.multiply %466, %arg49 : tensor<32xf32>
    %468 = stablehlo.add %465, %467 : tensor<32xf32>
    %469 = stablehlo.multiply %299, %299 : tensor<50257x32xf32>
    %470 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %471 = stablehlo.multiply %470, %469 : tensor<50257x32xf32>
    %472 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %473 = stablehlo.multiply %472, %arg50 : tensor<50257x32xf32>
    %474 = stablehlo.add %471, %473 : tensor<50257x32xf32>
    %475 = stablehlo.multiply %304, %304 : tensor<1024x32xf32>
    %476 = stablehlo.broadcast_in_dim %cst_66, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %477 = stablehlo.multiply %476, %475 : tensor<1024x32xf32>
    %478 = stablehlo.broadcast_in_dim %cst_67, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %479 = stablehlo.multiply %478, %arg51 : tensor<1024x32xf32>
    %480 = stablehlo.add %477, %479 : tensor<1024x32xf32>
    %481 = stablehlo.compare  LT, %arg19, %c_47,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %482 = stablehlo.add %arg19, %c : tensor<i32>
    %483 = call @_where_31(%481, %482, %c_47) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %484 = stablehlo.convert %483 : (tensor<i32>) -> tensor<f32>
    %485 = stablehlo.power %cst_44, %484 : tensor<f32>
    %486 = stablehlo.subtract %cst_12, %485 : tensor<f32>
    %487 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %488 = stablehlo.divide %309, %487 : tensor<2x32xf32>
    %489 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %490 = stablehlo.divide %314, %489 : tensor<2x32xf32>
    %491 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %492 = stablehlo.divide %319, %491 : tensor<2x32x3x4x8xf32>
    %493 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %494 = stablehlo.divide %324, %493 : tensor<2x3x4x8xf32>
    %495 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %496 = stablehlo.divide %329, %495 : tensor<2x4x8x32xf32>
    %497 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %498 = stablehlo.divide %334, %497 : tensor<2x32xf32>
    %499 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %500 = stablehlo.divide %339, %499 : tensor<2x32xf32>
    %501 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %502 = stablehlo.divide %344, %501 : tensor<2x32xf32>
    %503 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %504 = stablehlo.divide %349, %503 : tensor<2x32x128xf32>
    %505 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %506 = stablehlo.divide %354, %505 : tensor<2x128xf32>
    %507 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %508 = stablehlo.divide %359, %507 : tensor<2x128x32xf32>
    %509 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %510 = stablehlo.divide %364, %509 : tensor<2x32xf32>
    %511 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %512 = stablehlo.divide %369, %511 : tensor<32xf32>
    %513 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %514 = stablehlo.divide %374, %513 : tensor<32xf32>
    %515 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %516 = stablehlo.divide %379, %515 : tensor<50257x32xf32>
    %517 = stablehlo.broadcast_in_dim %486, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %518 = stablehlo.divide %384, %517 : tensor<1024x32xf32>
    %cst_68 = stablehlo.constant dense<0.949999988> : tensor<f32>
    %519 = stablehlo.convert %483 : (tensor<i32>) -> tensor<f32>
    %520 = stablehlo.power %cst_68, %519 : tensor<f32>
    %521 = stablehlo.subtract %cst_12, %520 : tensor<f32>
    %522 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %523 = stablehlo.divide %390, %522 : tensor<2x32xf32>
    %524 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %525 = stablehlo.divide %396, %524 : tensor<2x32xf32>
    %526 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %527 = stablehlo.divide %402, %526 : tensor<2x32x3x4x8xf32>
    %528 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %529 = stablehlo.divide %408, %528 : tensor<2x3x4x8xf32>
    %530 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %531 = stablehlo.divide %414, %530 : tensor<2x4x8x32xf32>
    %532 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %533 = stablehlo.divide %420, %532 : tensor<2x32xf32>
    %534 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %535 = stablehlo.divide %426, %534 : tensor<2x32xf32>
    %536 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %537 = stablehlo.divide %432, %536 : tensor<2x32xf32>
    %538 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %539 = stablehlo.divide %438, %538 : tensor<2x32x128xf32>
    %540 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %541 = stablehlo.divide %444, %540 : tensor<2x128xf32>
    %542 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %543 = stablehlo.divide %450, %542 : tensor<2x128x32xf32>
    %544 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %545 = stablehlo.divide %456, %544 : tensor<2x32xf32>
    %546 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %547 = stablehlo.divide %462, %546 : tensor<32xf32>
    %548 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %549 = stablehlo.divide %468, %548 : tensor<32xf32>
    %550 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %551 = stablehlo.divide %474, %550 : tensor<50257x32xf32>
    %552 = stablehlo.broadcast_in_dim %521, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %553 = stablehlo.divide %480, %552 : tensor<1024x32xf32>
    %554 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %555 = stablehlo.add %523, %554 : tensor<2x32xf32>
    %556 = stablehlo.sqrt %555 : tensor<2x32xf32>
    %cst_69 = stablehlo.constant dense<9.99999993E-9> : tensor<f32>
    %557 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %558 = stablehlo.add %556, %557 : tensor<2x32xf32>
    %559 = stablehlo.divide %488, %558 : tensor<2x32xf32>
    %560 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %561 = stablehlo.add %525, %560 : tensor<2x32xf32>
    %562 = stablehlo.sqrt %561 : tensor<2x32xf32>
    %563 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %564 = stablehlo.add %562, %563 : tensor<2x32xf32>
    %565 = stablehlo.divide %490, %564 : tensor<2x32xf32>
    %566 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %567 = stablehlo.add %527, %566 : tensor<2x32x3x4x8xf32>
    %568 = stablehlo.sqrt %567 : tensor<2x32x3x4x8xf32>
    %569 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %570 = stablehlo.add %568, %569 : tensor<2x32x3x4x8xf32>
    %571 = stablehlo.divide %492, %570 : tensor<2x32x3x4x8xf32>
    %572 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %573 = stablehlo.add %529, %572 : tensor<2x3x4x8xf32>
    %574 = stablehlo.sqrt %573 : tensor<2x3x4x8xf32>
    %575 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %576 = stablehlo.add %574, %575 : tensor<2x3x4x8xf32>
    %577 = stablehlo.divide %494, %576 : tensor<2x3x4x8xf32>
    %578 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %579 = stablehlo.add %531, %578 : tensor<2x4x8x32xf32>
    %580 = stablehlo.sqrt %579 : tensor<2x4x8x32xf32>
    %581 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %582 = stablehlo.add %580, %581 : tensor<2x4x8x32xf32>
    %583 = stablehlo.divide %496, %582 : tensor<2x4x8x32xf32>
    %584 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %585 = stablehlo.add %533, %584 : tensor<2x32xf32>
    %586 = stablehlo.sqrt %585 : tensor<2x32xf32>
    %587 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %588 = stablehlo.add %586, %587 : tensor<2x32xf32>
    %589 = stablehlo.divide %498, %588 : tensor<2x32xf32>
    %590 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %591 = stablehlo.add %535, %590 : tensor<2x32xf32>
    %592 = stablehlo.sqrt %591 : tensor<2x32xf32>
    %593 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %594 = stablehlo.add %592, %593 : tensor<2x32xf32>
    %595 = stablehlo.divide %500, %594 : tensor<2x32xf32>
    %596 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %597 = stablehlo.add %537, %596 : tensor<2x32xf32>
    %598 = stablehlo.sqrt %597 : tensor<2x32xf32>
    %599 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %600 = stablehlo.add %598, %599 : tensor<2x32xf32>
    %601 = stablehlo.divide %502, %600 : tensor<2x32xf32>
    %602 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %603 = stablehlo.add %539, %602 : tensor<2x32x128xf32>
    %604 = stablehlo.sqrt %603 : tensor<2x32x128xf32>
    %605 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %606 = stablehlo.add %604, %605 : tensor<2x32x128xf32>
    %607 = stablehlo.divide %504, %606 : tensor<2x32x128xf32>
    %608 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %609 = stablehlo.add %541, %608 : tensor<2x128xf32>
    %610 = stablehlo.sqrt %609 : tensor<2x128xf32>
    %611 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %612 = stablehlo.add %610, %611 : tensor<2x128xf32>
    %613 = stablehlo.divide %506, %612 : tensor<2x128xf32>
    %614 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %615 = stablehlo.add %543, %614 : tensor<2x128x32xf32>
    %616 = stablehlo.sqrt %615 : tensor<2x128x32xf32>
    %617 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %618 = stablehlo.add %616, %617 : tensor<2x128x32xf32>
    %619 = stablehlo.divide %508, %618 : tensor<2x128x32xf32>
    %620 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %621 = stablehlo.add %545, %620 : tensor<2x32xf32>
    %622 = stablehlo.sqrt %621 : tensor<2x32xf32>
    %623 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %624 = stablehlo.add %622, %623 : tensor<2x32xf32>
    %625 = stablehlo.divide %510, %624 : tensor<2x32xf32>
    %626 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %627 = stablehlo.add %547, %626 : tensor<32xf32>
    %628 = stablehlo.sqrt %627 : tensor<32xf32>
    %629 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %630 = stablehlo.add %628, %629 : tensor<32xf32>
    %631 = stablehlo.divide %512, %630 : tensor<32xf32>
    %632 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %633 = stablehlo.add %549, %632 : tensor<32xf32>
    %634 = stablehlo.sqrt %633 : tensor<32xf32>
    %635 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %636 = stablehlo.add %634, %635 : tensor<32xf32>
    %637 = stablehlo.divide %514, %636 : tensor<32xf32>
    %638 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %639 = stablehlo.add %551, %638 : tensor<50257x32xf32>
    %640 = stablehlo.sqrt %639 : tensor<50257x32xf32>
    %641 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %642 = stablehlo.add %640, %641 : tensor<50257x32xf32>
    %643 = stablehlo.divide %516, %642 : tensor<50257x32xf32>
    %644 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %645 = stablehlo.add %553, %644 : tensor<1024x32xf32>
    %646 = stablehlo.sqrt %645 : tensor<1024x32xf32>
    %647 = stablehlo.broadcast_in_dim %cst_69, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %648 = stablehlo.add %646, %647 : tensor<1024x32xf32>
    %649 = stablehlo.divide %518, %648 : tensor<1024x32xf32>
    %650 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %651 = stablehlo.multiply %650, %arg3 : tensor<2x32x3x4x8xf32>
    %652 = stablehlo.add %571, %651 : tensor<2x32x3x4x8xf32>
    %653 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %654 = stablehlo.multiply %653, %arg5 : tensor<2x4x8x32xf32>
    %655 = stablehlo.add %583, %654 : tensor<2x4x8x32xf32>
    %656 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %657 = stablehlo.multiply %656, %arg9 : tensor<2x32x128xf32>
    %658 = stablehlo.add %607, %657 : tensor<2x32x128xf32>
    %659 = stablehlo.broadcast_in_dim %cst_64, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %660 = stablehlo.multiply %659, %arg11 : tensor<2x128x32xf32>
    %661 = stablehlo.add %619, %660 : tensor<2x128x32xf32>
    %662 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %663 = stablehlo.multiply %662, %559 : tensor<2x32xf32>
    %664 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %665 = stablehlo.multiply %664, %565 : tensor<2x32xf32>
    %666 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32x3x4x8xf32>
    %667 = stablehlo.multiply %666, %652 : tensor<2x32x3x4x8xf32>
    %668 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x3x4x8xf32>
    %669 = stablehlo.multiply %668, %577 : tensor<2x3x4x8xf32>
    %670 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x4x8x32xf32>
    %671 = stablehlo.multiply %670, %655 : tensor<2x4x8x32xf32>
    %672 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %673 = stablehlo.multiply %672, %589 : tensor<2x32xf32>
    %674 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %675 = stablehlo.multiply %674, %595 : tensor<2x32xf32>
    %676 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %677 = stablehlo.multiply %676, %601 : tensor<2x32xf32>
    %678 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32x128xf32>
    %679 = stablehlo.multiply %678, %658 : tensor<2x32x128xf32>
    %680 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x128xf32>
    %681 = stablehlo.multiply %680, %613 : tensor<2x128xf32>
    %682 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x128x32xf32>
    %683 = stablehlo.multiply %682, %661 : tensor<2x128x32xf32>
    %684 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<2x32xf32>
    %685 = stablehlo.multiply %684, %625 : tensor<2x32xf32>
    %686 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %687 = stablehlo.multiply %686, %631 : tensor<32xf32>
    %688 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<32xf32>
    %689 = stablehlo.multiply %688, %637 : tensor<32xf32>
    %690 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %691 = stablehlo.multiply %690, %643 : tensor<50257x32xf32>
    %692 = stablehlo.broadcast_in_dim %174, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %693 = stablehlo.multiply %692, %649 : tensor<1024x32xf32>
    %694 = stablehlo.compare  LT, %arg17, %c_47,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %695 = stablehlo.add %arg17, %c : tensor<i32>
    %696 = call @_where_31(%694, %695, %c_47) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %697 = stablehlo.add %arg1, %663 : tensor<2x32xf32>
    %698 = stablehlo.add %arg2, %665 : tensor<2x32xf32>
    %699 = stablehlo.add %arg3, %667 : tensor<2x32x3x4x8xf32>
    %700 = stablehlo.add %arg4, %669 : tensor<2x3x4x8xf32>
    %701 = stablehlo.add %arg5, %671 : tensor<2x4x8x32xf32>
    %702 = stablehlo.add %arg6, %673 : tensor<2x32xf32>
    %703 = stablehlo.add %arg7, %675 : tensor<2x32xf32>
    %704 = stablehlo.add %arg8, %677 : tensor<2x32xf32>
    %705 = stablehlo.add %arg9, %679 : tensor<2x32x128xf32>
    %706 = stablehlo.add %arg10, %681 : tensor<2x128xf32>
    %707 = stablehlo.add %arg11, %683 : tensor<2x128x32xf32>
    %708 = stablehlo.add %arg12, %685 : tensor<2x32xf32>
    %709 = stablehlo.add %arg13, %687 : tensor<32xf32>
    %710 = stablehlo.add %arg14, %689 : tensor<32xf32>
    %711 = stablehlo.add %arg15, %691 : tensor<50257x32xf32>
    %712 = stablehlo.add %arg16, %693 : tensor<1024x32xf32>
    %713 = stablehlo.add %arg0, %c_2 : tensor<i32>
    %714 = stablehlo.custom_call @Sharding(%697) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %715 = stablehlo.custom_call @Sharding(%698) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %716 = stablehlo.custom_call @Sharding(%699) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x3x4x8xf32>) -> tensor<2x32x3x4x8xf32>
    %717 = stablehlo.custom_call @Sharding(%700) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x3x4x8xf32>) -> tensor<2x3x4x8xf32>
    %718 = stablehlo.custom_call @Sharding(%701) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x4x8x32xf32>) -> tensor<2x4x8x32xf32>
    %719 = stablehlo.custom_call @Sharding(%702) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %720 = stablehlo.custom_call @Sharding(%703) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %721 = stablehlo.custom_call @Sharding(%704) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %722 = stablehlo.custom_call @Sharding(%705) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x128xf32>) -> tensor<2x32x128xf32>
    %723 = stablehlo.custom_call @Sharding(%706) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %724 = stablehlo.custom_call @Sharding(%707) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128x32xf32>) -> tensor<2x128x32xf32>
    %725 = stablehlo.custom_call @Sharding(%708) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %726 = stablehlo.custom_call @Sharding(%709) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %727 = stablehlo.custom_call @Sharding(%710) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %728 = stablehlo.custom_call @Sharding(%711) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<50257x32xf32>) -> tensor<50257x32xf32>
    %729 = stablehlo.custom_call @Sharding(%712) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<1024x32xf32>) -> tensor<1024x32xf32>
    %730 = stablehlo.custom_call @Sharding(%309) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %731 = stablehlo.custom_call @Sharding(%314) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %732 = stablehlo.custom_call @Sharding(%319) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x3x4x8xf32>) -> tensor<2x32x3x4x8xf32>
    %733 = stablehlo.custom_call @Sharding(%324) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x3x4x8xf32>) -> tensor<2x3x4x8xf32>
    %734 = stablehlo.custom_call @Sharding(%329) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x4x8x32xf32>) -> tensor<2x4x8x32xf32>
    %735 = stablehlo.custom_call @Sharding(%334) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %736 = stablehlo.custom_call @Sharding(%339) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %737 = stablehlo.custom_call @Sharding(%344) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %738 = stablehlo.custom_call @Sharding(%349) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x128xf32>) -> tensor<2x32x128xf32>
    %739 = stablehlo.custom_call @Sharding(%354) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %740 = stablehlo.custom_call @Sharding(%359) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128x32xf32>) -> tensor<2x128x32xf32>
    %741 = stablehlo.custom_call @Sharding(%364) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %742 = stablehlo.custom_call @Sharding(%369) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %743 = stablehlo.custom_call @Sharding(%374) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %744 = stablehlo.custom_call @Sharding(%379) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<50257x32xf32>) -> tensor<50257x32xf32>
    %745 = stablehlo.custom_call @Sharding(%384) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<1024x32xf32>) -> tensor<1024x32xf32>
    %746 = stablehlo.custom_call @Sharding(%390) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %747 = stablehlo.custom_call @Sharding(%396) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %748 = stablehlo.custom_call @Sharding(%402) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x3x4x8xf32>) -> tensor<2x32x3x4x8xf32>
    %749 = stablehlo.custom_call @Sharding(%408) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x3x4x8xf32>) -> tensor<2x3x4x8xf32>
    %750 = stablehlo.custom_call @Sharding(%414) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x4x8x32xf32>) -> tensor<2x4x8x32xf32>
    %751 = stablehlo.custom_call @Sharding(%420) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %752 = stablehlo.custom_call @Sharding(%426) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %753 = stablehlo.custom_call @Sharding(%432) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %754 = stablehlo.custom_call @Sharding(%438) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32x128xf32>) -> tensor<2x32x128xf32>
    %755 = stablehlo.custom_call @Sharding(%444) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128xf32>) -> tensor<2x128xf32>
    %756 = stablehlo.custom_call @Sharding(%450) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x128x32xf32>) -> tensor<2x128x32xf32>
    %757 = stablehlo.custom_call @Sharding(%456) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<2x32xf32>) -> tensor<2x32xf32>
    %758 = stablehlo.custom_call @Sharding(%462) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %759 = stablehlo.custom_call @Sharding(%468) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32xf32>) -> tensor<32xf32>
    %760 = stablehlo.custom_call @Sharding(%474) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<50257x32xf32>) -> tensor<50257x32xf32>
    %761 = stablehlo.custom_call @Sharding(%480) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<1024x32xf32>) -> tensor<1024x32xf32>
    %c_70 = stablehlo.constant dense<10> : tensor<i32>
    %762 = call @remainder(%arg0, %c_70) : (tensor<i32>, tensor<i32>) -> tensor<i32>
    %763 = stablehlo.compare  EQ, %762, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %764 = stablehlo.convert %763 : (tensor<i1>) -> tensor<i32>
    %765:58 = "stablehlo.case"(%764) ({
      %cst_71 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      stablehlo.return %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71, %cst_71 : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>
    }, {
      %766 = func.call @norm(%144#16) : (tensor<2x32xf32>) -> tensor<2xf32>
      %767 = func.call @norm(%144#17) : (tensor<2x32xf32>) -> tensor<2xf32>
      %768 = func.call @norm_33(%144#18) : (tensor<2x32x3x4x8xf32>) -> tensor<2xf32>
      %769 = func.call @norm_34(%144#19) : (tensor<2x3x4x8xf32>) -> tensor<2xf32>
      %770 = func.call @norm_35(%144#20) : (tensor<2x4x8x32xf32>) -> tensor<2xf32>
      %771 = func.call @norm(%144#21) : (tensor<2x32xf32>) -> tensor<2xf32>
      %772 = func.call @norm(%144#22) : (tensor<2x32xf32>) -> tensor<2xf32>
      %773 = func.call @norm(%144#23) : (tensor<2x32xf32>) -> tensor<2xf32>
      %774 = func.call @norm_36(%144#24) : (tensor<2x32x128xf32>) -> tensor<2xf32>
      %775 = func.call @norm_37(%144#25) : (tensor<2x128xf32>) -> tensor<2xf32>
      %776 = func.call @norm_38(%144#26) : (tensor<2x128x32xf32>) -> tensor<2xf32>
      %777 = func.call @norm(%144#27) : (tensor<2x32xf32>) -> tensor<2xf32>
      %778 = stablehlo.slice %769 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %779 = stablehlo.reshape %778 : (tensor<1xf32>) -> tensor<f32>
      %780 = stablehlo.slice %769 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %781 = stablehlo.reshape %780 : (tensor<1xf32>) -> tensor<f32>
      %782 = stablehlo.slice %768 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %783 = stablehlo.reshape %782 : (tensor<1xf32>) -> tensor<f32>
      %784 = stablehlo.slice %768 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %785 = stablehlo.reshape %784 : (tensor<1xf32>) -> tensor<f32>
      %786 = stablehlo.slice %771 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %787 = stablehlo.reshape %786 : (tensor<1xf32>) -> tensor<f32>
      %788 = stablehlo.slice %771 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %789 = stablehlo.reshape %788 : (tensor<1xf32>) -> tensor<f32>
      %790 = stablehlo.slice %770 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %791 = stablehlo.reshape %790 : (tensor<1xf32>) -> tensor<f32>
      %792 = stablehlo.slice %770 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %793 = stablehlo.reshape %792 : (tensor<1xf32>) -> tensor<f32>
      %794 = stablehlo.slice %767 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %795 = stablehlo.reshape %794 : (tensor<1xf32>) -> tensor<f32>
      %796 = stablehlo.slice %767 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %797 = stablehlo.reshape %796 : (tensor<1xf32>) -> tensor<f32>
      %798 = stablehlo.slice %766 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %799 = stablehlo.reshape %798 : (tensor<1xf32>) -> tensor<f32>
      %800 = stablehlo.slice %766 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %801 = stablehlo.reshape %800 : (tensor<1xf32>) -> tensor<f32>
      %802 = stablehlo.slice %773 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %803 = stablehlo.reshape %802 : (tensor<1xf32>) -> tensor<f32>
      %804 = stablehlo.slice %773 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %805 = stablehlo.reshape %804 : (tensor<1xf32>) -> tensor<f32>
      %806 = stablehlo.slice %772 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %807 = stablehlo.reshape %806 : (tensor<1xf32>) -> tensor<f32>
      %808 = stablehlo.slice %772 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %809 = stablehlo.reshape %808 : (tensor<1xf32>) -> tensor<f32>
      %810 = stablehlo.slice %775 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %811 = stablehlo.reshape %810 : (tensor<1xf32>) -> tensor<f32>
      %812 = stablehlo.slice %775 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %813 = stablehlo.reshape %812 : (tensor<1xf32>) -> tensor<f32>
      %814 = stablehlo.slice %774 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %815 = stablehlo.reshape %814 : (tensor<1xf32>) -> tensor<f32>
      %816 = stablehlo.slice %774 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %817 = stablehlo.reshape %816 : (tensor<1xf32>) -> tensor<f32>
      %818 = stablehlo.slice %777 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %819 = stablehlo.reshape %818 : (tensor<1xf32>) -> tensor<f32>
      %820 = stablehlo.slice %777 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %821 = stablehlo.reshape %820 : (tensor<1xf32>) -> tensor<f32>
      %822 = stablehlo.slice %776 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %823 = stablehlo.reshape %822 : (tensor<1xf32>) -> tensor<f32>
      %824 = stablehlo.slice %776 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %825 = stablehlo.reshape %824 : (tensor<1xf32>) -> tensor<f32>
      %826 = func.call @norm_39(%149) : (tensor<32xf32>) -> tensor<f32>
      %827 = func.call @norm_39(%115) : (tensor<32xf32>) -> tensor<f32>
      %828 = func.call @norm_40(%148) : (tensor<50257x32xf32>) -> tensor<f32>
      %829 = func.call @norm_41(%146) : (tensor<1024x32xf32>) -> tensor<f32>
      %cst_71 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %830 = stablehlo.add %cst_71, %779 : tensor<f32>
      %831 = stablehlo.add %830, %781 : tensor<f32>
      %832 = stablehlo.add %831, %783 : tensor<f32>
      %833 = stablehlo.add %832, %785 : tensor<f32>
      %834 = stablehlo.add %833, %787 : tensor<f32>
      %835 = stablehlo.add %834, %789 : tensor<f32>
      %836 = stablehlo.add %835, %791 : tensor<f32>
      %837 = stablehlo.add %836, %793 : tensor<f32>
      %838 = stablehlo.add %837, %795 : tensor<f32>
      %839 = stablehlo.add %838, %797 : tensor<f32>
      %840 = stablehlo.add %839, %799 : tensor<f32>
      %841 = stablehlo.add %840, %801 : tensor<f32>
      %842 = stablehlo.add %841, %803 : tensor<f32>
      %843 = stablehlo.add %842, %805 : tensor<f32>
      %844 = stablehlo.add %843, %807 : tensor<f32>
      %845 = stablehlo.add %844, %809 : tensor<f32>
      %846 = stablehlo.add %845, %811 : tensor<f32>
      %847 = stablehlo.add %846, %813 : tensor<f32>
      %848 = stablehlo.add %847, %815 : tensor<f32>
      %849 = stablehlo.add %848, %817 : tensor<f32>
      %850 = stablehlo.add %849, %819 : tensor<f32>
      %851 = stablehlo.add %850, %821 : tensor<f32>
      %852 = stablehlo.add %851, %823 : tensor<f32>
      %853 = stablehlo.add %852, %825 : tensor<f32>
      %854 = stablehlo.add %853, %826 : tensor<f32>
      %855 = stablehlo.add %854, %827 : tensor<f32>
      %856 = stablehlo.add %855, %828 : tensor<f32>
      %857 = stablehlo.add %856, %829 : tensor<f32>
      %858 = func.call @norm(%arg1) : (tensor<2x32xf32>) -> tensor<2xf32>
      %859 = func.call @norm(%arg2) : (tensor<2x32xf32>) -> tensor<2xf32>
      %860 = func.call @norm_33(%arg3) : (tensor<2x32x3x4x8xf32>) -> tensor<2xf32>
      %861 = func.call @norm_34(%arg4) : (tensor<2x3x4x8xf32>) -> tensor<2xf32>
      %862 = func.call @norm_35(%arg5) : (tensor<2x4x8x32xf32>) -> tensor<2xf32>
      %863 = func.call @norm(%arg6) : (tensor<2x32xf32>) -> tensor<2xf32>
      %864 = func.call @norm(%arg7) : (tensor<2x32xf32>) -> tensor<2xf32>
      %865 = func.call @norm(%arg8) : (tensor<2x32xf32>) -> tensor<2xf32>
      %866 = func.call @norm_36(%arg9) : (tensor<2x32x128xf32>) -> tensor<2xf32>
      %867 = func.call @norm_37(%arg10) : (tensor<2x128xf32>) -> tensor<2xf32>
      %868 = func.call @norm_38(%arg11) : (tensor<2x128x32xf32>) -> tensor<2xf32>
      %869 = func.call @norm(%arg12) : (tensor<2x32xf32>) -> tensor<2xf32>
      %870 = stablehlo.slice %861 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %871 = stablehlo.reshape %870 : (tensor<1xf32>) -> tensor<f32>
      %872 = stablehlo.slice %861 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %873 = stablehlo.reshape %872 : (tensor<1xf32>) -> tensor<f32>
      %874 = stablehlo.slice %860 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %875 = stablehlo.reshape %874 : (tensor<1xf32>) -> tensor<f32>
      %876 = stablehlo.slice %860 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %877 = stablehlo.reshape %876 : (tensor<1xf32>) -> tensor<f32>
      %878 = stablehlo.slice %863 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %879 = stablehlo.reshape %878 : (tensor<1xf32>) -> tensor<f32>
      %880 = stablehlo.slice %863 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %881 = stablehlo.reshape %880 : (tensor<1xf32>) -> tensor<f32>
      %882 = stablehlo.slice %862 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %883 = stablehlo.reshape %882 : (tensor<1xf32>) -> tensor<f32>
      %884 = stablehlo.slice %862 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %885 = stablehlo.reshape %884 : (tensor<1xf32>) -> tensor<f32>
      %886 = stablehlo.slice %859 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %887 = stablehlo.reshape %886 : (tensor<1xf32>) -> tensor<f32>
      %888 = stablehlo.slice %859 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %889 = stablehlo.reshape %888 : (tensor<1xf32>) -> tensor<f32>
      %890 = stablehlo.slice %858 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %891 = stablehlo.reshape %890 : (tensor<1xf32>) -> tensor<f32>
      %892 = stablehlo.slice %858 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %893 = stablehlo.reshape %892 : (tensor<1xf32>) -> tensor<f32>
      %894 = stablehlo.slice %865 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %895 = stablehlo.reshape %894 : (tensor<1xf32>) -> tensor<f32>
      %896 = stablehlo.slice %865 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %897 = stablehlo.reshape %896 : (tensor<1xf32>) -> tensor<f32>
      %898 = stablehlo.slice %864 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %899 = stablehlo.reshape %898 : (tensor<1xf32>) -> tensor<f32>
      %900 = stablehlo.slice %864 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %901 = stablehlo.reshape %900 : (tensor<1xf32>) -> tensor<f32>
      %902 = stablehlo.slice %867 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %903 = stablehlo.reshape %902 : (tensor<1xf32>) -> tensor<f32>
      %904 = stablehlo.slice %867 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %905 = stablehlo.reshape %904 : (tensor<1xf32>) -> tensor<f32>
      %906 = stablehlo.slice %866 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %907 = stablehlo.reshape %906 : (tensor<1xf32>) -> tensor<f32>
      %908 = stablehlo.slice %866 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %909 = stablehlo.reshape %908 : (tensor<1xf32>) -> tensor<f32>
      %910 = stablehlo.slice %869 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %911 = stablehlo.reshape %910 : (tensor<1xf32>) -> tensor<f32>
      %912 = stablehlo.slice %869 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %913 = stablehlo.reshape %912 : (tensor<1xf32>) -> tensor<f32>
      %914 = stablehlo.slice %868 [0:1] : (tensor<2xf32>) -> tensor<1xf32>
      %915 = stablehlo.reshape %914 : (tensor<1xf32>) -> tensor<f32>
      %916 = stablehlo.slice %868 [1:2] : (tensor<2xf32>) -> tensor<1xf32>
      %917 = stablehlo.reshape %916 : (tensor<1xf32>) -> tensor<f32>
      %918 = func.call @norm_39(%arg13) : (tensor<32xf32>) -> tensor<f32>
      %919 = func.call @norm_39(%arg14) : (tensor<32xf32>) -> tensor<f32>
      %920 = func.call @norm_40(%arg15) : (tensor<50257x32xf32>) -> tensor<f32>
      %921 = func.call @norm_41(%arg16) : (tensor<1024x32xf32>) -> tensor<f32>
      %922 = stablehlo.add %cst_71, %871 : tensor<f32>
      %923 = stablehlo.add %922, %873 : tensor<f32>
      %924 = stablehlo.add %923, %875 : tensor<f32>
      %925 = stablehlo.add %924, %877 : tensor<f32>
      %926 = stablehlo.add %925, %879 : tensor<f32>
      %927 = stablehlo.add %926, %881 : tensor<f32>
      %928 = stablehlo.add %927, %883 : tensor<f32>
      %929 = stablehlo.add %928, %885 : tensor<f32>
      %930 = stablehlo.add %929, %887 : tensor<f32>
      %931 = stablehlo.add %930, %889 : tensor<f32>
      %932 = stablehlo.add %931, %891 : tensor<f32>
      %933 = stablehlo.add %932, %893 : tensor<f32>
      %934 = stablehlo.add %933, %895 : tensor<f32>
      %935 = stablehlo.add %934, %897 : tensor<f32>
      %936 = stablehlo.add %935, %899 : tensor<f32>
      %937 = stablehlo.add %936, %901 : tensor<f32>
      %938 = stablehlo.add %937, %903 : tensor<f32>
      %939 = stablehlo.add %938, %905 : tensor<f32>
      %940 = stablehlo.add %939, %907 : tensor<f32>
      %941 = stablehlo.add %940, %909 : tensor<f32>
      %942 = stablehlo.add %941, %911 : tensor<f32>
      %943 = stablehlo.add %942, %913 : tensor<f32>
      %944 = stablehlo.add %943, %915 : tensor<f32>
      %945 = stablehlo.add %944, %917 : tensor<f32>
      %946 = stablehlo.add %945, %918 : tensor<f32>
      %947 = stablehlo.add %946, %919 : tensor<f32>
      %948 = stablehlo.add %947, %920 : tensor<f32>
      %949 = stablehlo.add %948, %921 : tensor<f32>
      stablehlo.return %829, %828, %857, %779, %783, %787, %791, %795, %799, %803, %807, %811, %815, %819, %823, %781, %785, %789, %793, %797, %801, %805, %809, %813, %817, %821, %825, %827, %826, %921, %920, %949, %871, %875, %879, %883, %887, %891, %895, %899, %903, %907, %911, %915, %873, %877, %881, %885, %889, %893, %897, %901, %905, %909, %913, %917, %919, %918 : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>
    }) : (tensor<i32>) -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>)
    return %93, %713, %714, %715, %716, %717, %718, %719, %720, %721, %722, %723, %724, %725, %726, %727, %728, %729, %696, %170, %173, %483, %730, %731, %732, %733, %734, %735, %736, %737, %738, %739, %740, %741, %742, %743, %744, %745, %746, %747, %748, %749, %750, %751, %752, %753, %754, %755, %756, %757, %758, %759, %760, %761, %arg52, %765#0, %765#1, %765#2, %765#3, %765#4, %765#5, %765#6, %765#7, %765#8, %765#9, %765#10, %765#11, %765#12, %765#13, %765#14, %765#15, %765#16, %765#17, %765#18, %765#19, %765#20, %765#21, %765#22, %765#23, %765#24, %765#25, %765#26, %765#27, %765#28, %765#29, %765#30, %765#31, %765#32, %765#33, %765#34, %765#35, %765#36, %765#37, %765#38, %765#39, %765#40, %765#41, %765#42, %765#43, %765#44, %765#45, %765#46, %765#47, %765#48, %765#49, %765#50, %765#51, %765#52, %765#53, %765#54, %765#55, %765#56, %765#57 : tensor<f32>, tensor<i32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<50257x32xf32>, tensor<1024x32xf32>, tensor<i32>, tensor<f32>, tensor<i32>, tensor<i32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<50257x32xf32>, tensor<1024x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x3x4x8xf32>, tensor<2x3x4x8xf32>, tensor<2x4x8x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32xf32>, tensor<2x32x128xf32>, tensor<2x128xf32>, tensor<2x128x32xf32>, tensor<2x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<50257x32xf32>, tensor<1024x32xf32>, tensor<2xui32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>
  }
  func.func private @_threefry_split(%arg0: tensor<2xui32>) -> tensor<2x2xui32> {
    %0 = stablehlo.slice %arg0 [0:1] : (tensor<2xui32>) -> tensor<1xui32>
    %1 = stablehlo.reshape %0 : (tensor<1xui32>) -> tensor<ui32>
    %2 = stablehlo.slice %arg0 [1:2] : (tensor<2xui32>) -> tensor<1xui32>
    %3 = stablehlo.reshape %2 : (tensor<1xui32>) -> tensor<ui32>
    %4 = stablehlo.iota dim = 0 : tensor<2xui64>
    %c = stablehlo.constant dense<1> : tensor<ui64>
    %5 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<ui64>) -> tensor<2xui64>
    %6 = stablehlo.multiply %5, %4 : tensor<2xui64>
    %c_0 = stablehlo.constant dense<32> : tensor<ui64>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui64>) -> tensor<2xui64>
    %8 = stablehlo.shift_right_logical %6, %7 : tensor<2xui64>
    %9 = stablehlo.convert %6 : (tensor<2xui64>) -> tensor<2xui32>
    %10 = stablehlo.convert %8 : (tensor<2xui64>) -> tensor<2xui32>
    %11:2 = call @threefry2x32(%1, %3, %10, %9) : (tensor<ui32>, tensor<ui32>, tensor<2xui32>, tensor<2xui32>) -> (tensor<2xui32>, tensor<2xui32>)
    %12 = stablehlo.broadcast_in_dim %11#0, dims = [0] : (tensor<2xui32>) -> tensor<2x1xui32>
    %13 = stablehlo.broadcast_in_dim %11#1, dims = [0] : (tensor<2xui32>) -> tensor<2x1xui32>
    %14 = stablehlo.concatenate %12, %13, dim = 1 : (tensor<2x1xui32>, tensor<2x1xui32>) -> tensor<2x2xui32>
    return %14 : tensor<2x2xui32>
  }
  func.func private @threefry2x32(%arg0: tensor<ui32>, %arg1: tensor<ui32>, %arg2: tensor<2xui32>, %arg3: tensor<2xui32>) -> (tensor<2xui32>, tensor<2xui32>) {
    %0 = stablehlo.xor %arg0, %arg1 : tensor<ui32>
    %c = stablehlo.constant dense<466688986> : tensor<ui32>
    %1 = stablehlo.xor %0, %c : tensor<ui32>
    %2 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %3 = stablehlo.add %arg2, %2 : tensor<2xui32>
    %4 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %5 = stablehlo.add %arg3, %4 : tensor<2xui32>
    %6 = stablehlo.add %3, %5 : tensor<2xui32>
    %c_0 = stablehlo.constant dense<13> : tensor<ui32>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %8 = stablehlo.shift_left %5, %7 : tensor<2xui32>
    %c_1 = stablehlo.constant dense<19> : tensor<ui32>
    %9 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %10 = stablehlo.shift_right_logical %5, %9 : tensor<2xui32>
    %11 = stablehlo.or %8, %10 : tensor<2xui32>
    %12 = stablehlo.xor %6, %11 : tensor<2xui32>
    %13 = stablehlo.add %6, %12 : tensor<2xui32>
    %c_2 = stablehlo.constant dense<15> : tensor<ui32>
    %14 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %15 = stablehlo.shift_left %12, %14 : tensor<2xui32>
    %c_3 = stablehlo.constant dense<17> : tensor<ui32>
    %16 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %17 = stablehlo.shift_right_logical %12, %16 : tensor<2xui32>
    %18 = stablehlo.or %15, %17 : tensor<2xui32>
    %19 = stablehlo.xor %13, %18 : tensor<2xui32>
    %20 = stablehlo.add %13, %19 : tensor<2xui32>
    %c_4 = stablehlo.constant dense<26> : tensor<ui32>
    %21 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %22 = stablehlo.shift_left %19, %21 : tensor<2xui32>
    %c_5 = stablehlo.constant dense<6> : tensor<ui32>
    %23 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %24 = stablehlo.shift_right_logical %19, %23 : tensor<2xui32>
    %25 = stablehlo.or %22, %24 : tensor<2xui32>
    %26 = stablehlo.xor %20, %25 : tensor<2xui32>
    %27 = stablehlo.add %20, %26 : tensor<2xui32>
    %28 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %29 = stablehlo.shift_left %26, %28 : tensor<2xui32>
    %30 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %31 = stablehlo.shift_right_logical %26, %30 : tensor<2xui32>
    %32 = stablehlo.or %29, %31 : tensor<2xui32>
    %33 = stablehlo.xor %27, %32 : tensor<2xui32>
    %34 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %35 = stablehlo.add %27, %34 : tensor<2xui32>
    %36 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %37 = stablehlo.add %33, %36 : tensor<2xui32>
    %c_6 = stablehlo.constant dense<1> : tensor<ui32>
    %38 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %39 = stablehlo.add %37, %38 : tensor<2xui32>
    %40 = stablehlo.add %35, %39 : tensor<2xui32>
    %41 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %42 = stablehlo.shift_left %39, %41 : tensor<2xui32>
    %43 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %44 = stablehlo.shift_right_logical %39, %43 : tensor<2xui32>
    %45 = stablehlo.or %42, %44 : tensor<2xui32>
    %46 = stablehlo.xor %40, %45 : tensor<2xui32>
    %47 = stablehlo.add %40, %46 : tensor<2xui32>
    %c_7 = stablehlo.constant dense<29> : tensor<ui32>
    %48 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %49 = stablehlo.shift_left %46, %48 : tensor<2xui32>
    %c_8 = stablehlo.constant dense<3> : tensor<ui32>
    %50 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %51 = stablehlo.shift_right_logical %46, %50 : tensor<2xui32>
    %52 = stablehlo.or %49, %51 : tensor<2xui32>
    %53 = stablehlo.xor %47, %52 : tensor<2xui32>
    %54 = stablehlo.add %47, %53 : tensor<2xui32>
    %c_9 = stablehlo.constant dense<16> : tensor<ui32>
    %55 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %56 = stablehlo.shift_left %53, %55 : tensor<2xui32>
    %57 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %58 = stablehlo.shift_right_logical %53, %57 : tensor<2xui32>
    %59 = stablehlo.or %56, %58 : tensor<2xui32>
    %60 = stablehlo.xor %54, %59 : tensor<2xui32>
    %61 = stablehlo.add %54, %60 : tensor<2xui32>
    %c_10 = stablehlo.constant dense<24> : tensor<ui32>
    %62 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %63 = stablehlo.shift_left %60, %62 : tensor<2xui32>
    %c_11 = stablehlo.constant dense<8> : tensor<ui32>
    %64 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %65 = stablehlo.shift_right_logical %60, %64 : tensor<2xui32>
    %66 = stablehlo.or %63, %65 : tensor<2xui32>
    %67 = stablehlo.xor %61, %66 : tensor<2xui32>
    %68 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %69 = stablehlo.add %61, %68 : tensor<2xui32>
    %70 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %71 = stablehlo.add %67, %70 : tensor<2xui32>
    %c_12 = stablehlo.constant dense<2> : tensor<ui32>
    %72 = stablehlo.broadcast_in_dim %c_12, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %73 = stablehlo.add %71, %72 : tensor<2xui32>
    %74 = stablehlo.add %69, %73 : tensor<2xui32>
    %75 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %76 = stablehlo.shift_left %73, %75 : tensor<2xui32>
    %77 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %78 = stablehlo.shift_right_logical %73, %77 : tensor<2xui32>
    %79 = stablehlo.or %76, %78 : tensor<2xui32>
    %80 = stablehlo.xor %74, %79 : tensor<2xui32>
    %81 = stablehlo.add %74, %80 : tensor<2xui32>
    %82 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %83 = stablehlo.shift_left %80, %82 : tensor<2xui32>
    %84 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %85 = stablehlo.shift_right_logical %80, %84 : tensor<2xui32>
    %86 = stablehlo.or %83, %85 : tensor<2xui32>
    %87 = stablehlo.xor %81, %86 : tensor<2xui32>
    %88 = stablehlo.add %81, %87 : tensor<2xui32>
    %89 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %90 = stablehlo.shift_left %87, %89 : tensor<2xui32>
    %91 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %92 = stablehlo.shift_right_logical %87, %91 : tensor<2xui32>
    %93 = stablehlo.or %90, %92 : tensor<2xui32>
    %94 = stablehlo.xor %88, %93 : tensor<2xui32>
    %95 = stablehlo.add %88, %94 : tensor<2xui32>
    %96 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %97 = stablehlo.shift_left %94, %96 : tensor<2xui32>
    %98 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %99 = stablehlo.shift_right_logical %94, %98 : tensor<2xui32>
    %100 = stablehlo.or %97, %99 : tensor<2xui32>
    %101 = stablehlo.xor %95, %100 : tensor<2xui32>
    %102 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %103 = stablehlo.add %95, %102 : tensor<2xui32>
    %104 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %105 = stablehlo.add %101, %104 : tensor<2xui32>
    %106 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %107 = stablehlo.add %105, %106 : tensor<2xui32>
    %108 = stablehlo.add %103, %107 : tensor<2xui32>
    %109 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %110 = stablehlo.shift_left %107, %109 : tensor<2xui32>
    %111 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %112 = stablehlo.shift_right_logical %107, %111 : tensor<2xui32>
    %113 = stablehlo.or %110, %112 : tensor<2xui32>
    %114 = stablehlo.xor %108, %113 : tensor<2xui32>
    %115 = stablehlo.add %108, %114 : tensor<2xui32>
    %116 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %117 = stablehlo.shift_left %114, %116 : tensor<2xui32>
    %118 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %119 = stablehlo.shift_right_logical %114, %118 : tensor<2xui32>
    %120 = stablehlo.or %117, %119 : tensor<2xui32>
    %121 = stablehlo.xor %115, %120 : tensor<2xui32>
    %122 = stablehlo.add %115, %121 : tensor<2xui32>
    %123 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %124 = stablehlo.shift_left %121, %123 : tensor<2xui32>
    %125 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %126 = stablehlo.shift_right_logical %121, %125 : tensor<2xui32>
    %127 = stablehlo.or %124, %126 : tensor<2xui32>
    %128 = stablehlo.xor %122, %127 : tensor<2xui32>
    %129 = stablehlo.add %122, %128 : tensor<2xui32>
    %130 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %131 = stablehlo.shift_left %128, %130 : tensor<2xui32>
    %132 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %133 = stablehlo.shift_right_logical %128, %132 : tensor<2xui32>
    %134 = stablehlo.or %131, %133 : tensor<2xui32>
    %135 = stablehlo.xor %129, %134 : tensor<2xui32>
    %136 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %137 = stablehlo.add %129, %136 : tensor<2xui32>
    %138 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %139 = stablehlo.add %135, %138 : tensor<2xui32>
    %c_13 = stablehlo.constant dense<4> : tensor<ui32>
    %140 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %141 = stablehlo.add %139, %140 : tensor<2xui32>
    %142 = stablehlo.add %137, %141 : tensor<2xui32>
    %143 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %144 = stablehlo.shift_left %141, %143 : tensor<2xui32>
    %145 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %146 = stablehlo.shift_right_logical %141, %145 : tensor<2xui32>
    %147 = stablehlo.or %144, %146 : tensor<2xui32>
    %148 = stablehlo.xor %142, %147 : tensor<2xui32>
    %149 = stablehlo.add %142, %148 : tensor<2xui32>
    %150 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %151 = stablehlo.shift_left %148, %150 : tensor<2xui32>
    %152 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %153 = stablehlo.shift_right_logical %148, %152 : tensor<2xui32>
    %154 = stablehlo.or %151, %153 : tensor<2xui32>
    %155 = stablehlo.xor %149, %154 : tensor<2xui32>
    %156 = stablehlo.add %149, %155 : tensor<2xui32>
    %157 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %158 = stablehlo.shift_left %155, %157 : tensor<2xui32>
    %159 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %160 = stablehlo.shift_right_logical %155, %159 : tensor<2xui32>
    %161 = stablehlo.or %158, %160 : tensor<2xui32>
    %162 = stablehlo.xor %156, %161 : tensor<2xui32>
    %163 = stablehlo.add %156, %162 : tensor<2xui32>
    %164 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %165 = stablehlo.shift_left %162, %164 : tensor<2xui32>
    %166 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %167 = stablehlo.shift_right_logical %162, %166 : tensor<2xui32>
    %168 = stablehlo.or %165, %167 : tensor<2xui32>
    %169 = stablehlo.xor %163, %168 : tensor<2xui32>
    %170 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %171 = stablehlo.add %163, %170 : tensor<2xui32>
    %172 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %173 = stablehlo.add %169, %172 : tensor<2xui32>
    %c_14 = stablehlo.constant dense<5> : tensor<ui32>
    %174 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<ui32>) -> tensor<2xui32>
    %175 = stablehlo.add %173, %174 : tensor<2xui32>
    return %171, %175 : tensor<2xui32>, tensor<2xui32>
  }
  func.func private @_take(%arg0: tensor<50257x32xf32>, %arg1: tensor<32x1024xi32>) -> (tensor<32x1024x32xf32>, tensor<32x1024x1xi32>) {
    %c = stablehlo.constant dense<0> : tensor<i32>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i32>) -> tensor<32x1024xi32>
    %1 = stablehlo.compare  LT, %arg1, %0,  SIGNED : (tensor<32x1024xi32>, tensor<32x1024xi32>) -> tensor<32x1024xi1>
    %c_0 = stablehlo.constant dense<50257> : tensor<i32>
    %2 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<i32>) -> tensor<32x1024xi32>
    %3 = stablehlo.add %arg1, %2 : tensor<32x1024xi32>
    %4 = call @_where(%1, %3, %arg1) : (tensor<32x1024xi1>, tensor<32x1024xi32>, tensor<32x1024xi32>) -> tensor<32x1024xi32>
    %5 = stablehlo.broadcast_in_dim %4, dims = [0, 1] : (tensor<32x1024xi32>) -> tensor<32x1024x1xi32>
    %c_1 = stablehlo.constant dense<50256> : tensor<1xi32>
    %c_2 = stablehlo.constant dense<0> : tensor<i32>
    %6 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i32>) -> tensor<32x1024x1xi32>
    %7 = stablehlo.compare  GE, %5, %6,  SIGNED : (tensor<32x1024x1xi32>, tensor<32x1024x1xi32>) -> tensor<32x1024x1xi1>
    %8 = stablehlo.broadcast_in_dim %c_1, dims = [2] : (tensor<1xi32>) -> tensor<1x1x1xi32>
    %9 = stablehlo.broadcast_in_dim %8, dims = [0, 1, 2] : (tensor<1x1x1xi32>) -> tensor<32x1024x1xi32>
    %10 = stablehlo.compare  LE, %5, %9,  SIGNED : (tensor<32x1024x1xi32>, tensor<32x1024x1xi32>) -> tensor<32x1024x1xi1>
    %11 = stablehlo.and %7, %10 : tensor<32x1024x1xi1>
    %c_3 = stablehlo.constant dense<true> : tensor<i1>
    %12 = stablehlo.reduce(%11 init: %c_3) applies stablehlo.and across dimensions = [2] : (tensor<32x1024x1xi1>, tensor<i1>) -> tensor<32x1024xi1>
    %13 = "stablehlo.gather"(%arg0, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [2], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 2>, indices_are_sorted = false, slice_sizes = array<i64: 1, 32>}> : (tensor<50257x32xf32>, tensor<32x1024x1xi32>) -> tensor<32x1024x32xf32>
    %14 = stablehlo.broadcast_in_dim %12, dims = [0, 1] : (tensor<32x1024xi1>) -> tensor<32x1024x32xi1>
    %cst = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %15 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024x32xf32>
    %16 = stablehlo.select %14, %13, %15 : tensor<32x1024x32xi1>, tensor<32x1024x32xf32>
    return %16, %5 : tensor<32x1024x32xf32>, tensor<32x1024x1xi32>
  }
  func.func private @_where(%arg0: tensor<32x1024xi1>, %arg1: tensor<32x1024xi32>, %arg2: tensor<32x1024xi32>) -> tensor<32x1024xi32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<32x1024xi1>, tensor<32x1024xi32>
    return %0 : tensor<32x1024xi32>
  }
  func.func private @_take_0(%arg0: tensor<1024x32xf32>, %arg1: tensor<1024xi32>) -> (tensor<1024x32xf32>, tensor<1024x1xi32>) {
    %c = stablehlo.constant dense<0> : tensor<i32>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i32>) -> tensor<1024xi32>
    %1 = stablehlo.compare  LT, %arg1, %0,  SIGNED : (tensor<1024xi32>, tensor<1024xi32>) -> tensor<1024xi1>
    %c_0 = stablehlo.constant dense<1024> : tensor<i32>
    %2 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<i32>) -> tensor<1024xi32>
    %3 = stablehlo.add %arg1, %2 : tensor<1024xi32>
    %4 = call @_where_1(%1, %3, %arg1) : (tensor<1024xi1>, tensor<1024xi32>, tensor<1024xi32>) -> tensor<1024xi32>
    %5 = stablehlo.broadcast_in_dim %4, dims = [0] : (tensor<1024xi32>) -> tensor<1024x1xi32>
    %c_1 = stablehlo.constant dense<1023> : tensor<1xi32>
    %c_2 = stablehlo.constant dense<0> : tensor<i32>
    %6 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i32>) -> tensor<1024x1xi32>
    %7 = stablehlo.compare  GE, %5, %6,  SIGNED : (tensor<1024x1xi32>, tensor<1024x1xi32>) -> tensor<1024x1xi1>
    %8 = stablehlo.broadcast_in_dim %c_1, dims = [1] : (tensor<1xi32>) -> tensor<1x1xi32>
    %9 = stablehlo.broadcast_in_dim %8, dims = [0, 1] : (tensor<1x1xi32>) -> tensor<1024x1xi32>
    %10 = stablehlo.compare  LE, %5, %9,  SIGNED : (tensor<1024x1xi32>, tensor<1024x1xi32>) -> tensor<1024x1xi1>
    %11 = stablehlo.and %7, %10 : tensor<1024x1xi1>
    %c_3 = stablehlo.constant dense<true> : tensor<i1>
    %12 = stablehlo.reduce(%11 init: %c_3) applies stablehlo.and across dimensions = [1] : (tensor<1024x1xi1>, tensor<i1>) -> tensor<1024xi1>
    %13 = "stablehlo.gather"(%arg0, %5) <{dimension_numbers = #stablehlo.gather<offset_dims = [1], collapsed_slice_dims = [0], start_index_map = [0], index_vector_dim = 1>, indices_are_sorted = false, slice_sizes = array<i64: 1, 32>}> : (tensor<1024x32xf32>, tensor<1024x1xi32>) -> tensor<1024x32xf32>
    %14 = stablehlo.broadcast_in_dim %12, dims = [0] : (tensor<1024xi1>) -> tensor<1024x32xi1>
    %cst = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %15 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %16 = stablehlo.select %14, %13, %15 : tensor<1024x32xi1>, tensor<1024x32xf32>
    return %16, %5 : tensor<1024x32xf32>, tensor<1024x1xi32>
  }
  func.func private @_where_1(%arg0: tensor<1024xi1>, %arg1: tensor<1024xi32>, %arg2: tensor<1024xi32>) -> tensor<1024xi32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<1024xi1>, tensor<1024xi32>
    return %0 : tensor<1024xi32>
  }
  func.func private @_var(%arg0: tensor<i32>) -> (tensor<f32>, tensor<i1>, tensor<32x1024xf32>) {
    %0 = stablehlo.convert %arg0 : (tensor<i32>) -> tensor<f32>
    %cst = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %1 = stablehlo.subtract %cst, %0 : tensor<f32>
    %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2 = stablehlo.compare  GT, %1, %cst_0,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %cst_1 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %3 = call @_where_2(%cst_1) : (tensor<f32>) -> tensor<32x1024xf32>
    return %1, %2, %3 : tensor<f32>, tensor<i1>, tensor<32x1024xf32>
  }
  func.func private @_where_2(%arg0: tensor<f32>) -> tensor<32x1024xf32> {
    %0 = stablehlo.convert %arg0 : tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    return %1 : tensor<32x1024xf32>
  }
  func.func private @_take_3(%arg0: tensor<i32>) -> tensor<1xi32> {
    %c = stablehlo.constant dense<0> : tensor<i32>
    %0 = stablehlo.compare  LT, %arg0, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %c_0 = stablehlo.constant dense<3> : tensor<i32>
    %1 = stablehlo.add %arg0, %c_0 : tensor<i32>
    %2 = call @_where_4(%0, %1, %arg0) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [] : (tensor<i32>) -> tensor<1xi32>
    return %3 : tensor<1xi32>
  }
  func.func private @_where_4(%arg0: tensor<i1>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<i32>
    return %0 : tensor<i32>
  }
  func.func private @None(%arg0: tensor<f32>, %arg1: tensor<i1>, %arg2: tensor<32x1024xf32>, %arg3: tensor<1xi32>, %arg4: tensor<1xi32>, %arg5: tensor<1xi32>, %arg6: tensor<32x1024xi32>, %arg7: tensor<32x4x1024x8xf32>, %arg8: tensor<32x4x1024xf32>, %arg9: tensor<f32>, %arg10: tensor<i1>, %arg11: tensor<32x1024xf32>, %arg12: tensor<32x1024x32xf32>, %arg13: tensor<32xf32>, %arg14: tensor<32xf32>, %arg15: tensor<32x3x4x8xf32>, %arg16: tensor<3x4x8xf32>, %arg17: tensor<4x8x32xf32>, %arg18: tensor<32xf32>, %arg19: tensor<32xf32>, %arg20: tensor<32xf32>, %arg21: tensor<32x128xf32>, %arg22: tensor<128xf32>, %arg23: tensor<128x32xf32>, %arg24: tensor<32xf32>) -> (tensor<32x1024x32xf32>, tensor<32x1024x32xf32>) {
    %0 = stablehlo.broadcast_in_dim %arg19, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %1 = stablehlo.broadcast_in_dim %arg13, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %2 = stablehlo.reduce(%arg12 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %3 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %4 = stablehlo.divide %2, %3 : tensor<32x1024xf32>
    %5 = stablehlo.broadcast_in_dim %4, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %6 = stablehlo.transpose %5, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %7 = stablehlo.subtract %arg12, %6 : tensor<32x1024x32xf32>
    %8 = call @_var_5(%arg12, %arg0, %arg1, %arg2) : (tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %cst_1 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %9 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %10 = stablehlo.add %8, %9 : tensor<32x1024xf32>
    %11 = stablehlo.rsqrt %10 : tensor<32x1024xf32>
    %12 = stablehlo.broadcast_in_dim %11, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %13 = stablehlo.transpose %12, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %14 = stablehlo.multiply %7, %13 : tensor<32x1024x32xf32>
    %15 = stablehlo.multiply %1, %14 : tensor<32x1024x32xf32>
    %16 = stablehlo.broadcast_in_dim %arg14, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %17 = stablehlo.add %15, %16 : tensor<32x1024x32xf32>
    %18 = stablehlo.dot_general %17, %arg15, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %19 = stablehlo.custom_call @Sharding(%18) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %20 = stablehlo.custom_call @Sharding(%19) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %21 = stablehlo.broadcast_in_dim %arg16, dims = [2, 3, 4] : (tensor<3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %22 = stablehlo.add %20, %21 : tensor<32x1024x3x4x8xf32>
    %23 = stablehlo.custom_call @Sharding(%22) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %24 = stablehlo.transpose %23, dims = [0, 2, 3, 1, 4] : (tensor<32x1024x3x4x8xf32>) -> tensor<32x3x4x1024x8xf32>
    %25 = call @_take_7(%24, %arg3) : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>) -> tensor<32x4x1024x8xf32>
    %26 = stablehlo.custom_call @Sharding(%25) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %cst_2 = stablehlo.constant dense<2.82842708> : tensor<f32>
    %27 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %28 = stablehlo.divide %26, %27 : tensor<32x4x1024x8xf32>
    %29 = call @_take_7(%24, %arg4) : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>) -> tensor<32x4x1024x8xf32>
    %30 = stablehlo.custom_call @Sharding(%29) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %31 = call @_take_7(%24, %arg5) : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>) -> tensor<32x4x1024x8xf32>
    %32 = stablehlo.custom_call @Sharding(%31) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %c = stablehlo.constant dense<0> : tensor<i32>
    %33:7 = stablehlo.while(%iterArg = %28, %iterArg_8 = %30, %iterArg_9 = %32, %iterArg_10 = %arg6, %iterArg_11 = %c, %iterArg_12 = %arg7, %iterArg_13 = %arg8) : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>
     cond {
      %c_14 = stablehlo.constant dense<1> : tensor<i32>
      %83 = stablehlo.compare  LT, %iterArg_11, %c_14,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      stablehlo.return %83 : tensor<i1>
    } do {
      %c_14 = stablehlo.constant dense<1024> : tensor<i32>
      %83 = stablehlo.multiply %iterArg_11, %c_14 : tensor<i32>
      %c_15 = stablehlo.constant dense<0> : tensor<i32>
      %84 = stablehlo.compare  LT, %83, %c_15,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %85 = stablehlo.convert %83 : tensor<i32>
      %c_16 = stablehlo.constant dense<1024> : tensor<i32>
      %86 = stablehlo.add %85, %c_16 : tensor<i32>
      %87 = stablehlo.select %84, %86, %83 : tensor<i1>, tensor<i32>
      %c_17 = stablehlo.constant dense<0> : tensor<i32>
      %88 = stablehlo.dynamic_slice %iterArg, %c_17, %c_17, %87, %c_17, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %89 = stablehlo.multiply %iterArg_11, %c_14 : tensor<i32>
      %90 = stablehlo.compare  LT, %89, %c_15,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %91 = stablehlo.convert %89 : tensor<i32>
      %92 = stablehlo.add %91, %c_16 : tensor<i32>
      %93 = stablehlo.select %90, %92, %89 : tensor<i1>, tensor<i32>
      %94 = stablehlo.dynamic_slice %iterArg_12, %c_17, %c_17, %93, %c_17, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %cst_18 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %95 = stablehlo.broadcast_in_dim %cst_18, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
      %cst_19 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %96 = stablehlo.broadcast_in_dim %cst_19, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
      %c_20 = stablehlo.constant dense<1> : tensor<i32>
      %97 = stablehlo.add %iterArg_11, %c_20 : tensor<i32>
      %98 = stablehlo.minimum %97, %c_20 : tensor<i32>
      %99:10 = stablehlo.while(%iterArg_21 = %98, %iterArg_22 = %iterArg_11, %iterArg_23 = %88, %iterArg_24 = %iterArg_8, %iterArg_25 = %iterArg_9, %iterArg_26 = %iterArg_10, %iterArg_27 = %c_15, %iterArg_28 = %94, %iterArg_29 = %95, %iterArg_30 = %96) : tensor<i32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>
       cond {
        %118 = stablehlo.compare  LT, %iterArg_27, %iterArg_21,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        stablehlo.return %118 : tensor<i1>
      } do {
        %c_31 = stablehlo.constant dense<1024> : tensor<i32>
        %118 = stablehlo.multiply %iterArg_27, %c_31 : tensor<i32>
        %c_32 = stablehlo.constant dense<0> : tensor<i32>
        %119 = stablehlo.compare  LT, %118, %c_32,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %120 = stablehlo.convert %118 : tensor<i32>
        %c_33 = stablehlo.constant dense<1024> : tensor<i32>
        %121 = stablehlo.add %120, %c_33 : tensor<i32>
        %122 = stablehlo.select %119, %121, %118 : tensor<i1>, tensor<i32>
        %c_34 = stablehlo.constant dense<0> : tensor<i32>
        %123 = stablehlo.dynamic_slice %iterArg_24, %c_34, %c_34, %122, %c_34, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %124 = stablehlo.multiply %iterArg_27, %c_31 : tensor<i32>
        %125 = stablehlo.compare  LT, %124, %c_32,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %126 = stablehlo.convert %124 : tensor<i32>
        %127 = stablehlo.add %126, %c_33 : tensor<i32>
        %128 = stablehlo.select %125, %127, %124 : tensor<i1>, tensor<i32>
        %129 = stablehlo.dynamic_slice %iterArg_25, %c_34, %c_34, %128, %c_34, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %130 = stablehlo.dot_general %iterArg_23, %123, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [3], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x1024xf32>
        %131 = stablehlo.custom_call @Sharding(%130) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %132 = stablehlo.multiply %iterArg_22, %c_31 : tensor<i32>
        %133 = stablehlo.multiply %iterArg_27, %c_31 : tensor<i32>
        %134 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %c_35 = stablehlo.constant dense<1> : tensor<i32>
        %135 = stablehlo.broadcast_in_dim %c_35, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %136 = stablehlo.multiply %134, %135 : tensor<1024xi32>
        %137 = stablehlo.convert %132 : tensor<i32>
        %138 = stablehlo.broadcast_in_dim %137, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %139 = stablehlo.add %136, %138 : tensor<1024xi32>
        %140 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %141 = stablehlo.broadcast_in_dim %c_35, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %142 = stablehlo.multiply %140, %141 : tensor<1024xi32>
        %143 = stablehlo.convert %133 : tensor<i32>
        %144 = stablehlo.broadcast_in_dim %143, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %145 = stablehlo.add %142, %144 : tensor<1024xi32>
        %146 = stablehlo.broadcast_in_dim %145, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %147 = stablehlo.broadcast_in_dim %139, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %148 = stablehlo.transpose %147, dims = [1, 0] : (tensor<1024x1024xi32>) -> tensor<1024x1024xi32>
        %149 = stablehlo.compare  GE, %148, %146,  SIGNED : (tensor<1024x1024xi32>, tensor<1024x1024xi32>) -> tensor<1024x1024xi1>
        %150 = stablehlo.compare  LT, %133, %c_32,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %151 = stablehlo.convert %133 : tensor<i32>
        %152 = stablehlo.add %151, %c_33 : tensor<i32>
        %153 = stablehlo.select %150, %152, %133 : tensor<i1>, tensor<i32>
        %154 = stablehlo.dynamic_slice %iterArg_26, %c_34, %153, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %155 = stablehlo.compare  LT, %132, %c_32,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %156 = stablehlo.convert %132 : tensor<i32>
        %157 = stablehlo.add %156, %c_33 : tensor<i32>
        %158 = stablehlo.select %155, %157, %132 : tensor<i1>, tensor<i32>
        %159 = stablehlo.dynamic_slice %iterArg_26, %c_34, %158, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %160 = stablehlo.broadcast_in_dim %159, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %161 = stablehlo.broadcast_in_dim %154, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %162 = stablehlo.transpose %161, dims = [2, 1, 0] : (tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi32>
        %163 = stablehlo.compare  EQ, %160, %162,  SIGNED : (tensor<1024x32x1024xi32>, tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi1>
        %164 = stablehlo.transpose %163, dims = [2, 0, 1] : (tensor<1024x32x1024xi1>) -> tensor<1024x1024x32xi1>
        %165 = stablehlo.broadcast_in_dim %149, dims = [1, 2] : (tensor<1024x1024xi1>) -> tensor<32x1024x1024xi1>
        %166 = stablehlo.transpose %165, dims = [1, 2, 0] : (tensor<32x1024x1024xi1>) -> tensor<1024x1024x32xi1>
        %167 = stablehlo.and %166, %164 : tensor<1024x1024x32xi1>
        %168 = stablehlo.broadcast_in_dim %167, dims = [1, 2, 3] : (tensor<1024x1024x32xi1>) -> tensor<4x1024x1024x32xi1>
        %169 = stablehlo.transpose %168, dims = [3, 0, 1, 2] : (tensor<4x1024x1024x32xi1>) -> tensor<32x4x1024x1024xi1>
        %cst_36 = stablehlo.constant dense<-1.000000e+10> : tensor<f32>
        %170 = func.call @_where_8(%169, %131, %cst_36) : (tensor<32x4x1024x1024xi1>, tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024x1024xf32>
        %cst_37 = stablehlo.constant dense<0xFF800000> : tensor<f32>
        %171 = stablehlo.reduce(%170 init: %cst_37) applies stablehlo.maximum across dimensions = [3] : (tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024xf32>
        %172 = stablehlo.maximum %iterArg_30, %171 : tensor<32x4x1024xf32>
        %173 = stablehlo.broadcast_in_dim %172, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<1024x32x4x1024xf32>
        %174 = stablehlo.transpose %173, dims = [1, 2, 3, 0] : (tensor<1024x32x4x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %175 = stablehlo.subtract %170, %174 : tensor<32x4x1024x1024xf32>
        %176 = stablehlo.exponential %175 : tensor<32x4x1024x1024xf32>
        %177 = stablehlo.subtract %iterArg_30, %172 : tensor<32x4x1024xf32>
        %178 = stablehlo.exponential %177 : tensor<32x4x1024xf32>
        %179 = stablehlo.multiply %178, %iterArg_29 : tensor<32x4x1024xf32>
        %cst_38 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
        %180 = stablehlo.reduce(%176 init: %cst_38) applies stablehlo.add across dimensions = [3] : (tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024xf32>
        %181 = stablehlo.add %179, %180 : tensor<32x4x1024xf32>
        %182 = stablehlo.broadcast_in_dim %178, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<8x32x4x1024xf32>
        %183 = stablehlo.transpose %182, dims = [1, 2, 3, 0] : (tensor<8x32x4x1024xf32>) -> tensor<32x4x1024x8xf32>
        %184 = stablehlo.multiply %183, %iterArg_28 : tensor<32x4x1024x8xf32>
        %185 = stablehlo.dot_general %176, %129, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x1024xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %186 = stablehlo.custom_call @Sharding(%185) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %187 = stablehlo.add %184, %186 : tensor<32x4x1024x8xf32>
        %c_39 = stablehlo.constant dense<1> : tensor<i32>
        %188 = stablehlo.add %iterArg_27, %c_39 : tensor<i32>
        stablehlo.return %iterArg_21, %iterArg_22, %iterArg_23, %iterArg_24, %iterArg_25, %iterArg_26, %188, %187, %181, %172 : tensor<i32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>
      }
      %100 = stablehlo.broadcast_in_dim %99#8, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<8x32x4x1024xf32>
      %101 = stablehlo.transpose %100, dims = [1, 2, 3, 0] : (tensor<8x32x4x1024xf32>) -> tensor<32x4x1024x8xf32>
      %102 = stablehlo.divide %99#7, %101 : tensor<32x4x1024x8xf32>
      %103 = stablehlo.log %99#8 : tensor<32x4x1024xf32>
      %104 = stablehlo.add %99#9, %103 : tensor<32x4x1024xf32>
      %105 = stablehlo.multiply %iterArg_11, %c_14 : tensor<i32>
      %106 = stablehlo.compare  LT, %105, %c_15,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %107 = stablehlo.convert %105 : tensor<i32>
      %108 = stablehlo.add %107, %c_16 : tensor<i32>
      %109 = stablehlo.select %106, %108, %105 : tensor<i1>, tensor<i32>
      %110 = stablehlo.dynamic_update_slice %iterArg_12, %102, %c_17, %c_17, %109, %c_17 : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %111 = stablehlo.multiply %iterArg_11, %c_14 : tensor<i32>
      %112 = stablehlo.compare  LT, %111, %c_15,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %113 = stablehlo.convert %111 : tensor<i32>
      %114 = stablehlo.add %113, %c_16 : tensor<i32>
      %115 = stablehlo.select %112, %114, %111 : tensor<i1>, tensor<i32>
      %116 = stablehlo.dynamic_update_slice %iterArg_13, %104, %c_17, %c_17, %115 : (tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024xf32>
      %117 = stablehlo.add %iterArg_11, %c_20 : tensor<i32>
      stablehlo.return %iterArg, %iterArg_8, %iterArg_9, %iterArg_10, %117, %110, %116 : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>
    }
    %34 = stablehlo.dot_general %33#5, %arg17, contracting_dims = [1, 3] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<4x8x32xf32>) -> tensor<32x1024x32xf32>
    %35 = stablehlo.custom_call @Sharding(%34) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %36 = stablehlo.custom_call @Sharding(%35) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %37 = stablehlo.broadcast_in_dim %arg18, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %38 = stablehlo.add %36, %37 : tensor<32x1024x32xf32>
    %39 = stablehlo.custom_call @Sharding(%38) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %40 = stablehlo.add %arg12, %39 : tensor<32x1024x32xf32>
    %cst_3 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %41 = stablehlo.reduce(%40 init: %cst_3) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %42 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %43 = stablehlo.divide %41, %42 : tensor<32x1024xf32>
    %44 = stablehlo.broadcast_in_dim %43, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %45 = stablehlo.transpose %44, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %46 = stablehlo.subtract %40, %45 : tensor<32x1024x32xf32>
    %47 = call @_var_5(%40, %arg9, %arg10, %arg11) : (tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %48 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %49 = stablehlo.add %47, %48 : tensor<32x1024xf32>
    %50 = stablehlo.rsqrt %49 : tensor<32x1024xf32>
    %51 = stablehlo.broadcast_in_dim %50, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %52 = stablehlo.transpose %51, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %53 = stablehlo.multiply %46, %52 : tensor<32x1024x32xf32>
    %54 = stablehlo.multiply %0, %53 : tensor<32x1024x32xf32>
    %55 = stablehlo.broadcast_in_dim %arg20, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %56 = stablehlo.add %54, %55 : tensor<32x1024x32xf32>
    %57 = stablehlo.dot_general %56, %arg21, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x128xf32>) -> tensor<32x1024x128xf32>
    %58 = stablehlo.custom_call @Sharding(%57) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %59 = stablehlo.custom_call @Sharding(%58) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %60 = stablehlo.broadcast_in_dim %arg22, dims = [2] : (tensor<128xf32>) -> tensor<32x1024x128xf32>
    %61 = stablehlo.add %59, %60 : tensor<32x1024x128xf32>
    %62 = stablehlo.custom_call @Sharding(%61) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %63 = stablehlo.multiply %62, %62 : tensor<32x1024x128xf32>
    %64 = stablehlo.multiply %63, %62 : tensor<32x1024x128xf32>
    %cst_4 = stablehlo.constant dense<4.471500e-02> : tensor<f32>
    %65 = stablehlo.broadcast_in_dim %cst_4, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %66 = stablehlo.multiply %65, %64 : tensor<32x1024x128xf32>
    %67 = stablehlo.add %62, %66 : tensor<32x1024x128xf32>
    %cst_5 = stablehlo.constant dense<0.797884583> : tensor<f32>
    %68 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %69 = stablehlo.multiply %68, %67 : tensor<32x1024x128xf32>
    %70 = stablehlo.tanh %69 : tensor<32x1024x128xf32>
    %cst_6 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %71 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %72 = stablehlo.add %71, %70 : tensor<32x1024x128xf32>
    %cst_7 = stablehlo.constant dense<5.000000e-01> : tensor<f32>
    %73 = stablehlo.broadcast_in_dim %cst_7, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %74 = stablehlo.multiply %73, %72 : tensor<32x1024x128xf32>
    %75 = stablehlo.multiply %62, %74 : tensor<32x1024x128xf32>
    %76 = stablehlo.dot_general %75, %arg23, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x128xf32>, tensor<128x32xf32>) -> tensor<32x1024x32xf32>
    %77 = stablehlo.custom_call @Sharding(%76) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %78 = stablehlo.custom_call @Sharding(%77) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %79 = stablehlo.broadcast_in_dim %arg24, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %80 = stablehlo.add %78, %79 : tensor<32x1024x32xf32>
    %81 = stablehlo.custom_call @Sharding(%80) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %82 = stablehlo.add %40, %81 : tensor<32x1024x32xf32>
    return %82, %arg12 : tensor<32x1024x32xf32>, tensor<32x1024x32xf32>
  }
  func.func private @_var_5(%arg0: tensor<32x1024x32xf32>, %arg1: tensor<f32>, %arg2: tensor<i1>, %arg3: tensor<32x1024xf32>) -> tensor<32x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024x1xf32>
    %3 = stablehlo.divide %1, %2 : tensor<32x1024x1xf32>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0, 1, 2] : (tensor<32x1024x1xf32>) -> tensor<32x1024x32xf32>
    %5 = stablehlo.subtract %arg0, %4 : tensor<32x1024x32xf32>
    %6 = stablehlo.multiply %5, %5 : tensor<32x1024x32xf32>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %7 = stablehlo.reduce(%6 init: %cst_1) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %8 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %9 = stablehlo.divide %7, %8 : tensor<32x1024xf32>
    %10 = call @_where_6(%9, %arg2, %arg3) : (tensor<32x1024xf32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    return %10 : tensor<32x1024xf32>
  }
  func.func private @_where_6(%arg0: tensor<32x1024xf32>, %arg1: tensor<i1>, %arg2: tensor<32x1024xf32>) -> tensor<32x1024xf32> {
    %0 = stablehlo.select %arg1, %arg0, %arg2 : tensor<i1>, tensor<32x1024xf32>
    return %0 : tensor<32x1024xf32>
  }
  func.func private @_take_7(%arg0: tensor<32x3x4x1024x8xf32>, %arg1: tensor<1xi32>) -> tensor<32x4x1024x8xf32> {
    %c = stablehlo.constant dense<2> : tensor<1xi32>
    %0 = stablehlo.convert %arg1 : tensor<1xi32>
    %c_0 = stablehlo.constant dense<0> : tensor<i32>
    %1 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<i32>) -> tensor<1xi32>
    %2 = stablehlo.compare  GE, %0, %1,  SIGNED : (tensor<1xi32>, tensor<1xi32>) -> tensor<1xi1>
    %3 = stablehlo.compare  LE, %0, %c,  SIGNED : (tensor<1xi32>, tensor<1xi32>) -> tensor<1xi1>
    %4 = stablehlo.and %2, %3 : tensor<1xi1>
    %c_1 = stablehlo.constant dense<true> : tensor<i1>
    %5 = stablehlo.reduce(%4 init: %c_1) applies stablehlo.and across dimensions = [0] : (tensor<1xi1>, tensor<i1>) -> tensor<i1>
    %6 = "stablehlo.gather"(%arg0, %0) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2, 3], collapsed_slice_dims = [1], start_index_map = [1]>, indices_are_sorted = false, slice_sizes = array<i64: 32, 1, 4, 1024, 8>}> : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>) -> tensor<32x4x1024x8xf32>
    %7 = stablehlo.broadcast_in_dim %5, dims = [] : (tensor<i1>) -> tensor<32x4x1024x8xi1>
    %cst = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %8 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %9 = stablehlo.select %7, %6, %8 : tensor<32x4x1024x8xi1>, tensor<32x4x1024x8xf32>
    return %9 : tensor<32x4x1024x8xf32>
  }
  func.func private @_where_8(%arg0: tensor<32x4x1024x1024xi1>, %arg1: tensor<32x4x1024x1024xf32>, %arg2: tensor<f32>) -> tensor<32x4x1024x1024xf32> {
    %0 = stablehlo.convert %arg2 : tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x4x1024x1024xf32>
    %2 = stablehlo.select %arg0, %arg1, %1 : tensor<32x4x1024x1024xi1>, tensor<32x4x1024x1024xf32>
    return %2 : tensor<32x4x1024x1024xf32>
  }
  func.func private @_var_9(%arg0: tensor<32x1024x32xf32>, %arg1: tensor<i32>) -> (tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024x1xf32>
    %3 = stablehlo.divide %1, %2 : tensor<32x1024x1xf32>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0, 1, 2] : (tensor<32x1024x1xf32>) -> tensor<32x1024x32xf32>
    %5 = stablehlo.subtract %arg0, %4 : tensor<32x1024x32xf32>
    %6 = stablehlo.multiply %5, %5 : tensor<32x1024x32xf32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %7 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024x32xf32>
    %8 = stablehlo.multiply %7, %5 : tensor<32x1024x32xf32>
    %9 = stablehlo.convert %arg1 : (tensor<i32>) -> tensor<f32>
    %10 = stablehlo.subtract %cst_0, %9 : tensor<f32>
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %11 = stablehlo.reduce(%6 init: %cst_2) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %12 = stablehlo.broadcast_in_dim %10, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %13 = stablehlo.divide %11, %12 : tensor<32x1024xf32>
    %cst_3 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %14 = stablehlo.compare  GT, %10, %cst_3,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %cst_4 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %15 = call @_where_10(%14, %13, %cst_4) : (tensor<i1>, tensor<32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    return %15, %8, %10, %14 : tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>
  }
  func.func private @_where_10(%arg0: tensor<i1>, %arg1: tensor<32x1024xf32>, %arg2: tensor<f32>) -> tensor<32x1024xf32> {
    %0 = stablehlo.convert %arg2 : tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %2 = stablehlo.select %arg0, %arg1, %1 : tensor<i1>, tensor<32x1024xf32>
    return %2 : tensor<32x1024xf32>
  }
  func.func private @_roll_static(%arg0: tensor<32x1024xi32>) -> tensor<32x1024xi32> {
    %0 = stablehlo.slice %arg0 [0:32, 1:1024] : (tensor<32x1024xi32>) -> tensor<32x1023xi32>
    %1 = stablehlo.slice %arg0 [0:32, 0:1] : (tensor<32x1024xi32>) -> tensor<32x1xi32>
    %2 = stablehlo.concatenate %0, %1, dim = 1 : (tensor<32x1023xi32>, tensor<32x1xi32>) -> tensor<32x1024xi32>
    return %2 : tensor<32x1024xi32>
  }
  func.func private @_one_hot(%arg0: tensor<32x1024xi32>) -> tensor<32x1024x50257xf32> {
    %0 = stablehlo.broadcast_in_dim %arg0, dims = [0, 1] : (tensor<32x1024xi32>) -> tensor<32x1024x1xi32>
    %1 = stablehlo.iota dim = 2 : tensor<1x1x50257xi32>
    %2 = stablehlo.broadcast_in_dim %0, dims = [0, 1, 2] : (tensor<32x1024x1xi32>) -> tensor<32x1024x50257xi32>
    %3 = stablehlo.broadcast_in_dim %1, dims = [0, 1, 2] : (tensor<1x1x50257xi32>) -> tensor<32x1024x50257xi32>
    %4 = stablehlo.compare  EQ, %2, %3,  SIGNED : (tensor<32x1024x50257xi32>, tensor<32x1024x50257xi32>) -> tensor<32x1024x50257xi1>
    %5 = stablehlo.convert %4 : (tensor<32x1024x50257xi1>) -> tensor<32x1024x50257xf32>
    return %5 : tensor<32x1024x50257xf32>
  }
  func.func private @_where_11(%arg0: tensor<32x1024xi1>, %arg1: tensor<32x1024xf32>, %arg2: tensor<f32>) -> tensor<32x1024xf32> {
    %0 = stablehlo.broadcast_in_dim %arg2, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.select %arg0, %arg1, %0 : tensor<32x1024xi1>, tensor<32x1024xf32>
    return %1 : tensor<32x1024xf32>
  }
  func.func private @_where_12(%arg0: tensor<32x1024xi1>, %arg1: tensor<32x1024xf32>) -> tensor<32x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.select %arg0, %arg1, %0 : tensor<32x1024xi1>, tensor<32x1024xf32>
    return %1 : tensor<32x1024xf32>
  }
  func.func private @_var_13(%arg0: tensor<32x1024x32xf32>, %arg1: tensor<f32>, %arg2: tensor<i1>, %arg3: tensor<32x1024xf32>) -> tensor<32x1024x32xf32> {
    %0 = call @_where_14(%arg2, %arg3) : (tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %1 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %2 = stablehlo.divide %0, %1 : tensor<32x1024xf32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %4 = stablehlo.multiply %3, %arg0 : tensor<32x1024x32xf32>
    %5 = stablehlo.negate %4 : tensor<32x1024x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6 = stablehlo.reduce(%5 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %7 = stablehlo.reshape %6 : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %8 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024x1xf32>
    %9 = stablehlo.divide %7, %8 : tensor<32x1024x1xf32>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %10 = stablehlo.reduce(%9 init: %cst_1) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x1xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %11 = stablehlo.broadcast_in_dim %10, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %12 = stablehlo.add %4, %11 : tensor<32x1024x32xf32>
    return %12 : tensor<32x1024x32xf32>
  }
  func.func private @_where_14(%arg0: tensor<i1>, %arg1: tensor<32x1024xf32>) -> tensor<32x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.select %arg0, %arg1, %0 : tensor<i1>, tensor<32x1024xf32>
    return %1 : tensor<32x1024xf32>
  }
  func.func private @None_15(%arg0: tensor<32x1024xi32>, %arg1: tensor<32x1024x32xf32>, %arg2: tensor<32x1024x32xf32>, %arg3: tensor<32xf32>, %arg4: tensor<32xf32>, %arg5: tensor<32x3x4x8xf32>, %arg6: tensor<3x4x8xf32>, %arg7: tensor<4x8x32xf32>, %arg8: tensor<32xf32>, %arg9: tensor<32xf32>, %arg10: tensor<32xf32>, %arg11: tensor<32x128xf32>, %arg12: tensor<128xf32>, %arg13: tensor<128x32xf32>, %arg14: tensor<2xui32>) -> (tensor<32x1024x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x3x4x8xf32>, tensor<3x4x8xf32>, tensor<4x8x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x128xf32>, tensor<128xf32>, tensor<128x32xf32>, tensor<32xf32>) {
    %0 = call @_threefry_split_16(%arg14) : (tensor<2xui32>) -> tensor<4x2xui32>
    %1 = stablehlo.slice %0 [0:1, 0:2] : (tensor<4x2xui32>) -> tensor<1x2xui32>
    %2 = stablehlo.reshape %1 : (tensor<1x2xui32>) -> tensor<2xui32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %3 = stablehlo.reduce(%arg2 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %4 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %5 = stablehlo.divide %3, %4 : tensor<32x1024xf32>
    %c = stablehlo.constant dense<0> : tensor<i32>
    %6:4 = call @_var_18(%arg2, %c) : (tensor<32x1024x32xf32>, tensor<i32>) -> (tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>)
    %cst_1 = stablehlo.constant dense<9.99999974E-6> : tensor<f32>
    %7 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %8 = stablehlo.add %6#0, %7 : tensor<32x1024xf32>
    %9 = stablehlo.rsqrt %8 : tensor<32x1024xf32>
    %10 = stablehlo.divide %9, %8 : tensor<32x1024xf32>
    %cst_2 = stablehlo.constant dense<-5.000000e-01> : tensor<f32>
    %11 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %12 = stablehlo.multiply %11, %10 : tensor<32x1024xf32>
    %13 = stablehlo.broadcast_in_dim %5, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %14 = stablehlo.transpose %13, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %15 = stablehlo.subtract %arg2, %14 : tensor<32x1024x32xf32>
    %16 = stablehlo.broadcast_in_dim %9, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %17 = stablehlo.transpose %16, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %18 = stablehlo.multiply %15, %17 : tensor<32x1024x32xf32>
    %19 = stablehlo.broadcast_in_dim %arg3, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %20 = stablehlo.multiply %19, %18 : tensor<32x1024x32xf32>
    %21 = stablehlo.broadcast_in_dim %arg4, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %22 = stablehlo.add %20, %21 : tensor<32x1024x32xf32>
    %23 = call @_threefry_split_20(%2) : (tensor<2xui32>) -> tensor<3x2xui32>
    %24 = stablehlo.slice %23 [0:1, 0:2] : (tensor<3x2xui32>) -> tensor<1x2xui32>
    %25 = stablehlo.reshape %24 : (tensor<1x2xui32>) -> tensor<2xui32>
    %26 = stablehlo.dot_general %22, %arg5, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %27 = stablehlo.custom_call @Sharding(%26) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %28 = stablehlo.custom_call @Sharding(%27) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %29 = stablehlo.broadcast_in_dim %arg6, dims = [2, 3, 4] : (tensor<3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %30 = stablehlo.add %28, %29 : tensor<32x1024x3x4x8xf32>
    %31 = stablehlo.custom_call @Sharding(%30) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %32 = stablehlo.transpose %31, dims = [0, 2, 3, 1, 4] : (tensor<32x1024x3x4x8xf32>) -> tensor<32x3x4x1024x8xf32>
    %33:2 = call @_take_22(%32, %c) : (tensor<32x3x4x1024x8xf32>, tensor<i32>) -> (tensor<32x4x1024x8xf32>, tensor<1xi32>)
    %c_3 = stablehlo.constant dense<1> : tensor<i32>
    %34:2 = call @_take_22(%32, %c_3) : (tensor<32x3x4x1024x8xf32>, tensor<i32>) -> (tensor<32x4x1024x8xf32>, tensor<1xi32>)
    %c_4 = stablehlo.constant dense<2> : tensor<i32>
    %35:2 = call @_take_22(%32, %c_4) : (tensor<32x3x4x1024x8xf32>, tensor<i32>) -> (tensor<32x4x1024x8xf32>, tensor<1xi32>)
    %36 = stablehlo.custom_call @Sharding(%33#0) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %37 = stablehlo.custom_call @Sharding(%34#0) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %38 = stablehlo.custom_call @Sharding(%35#0) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %cst_5 = stablehlo.constant dense<2.82842708> : tensor<f32>
    %39 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %40 = stablehlo.divide %36, %39 : tensor<32x4x1024x8xf32>
    %cst_6 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %41 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %42 = stablehlo.custom_call @Sharding(%41) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %43 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
    %44 = stablehlo.custom_call @Sharding(%43) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024xf32>) -> tensor<32x4x1024xf32>
    %45:7 = stablehlo.while(%iterArg = %40, %iterArg_26 = %37, %iterArg_27 = %38, %iterArg_28 = %arg0, %iterArg_29 = %c, %iterArg_30 = %42, %iterArg_31 = %44) : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>
     cond {
      %c_32 = stablehlo.constant dense<1> : tensor<i32>
      %199 = stablehlo.compare  LT, %iterArg_29, %c_32,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      stablehlo.return %199 : tensor<i1>
    } do {
      %c_32 = stablehlo.constant dense<1024> : tensor<i32>
      %199 = stablehlo.multiply %iterArg_29, %c_32 : tensor<i32>
      %c_33 = stablehlo.constant dense<0> : tensor<i32>
      %200 = stablehlo.compare  LT, %199, %c_33,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %201 = stablehlo.convert %199 : tensor<i32>
      %c_34 = stablehlo.constant dense<1024> : tensor<i32>
      %202 = stablehlo.add %201, %c_34 : tensor<i32>
      %203 = stablehlo.select %200, %202, %199 : tensor<i1>, tensor<i32>
      %c_35 = stablehlo.constant dense<0> : tensor<i32>
      %204 = stablehlo.dynamic_slice %iterArg, %c_35, %c_35, %203, %c_35, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %205 = stablehlo.multiply %iterArg_29, %c_32 : tensor<i32>
      %206 = stablehlo.compare  LT, %205, %c_33,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %207 = stablehlo.convert %205 : tensor<i32>
      %208 = stablehlo.add %207, %c_34 : tensor<i32>
      %209 = stablehlo.select %206, %208, %205 : tensor<i1>, tensor<i32>
      %210 = stablehlo.dynamic_slice %iterArg_30, %c_35, %c_35, %209, %c_35, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %cst_36 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
      %211 = stablehlo.broadcast_in_dim %cst_36, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
      %cst_37 = stablehlo.constant dense<0xFF800000> : tensor<f32>
      %212 = stablehlo.broadcast_in_dim %cst_37, dims = [] : (tensor<f32>) -> tensor<32x4x1024xf32>
      %c_38 = stablehlo.constant dense<1> : tensor<i32>
      %213 = stablehlo.add %iterArg_29, %c_38 : tensor<i32>
      %214 = stablehlo.minimum %213, %c_38 : tensor<i32>
      %215:10 = stablehlo.while(%iterArg_39 = %214, %iterArg_40 = %iterArg_29, %iterArg_41 = %204, %iterArg_42 = %iterArg_26, %iterArg_43 = %iterArg_27, %iterArg_44 = %iterArg_28, %iterArg_45 = %c_33, %iterArg_46 = %210, %iterArg_47 = %211, %iterArg_48 = %212) : tensor<i32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>
       cond {
        %234 = stablehlo.compare  LT, %iterArg_45, %iterArg_39,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        stablehlo.return %234 : tensor<i1>
      } do {
        %c_49 = stablehlo.constant dense<1024> : tensor<i32>
        %234 = stablehlo.multiply %iterArg_45, %c_49 : tensor<i32>
        %c_50 = stablehlo.constant dense<0> : tensor<i32>
        %235 = stablehlo.compare  LT, %234, %c_50,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %236 = stablehlo.convert %234 : tensor<i32>
        %c_51 = stablehlo.constant dense<1024> : tensor<i32>
        %237 = stablehlo.add %236, %c_51 : tensor<i32>
        %238 = stablehlo.select %235, %237, %234 : tensor<i1>, tensor<i32>
        %c_52 = stablehlo.constant dense<0> : tensor<i32>
        %239 = stablehlo.dynamic_slice %iterArg_42, %c_52, %c_52, %238, %c_52, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %240 = stablehlo.multiply %iterArg_45, %c_49 : tensor<i32>
        %241 = stablehlo.compare  LT, %240, %c_50,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %242 = stablehlo.convert %240 : tensor<i32>
        %243 = stablehlo.add %242, %c_51 : tensor<i32>
        %244 = stablehlo.select %241, %243, %240 : tensor<i1>, tensor<i32>
        %245 = stablehlo.dynamic_slice %iterArg_43, %c_52, %c_52, %244, %c_52, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %246 = stablehlo.dot_general %iterArg_41, %239, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [3], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x1024xf32>
        %247 = stablehlo.custom_call @Sharding(%246) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %248 = stablehlo.multiply %iterArg_40, %c_49 : tensor<i32>
        %249 = stablehlo.multiply %iterArg_45, %c_49 : tensor<i32>
        %250 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %c_53 = stablehlo.constant dense<1> : tensor<i32>
        %251 = stablehlo.broadcast_in_dim %c_53, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %252 = stablehlo.multiply %250, %251 : tensor<1024xi32>
        %253 = stablehlo.convert %248 : tensor<i32>
        %254 = stablehlo.broadcast_in_dim %253, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %255 = stablehlo.add %252, %254 : tensor<1024xi32>
        %256 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %257 = stablehlo.broadcast_in_dim %c_53, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %258 = stablehlo.multiply %256, %257 : tensor<1024xi32>
        %259 = stablehlo.convert %249 : tensor<i32>
        %260 = stablehlo.broadcast_in_dim %259, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %261 = stablehlo.add %258, %260 : tensor<1024xi32>
        %262 = stablehlo.broadcast_in_dim %261, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %263 = stablehlo.broadcast_in_dim %255, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %264 = stablehlo.transpose %263, dims = [1, 0] : (tensor<1024x1024xi32>) -> tensor<1024x1024xi32>
        %265 = stablehlo.compare  GE, %264, %262,  SIGNED : (tensor<1024x1024xi32>, tensor<1024x1024xi32>) -> tensor<1024x1024xi1>
        %266 = stablehlo.compare  LT, %249, %c_50,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %267 = stablehlo.convert %249 : tensor<i32>
        %268 = stablehlo.add %267, %c_51 : tensor<i32>
        %269 = stablehlo.select %266, %268, %249 : tensor<i1>, tensor<i32>
        %270 = stablehlo.dynamic_slice %iterArg_44, %c_52, %269, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %271 = stablehlo.compare  LT, %248, %c_50,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %272 = stablehlo.convert %248 : tensor<i32>
        %273 = stablehlo.add %272, %c_51 : tensor<i32>
        %274 = stablehlo.select %271, %273, %248 : tensor<i1>, tensor<i32>
        %275 = stablehlo.dynamic_slice %iterArg_44, %c_52, %274, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %276 = stablehlo.broadcast_in_dim %275, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %277 = stablehlo.broadcast_in_dim %270, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %278 = stablehlo.transpose %277, dims = [2, 1, 0] : (tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi32>
        %279 = stablehlo.compare  EQ, %276, %278,  SIGNED : (tensor<1024x32x1024xi32>, tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi1>
        %280 = stablehlo.transpose %279, dims = [2, 0, 1] : (tensor<1024x32x1024xi1>) -> tensor<1024x1024x32xi1>
        %281 = stablehlo.broadcast_in_dim %265, dims = [1, 2] : (tensor<1024x1024xi1>) -> tensor<32x1024x1024xi1>
        %282 = stablehlo.transpose %281, dims = [1, 2, 0] : (tensor<32x1024x1024xi1>) -> tensor<1024x1024x32xi1>
        %283 = stablehlo.and %282, %280 : tensor<1024x1024x32xi1>
        %284 = stablehlo.broadcast_in_dim %283, dims = [1, 2, 3] : (tensor<1024x1024x32xi1>) -> tensor<4x1024x1024x32xi1>
        %285 = stablehlo.transpose %284, dims = [3, 0, 1, 2] : (tensor<4x1024x1024x32xi1>) -> tensor<32x4x1024x1024xi1>
        %cst_54 = stablehlo.constant dense<-1.000000e+10> : tensor<f32>
        %286 = func.call @_where_24(%285, %247, %cst_54) : (tensor<32x4x1024x1024xi1>, tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024x1024xf32>
        %cst_55 = stablehlo.constant dense<0xFF800000> : tensor<f32>
        %287 = stablehlo.reduce(%286 init: %cst_55) applies stablehlo.maximum across dimensions = [3] : (tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024xf32>
        %288 = stablehlo.maximum %iterArg_48, %287 : tensor<32x4x1024xf32>
        %289 = stablehlo.broadcast_in_dim %288, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<1024x32x4x1024xf32>
        %290 = stablehlo.transpose %289, dims = [1, 2, 3, 0] : (tensor<1024x32x4x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %291 = stablehlo.subtract %286, %290 : tensor<32x4x1024x1024xf32>
        %292 = stablehlo.exponential %291 : tensor<32x4x1024x1024xf32>
        %293 = stablehlo.subtract %iterArg_48, %288 : tensor<32x4x1024xf32>
        %294 = stablehlo.exponential %293 : tensor<32x4x1024xf32>
        %295 = stablehlo.multiply %294, %iterArg_47 : tensor<32x4x1024xf32>
        %cst_56 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
        %296 = stablehlo.reduce(%292 init: %cst_56) applies stablehlo.add across dimensions = [3] : (tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024xf32>
        %297 = stablehlo.add %295, %296 : tensor<32x4x1024xf32>
        %298 = stablehlo.broadcast_in_dim %294, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<8x32x4x1024xf32>
        %299 = stablehlo.transpose %298, dims = [1, 2, 3, 0] : (tensor<8x32x4x1024xf32>) -> tensor<32x4x1024x8xf32>
        %300 = stablehlo.multiply %299, %iterArg_46 : tensor<32x4x1024x8xf32>
        %301 = stablehlo.dot_general %292, %245, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x1024xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %302 = stablehlo.custom_call @Sharding(%301) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %303 = stablehlo.add %300, %302 : tensor<32x4x1024x8xf32>
        %c_57 = stablehlo.constant dense<1> : tensor<i32>
        %304 = stablehlo.add %iterArg_45, %c_57 : tensor<i32>
        stablehlo.return %iterArg_39, %iterArg_40, %iterArg_41, %iterArg_42, %iterArg_43, %iterArg_44, %304, %303, %297, %288 : tensor<i32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>
      }
      %216 = stablehlo.broadcast_in_dim %215#8, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<8x32x4x1024xf32>
      %217 = stablehlo.transpose %216, dims = [1, 2, 3, 0] : (tensor<8x32x4x1024xf32>) -> tensor<32x4x1024x8xf32>
      %218 = stablehlo.divide %215#7, %217 : tensor<32x4x1024x8xf32>
      %219 = stablehlo.log %215#8 : tensor<32x4x1024xf32>
      %220 = stablehlo.add %215#9, %219 : tensor<32x4x1024xf32>
      %221 = stablehlo.multiply %iterArg_29, %c_32 : tensor<i32>
      %222 = stablehlo.compare  LT, %221, %c_33,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %223 = stablehlo.convert %221 : tensor<i32>
      %224 = stablehlo.add %223, %c_34 : tensor<i32>
      %225 = stablehlo.select %222, %224, %221 : tensor<i1>, tensor<i32>
      %226 = stablehlo.dynamic_update_slice %iterArg_30, %218, %c_35, %c_35, %225, %c_35 : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %227 = stablehlo.multiply %iterArg_29, %c_32 : tensor<i32>
      %228 = stablehlo.compare  LT, %227, %c_33,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %229 = stablehlo.convert %227 : tensor<i32>
      %230 = stablehlo.add %229, %c_34 : tensor<i32>
      %231 = stablehlo.select %228, %230, %227 : tensor<i1>, tensor<i32>
      %232 = stablehlo.dynamic_update_slice %iterArg_31, %220, %c_35, %c_35, %231 : (tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024xf32>
      %233 = stablehlo.add %iterArg_29, %c_38 : tensor<i32>
      stablehlo.return %iterArg, %iterArg_26, %iterArg_27, %iterArg_28, %233, %226, %232 : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>
    }
    %46 = stablehlo.dot_general %45#5, %arg7, contracting_dims = [1, 3] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<4x8x32xf32>) -> tensor<32x1024x32xf32>
    %47 = stablehlo.custom_call @Sharding(%46) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %48 = stablehlo.custom_call @Sharding(%47) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %49 = stablehlo.broadcast_in_dim %arg8, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %50 = stablehlo.add %48, %49 : tensor<32x1024x32xf32>
    %51 = stablehlo.custom_call @Sharding(%50) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %52 = stablehlo.add %arg2, %51 : tensor<32x1024x32xf32>
    %cst_7 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %53 = stablehlo.reduce(%52 init: %cst_7) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %54 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %55 = stablehlo.divide %53, %54 : tensor<32x1024xf32>
    %56:4 = call @_var_18(%52, %c) : (tensor<32x1024x32xf32>, tensor<i32>) -> (tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>)
    %57 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %58 = stablehlo.add %56#0, %57 : tensor<32x1024xf32>
    %59 = stablehlo.rsqrt %58 : tensor<32x1024xf32>
    %60 = stablehlo.divide %59, %58 : tensor<32x1024xf32>
    %61 = stablehlo.broadcast_in_dim %cst_2, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %62 = stablehlo.multiply %61, %60 : tensor<32x1024xf32>
    %63 = stablehlo.broadcast_in_dim %55, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %64 = stablehlo.transpose %63, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %65 = stablehlo.subtract %52, %64 : tensor<32x1024x32xf32>
    %66 = stablehlo.broadcast_in_dim %59, dims = [1, 2] : (tensor<32x1024xf32>) -> tensor<32x32x1024xf32>
    %67 = stablehlo.transpose %66, dims = [1, 2, 0] : (tensor<32x32x1024xf32>) -> tensor<32x1024x32xf32>
    %68 = stablehlo.multiply %65, %67 : tensor<32x1024x32xf32>
    %69 = stablehlo.broadcast_in_dim %arg9, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %70 = stablehlo.multiply %69, %68 : tensor<32x1024x32xf32>
    %71 = stablehlo.broadcast_in_dim %arg10, dims = [2] : (tensor<32xf32>) -> tensor<32x1024x32xf32>
    %72 = stablehlo.add %70, %71 : tensor<32x1024x32xf32>
    %73 = stablehlo.dot_general %72, %arg11, contracting_dims = [2] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x128xf32>) -> tensor<32x1024x128xf32>
    %74 = stablehlo.custom_call @Sharding(%73) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %75 = stablehlo.custom_call @Sharding(%74) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %76 = stablehlo.broadcast_in_dim %arg12, dims = [2] : (tensor<128xf32>) -> tensor<32x1024x128xf32>
    %77 = stablehlo.add %75, %76 : tensor<32x1024x128xf32>
    %78 = stablehlo.custom_call @Sharding(%77) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %79 = stablehlo.multiply %78, %78 : tensor<32x1024x128xf32>
    %80 = stablehlo.multiply %79, %78 : tensor<32x1024x128xf32>
    %81 = stablehlo.multiply %78, %78 : tensor<32x1024x128xf32>
    %cst_8 = stablehlo.constant dense<3.000000e+00> : tensor<f32>
    %82 = stablehlo.broadcast_in_dim %cst_8, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %83 = stablehlo.multiply %82, %81 : tensor<32x1024x128xf32>
    %cst_9 = stablehlo.constant dense<4.471500e-02> : tensor<f32>
    %84 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %85 = stablehlo.multiply %84, %80 : tensor<32x1024x128xf32>
    %86 = stablehlo.add %78, %85 : tensor<32x1024x128xf32>
    %cst_10 = stablehlo.constant dense<0.797884583> : tensor<f32>
    %87 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %88 = stablehlo.multiply %87, %86 : tensor<32x1024x128xf32>
    %89 = stablehlo.tanh %88 : tensor<32x1024x128xf32>
    %cst_11 = stablehlo.constant dense<1.000000e+00> : tensor<f32>
    %90 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<f32>
    %91 = stablehlo.broadcast_in_dim %90, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %92 = stablehlo.subtract %91, %89 : tensor<32x1024x128xf32>
    %93 = stablehlo.broadcast_in_dim %cst_11, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %94 = stablehlo.add %93, %89 : tensor<32x1024x128xf32>
    %cst_12 = stablehlo.constant dense<5.000000e-01> : tensor<f32>
    %95 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %96 = stablehlo.multiply %95, %94 : tensor<32x1024x128xf32>
    %97 = stablehlo.multiply %78, %96 : tensor<32x1024x128xf32>
    %98 = stablehlo.custom_call @Sharding(%arg1) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %cst_13 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %99 = stablehlo.reduce(%98 init: %cst_13) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %100 = stablehlo.custom_call @Sharding(%98) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %101 = stablehlo.custom_call @Sharding(%100) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %102 = stablehlo.dot_general %101, %97, contracting_dims = [0, 1] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x1024x128xf32>) -> tensor<32x128xf32>
    %103 = stablehlo.transpose %102, dims = [1, 0] : (tensor<32x128xf32>) -> tensor<128x32xf32>
    %104 = stablehlo.dot_general %101, %arg13, contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<128x32xf32>) -> tensor<32x1024x128xf32>
    %105 = stablehlo.multiply %78, %104 : tensor<32x1024x128xf32>
    %106 = stablehlo.broadcast_in_dim %cst_12, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %107 = stablehlo.multiply %106, %105 : tensor<32x1024x128xf32>
    %108 = stablehlo.multiply %107, %92 : tensor<32x1024x128xf32>
    %109 = stablehlo.multiply %108, %89 : tensor<32x1024x128xf32>
    %110 = stablehlo.add %108, %109 : tensor<32x1024x128xf32>
    %111 = stablehlo.broadcast_in_dim %cst_10, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %112 = stablehlo.multiply %111, %110 : tensor<32x1024x128xf32>
    %113 = stablehlo.broadcast_in_dim %cst_9, dims = [] : (tensor<f32>) -> tensor<32x1024x128xf32>
    %114 = stablehlo.multiply %113, %112 : tensor<32x1024x128xf32>
    %115 = stablehlo.multiply %114, %83 : tensor<32x1024x128xf32>
    %116 = stablehlo.add %112, %115 : tensor<32x1024x128xf32>
    %117 = stablehlo.multiply %104, %96 : tensor<32x1024x128xf32>
    %118 = stablehlo.add %116, %117 : tensor<32x1024x128xf32>
    %119 = stablehlo.custom_call @Sharding(%118) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %cst_14 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %120 = stablehlo.reduce(%119 init: %cst_14) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x128xf32>, tensor<f32>) -> tensor<128xf32>
    %121 = stablehlo.custom_call @Sharding(%119) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %122 = stablehlo.custom_call @Sharding(%121) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x128xf32>) -> tensor<32x1024x128xf32>
    %123 = stablehlo.dot_general %122, %72, contracting_dims = [0, 1] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x128xf32>, tensor<32x1024x32xf32>) -> tensor<128x32xf32>
    %124 = stablehlo.transpose %123, dims = [1, 0] : (tensor<128x32xf32>) -> tensor<32x128xf32>
    %125 = stablehlo.dot_general %122, %arg11, contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x128xf32>, tensor<32x128xf32>) -> tensor<32x1024x32xf32>
    %cst_15 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %126 = stablehlo.reduce(%125 init: %cst_15) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %127 = stablehlo.multiply %69, %125 : tensor<32x1024x32xf32>
    %128 = stablehlo.multiply %65, %127 : tensor<32x1024x32xf32>
    %129 = stablehlo.transpose %128, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_16 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %130 = stablehlo.reduce(%129 init: %cst_16) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %131 = stablehlo.multiply %130, %62 : tensor<32x1024xf32>
    %132 = call @_var_25(%56#1, %56#2, %56#3, %131) : (tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %133 = stablehlo.add %arg1, %132 : tensor<32x1024x32xf32>
    %134 = stablehlo.multiply %127, %67 : tensor<32x1024x32xf32>
    %135 = stablehlo.negate %134 : tensor<32x1024x32xf32>
    %136 = stablehlo.add %133, %134 : tensor<32x1024x32xf32>
    %137 = stablehlo.transpose %135, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_17 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %138 = stablehlo.reduce(%137 init: %cst_17) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %139 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %140 = stablehlo.divide %138, %139 : tensor<32x1024xf32>
    %141 = stablehlo.broadcast_in_dim %140, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %142 = stablehlo.add %136, %141 : tensor<32x1024x32xf32>
    %143 = stablehlo.custom_call @Sharding(%142) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %cst_18 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %144 = stablehlo.reduce(%143 init: %cst_18) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %145 = stablehlo.custom_call @Sharding(%143) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %146 = stablehlo.custom_call @Sharding(%145) {backend_config = "", mhlo.sharding = "{replicated}"} : (tensor<32x1024x32xf32>) -> tensor<32x1024x32xf32>
    %147 = stablehlo.dot_general %146, %45#5, contracting_dims = [0, 1] x [0, 2], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x8xf32>
    %148 = stablehlo.transpose %147, dims = [1, 2, 0] : (tensor<32x4x8xf32>) -> tensor<4x8x32xf32>
    %149 = stablehlo.dot_general %146, %arg7, contracting_dims = [2] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x32xf32>, tensor<4x8x32xf32>) -> tensor<32x1024x4x8xf32>
    %150 = stablehlo.transpose %149, dims = [0, 2, 1, 3] : (tensor<32x1024x4x8xf32>) -> tensor<32x4x1024x8xf32>
    %151 = stablehlo.multiply %150, %45#5 : tensor<32x4x1024x8xf32>
    %cst_19 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %152 = stablehlo.reduce(%151 init: %cst_19) applies stablehlo.add across dimensions = [3] : (tensor<32x4x1024x8xf32>, tensor<f32>) -> tensor<32x4x1024xf32>
    %153 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %154 = stablehlo.multiply %40, %153 : tensor<32x4x1024x8xf32>
    %155 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %156 = stablehlo.multiply %37, %155 : tensor<32x4x1024x8xf32>
    %157 = stablehlo.broadcast_in_dim %cst_6, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %158 = stablehlo.multiply %38, %157 : tensor<32x4x1024x8xf32>
    %159:11 = stablehlo.while(%iterArg = %37, %iterArg_26 = %38, %iterArg_27 = %40, %iterArg_28 = %150, %iterArg_29 = %45#6, %iterArg_30 = %152, %iterArg_31 = %arg0, %iterArg_32 = %c, %iterArg_33 = %154, %iterArg_34 = %156, %iterArg_35 = %158) : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>
     cond {
      %c_36 = stablehlo.constant dense<1> : tensor<i32>
      %199 = stablehlo.compare  LT, %iterArg_32, %c_36,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      stablehlo.return %199 : tensor<i1>
    } do {
      %c_36 = stablehlo.constant dense<1024> : tensor<i32>
      %199 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %c_37 = stablehlo.constant dense<0> : tensor<i32>
      %200 = stablehlo.compare  LT, %199, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %201 = stablehlo.convert %199 : tensor<i32>
      %c_38 = stablehlo.constant dense<1024> : tensor<i32>
      %202 = stablehlo.add %201, %c_38 : tensor<i32>
      %203 = stablehlo.select %200, %202, %199 : tensor<i1>, tensor<i32>
      %c_39 = stablehlo.constant dense<0> : tensor<i32>
      %204 = stablehlo.dynamic_slice %iterArg, %c_39, %c_39, %203, %c_39, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %205 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %206 = stablehlo.compare  LT, %205, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %207 = stablehlo.convert %205 : tensor<i32>
      %208 = stablehlo.add %207, %c_38 : tensor<i32>
      %209 = stablehlo.select %206, %208, %205 : tensor<i1>, tensor<i32>
      %210 = stablehlo.dynamic_slice %iterArg_26, %c_39, %c_39, %209, %c_39, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %211 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %212 = stablehlo.compare  LT, %211, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %213 = stablehlo.convert %211 : tensor<i32>
      %214 = stablehlo.add %213, %c_38 : tensor<i32>
      %215 = stablehlo.select %212, %214, %211 : tensor<i1>, tensor<i32>
      %216 = stablehlo.dynamic_slice %iterArg_34, %c_39, %c_39, %215, %c_39, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %217 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %218 = stablehlo.compare  LT, %217, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %219 = stablehlo.convert %217 : tensor<i32>
      %220 = stablehlo.add %219, %c_38 : tensor<i32>
      %221 = stablehlo.select %218, %220, %217 : tensor<i1>, tensor<i32>
      %222 = stablehlo.dynamic_slice %iterArg_35, %c_39, %c_39, %221, %c_39, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %223:12 = stablehlo.while(%iterArg_41 = %iterArg_32, %iterArg_42 = %iterArg_27, %iterArg_43 = %iterArg_28, %iterArg_44 = %iterArg_29, %iterArg_45 = %iterArg_30, %iterArg_46 = %204, %iterArg_47 = %iterArg_31, %iterArg_48 = %210, %iterArg_49 = %iterArg_32, %iterArg_50 = %iterArg_33, %iterArg_51 = %216, %iterArg_52 = %222) : tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>
       cond {
        %c_53 = stablehlo.constant dense<1> : tensor<i32>
        %237 = stablehlo.compare  LT, %iterArg_49, %c_53,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        stablehlo.return %237 : tensor<i1>
      } do {
        %c_53 = stablehlo.constant dense<1024> : tensor<i32>
        %237 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %c_54 = stablehlo.constant dense<0> : tensor<i32>
        %238 = stablehlo.compare  LT, %237, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %239 = stablehlo.convert %237 : tensor<i32>
        %c_55 = stablehlo.constant dense<1024> : tensor<i32>
        %240 = stablehlo.add %239, %c_55 : tensor<i32>
        %241 = stablehlo.select %238, %240, %237 : tensor<i1>, tensor<i32>
        %c_56 = stablehlo.constant dense<0> : tensor<i32>
        %242 = stablehlo.dynamic_slice %iterArg_42, %c_56, %c_56, %241, %c_56, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %243 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %244 = stablehlo.compare  LT, %243, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %245 = stablehlo.convert %243 : tensor<i32>
        %246 = stablehlo.add %245, %c_55 : tensor<i32>
        %247 = stablehlo.select %244, %246, %243 : tensor<i1>, tensor<i32>
        %248 = stablehlo.dynamic_slice %iterArg_50, %c_56, %c_56, %247, %c_56, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %249 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %250 = stablehlo.compare  LT, %249, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %251 = stablehlo.convert %249 : tensor<i32>
        %252 = stablehlo.add %251, %c_55 : tensor<i32>
        %253 = stablehlo.select %250, %252, %249 : tensor<i1>, tensor<i32>
        %254 = stablehlo.dynamic_slice %iterArg_43, %c_56, %c_56, %253, %c_56, sizes = [32, 4, 1024, 8] : (tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %255 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %256 = stablehlo.compare  LT, %255, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %257 = stablehlo.convert %255 : tensor<i32>
        %258 = stablehlo.add %257, %c_55 : tensor<i32>
        %259 = stablehlo.select %256, %258, %255 : tensor<i1>, tensor<i32>
        %260 = stablehlo.dynamic_slice %iterArg_44, %c_56, %c_56, %259, sizes = [32, 4, 1024] : (tensor<32x4x1024xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024xf32>
        %261 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %262 = stablehlo.compare  LT, %261, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %263 = stablehlo.convert %261 : tensor<i32>
        %264 = stablehlo.add %263, %c_55 : tensor<i32>
        %265 = stablehlo.select %262, %264, %261 : tensor<i1>, tensor<i32>
        %266 = stablehlo.dynamic_slice %iterArg_45, %c_56, %c_56, %265, sizes = [32, 4, 1024] : (tensor<32x4x1024xf32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024xf32>
        %267 = stablehlo.dot_general %242, %iterArg_46, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [3], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x1024xf32>
        %268 = stablehlo.custom_call @Sharding(%267) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %269 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %270 = stablehlo.multiply %iterArg_41, %c_53 : tensor<i32>
        %271 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %c_57 = stablehlo.constant dense<1> : tensor<i32>
        %272 = stablehlo.broadcast_in_dim %c_57, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %273 = stablehlo.multiply %271, %272 : tensor<1024xi32>
        %274 = stablehlo.convert %269 : tensor<i32>
        %275 = stablehlo.broadcast_in_dim %274, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %276 = stablehlo.add %273, %275 : tensor<1024xi32>
        %277 = stablehlo.iota dim = 0 : tensor<1024xi32>
        %278 = stablehlo.broadcast_in_dim %c_57, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %279 = stablehlo.multiply %277, %278 : tensor<1024xi32>
        %280 = stablehlo.convert %270 : tensor<i32>
        %281 = stablehlo.broadcast_in_dim %280, dims = [] : (tensor<i32>) -> tensor<1024xi32>
        %282 = stablehlo.add %279, %281 : tensor<1024xi32>
        %283 = stablehlo.broadcast_in_dim %282, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %284 = stablehlo.broadcast_in_dim %276, dims = [1] : (tensor<1024xi32>) -> tensor<1024x1024xi32>
        %285 = stablehlo.transpose %284, dims = [1, 0] : (tensor<1024x1024xi32>) -> tensor<1024x1024xi32>
        %286 = stablehlo.compare  GE, %285, %283,  SIGNED : (tensor<1024x1024xi32>, tensor<1024x1024xi32>) -> tensor<1024x1024xi1>
        %287 = stablehlo.compare  LT, %270, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %288 = stablehlo.convert %270 : tensor<i32>
        %289 = stablehlo.add %288, %c_55 : tensor<i32>
        %290 = stablehlo.select %287, %289, %270 : tensor<i1>, tensor<i32>
        %291 = stablehlo.dynamic_slice %iterArg_47, %c_56, %290, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %292 = stablehlo.compare  LT, %269, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %293 = stablehlo.convert %269 : tensor<i32>
        %294 = stablehlo.add %293, %c_55 : tensor<i32>
        %295 = stablehlo.select %292, %294, %269 : tensor<i1>, tensor<i32>
        %296 = stablehlo.dynamic_slice %iterArg_47, %c_56, %295, sizes = [32, 1024] : (tensor<32x1024xi32>, tensor<i32>, tensor<i32>) -> tensor<32x1024xi32>
        %297 = stablehlo.broadcast_in_dim %296, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %298 = stablehlo.broadcast_in_dim %291, dims = [1, 2] : (tensor<32x1024xi32>) -> tensor<1024x32x1024xi32>
        %299 = stablehlo.transpose %298, dims = [2, 1, 0] : (tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi32>
        %300 = stablehlo.compare  EQ, %297, %299,  SIGNED : (tensor<1024x32x1024xi32>, tensor<1024x32x1024xi32>) -> tensor<1024x32x1024xi1>
        %301 = stablehlo.transpose %300, dims = [2, 0, 1] : (tensor<1024x32x1024xi1>) -> tensor<1024x1024x32xi1>
        %302 = stablehlo.broadcast_in_dim %286, dims = [1, 2] : (tensor<1024x1024xi1>) -> tensor<32x1024x1024xi1>
        %303 = stablehlo.transpose %302, dims = [1, 2, 0] : (tensor<32x1024x1024xi1>) -> tensor<1024x1024x32xi1>
        %304 = stablehlo.and %303, %301 : tensor<1024x1024x32xi1>
        %305 = stablehlo.broadcast_in_dim %304, dims = [1, 2, 3] : (tensor<1024x1024x32xi1>) -> tensor<4x1024x1024x32xi1>
        %306 = stablehlo.transpose %305, dims = [3, 0, 1, 2] : (tensor<4x1024x1024x32xi1>) -> tensor<32x4x1024x1024xi1>
        %cst_58 = stablehlo.constant dense<-1.000000e+10> : tensor<f32>
        %307 = func.call @_where_24(%306, %268, %cst_58) : (tensor<32x4x1024x1024xi1>, tensor<32x4x1024x1024xf32>, tensor<f32>) -> tensor<32x4x1024x1024xf32>
        %308 = stablehlo.broadcast_in_dim %260, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<1024x32x4x1024xf32>
        %309 = stablehlo.transpose %308, dims = [1, 2, 3, 0] : (tensor<1024x32x4x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %310 = stablehlo.subtract %307, %309 : tensor<32x4x1024x1024xf32>
        %311 = stablehlo.exponential %310 : tensor<32x4x1024x1024xf32>
        %312 = stablehlo.dot_general %254, %iterArg_48, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [3], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x1024xf32>
        %313 = stablehlo.custom_call @Sharding(%312) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %314 = stablehlo.broadcast_in_dim %266, dims = [1, 2, 3] : (tensor<32x4x1024xf32>) -> tensor<1024x32x4x1024xf32>
        %315 = stablehlo.transpose %314, dims = [1, 2, 3, 0] : (tensor<1024x32x4x1024xf32>) -> tensor<32x4x1024x1024xf32>
        %316 = stablehlo.subtract %313, %315 : tensor<32x4x1024x1024xf32>
        %317 = stablehlo.multiply %311, %316 : tensor<32x4x1024x1024xf32>
        %318 = stablehlo.dot_general %311, %254, batching_dims = [0, 1] x [0, 1], contracting_dims = [2] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x1024xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %319 = stablehlo.custom_call @Sharding(%318) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %320 = stablehlo.dot_general %317, %242, batching_dims = [0, 1] x [0, 1], contracting_dims = [2] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x1024xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %321 = stablehlo.custom_call @Sharding(%320) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %cst_59 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
        %322 = stablehlo.reduce(%319 init: %cst_59) applies stablehlo.add across dimensions = [] : (tensor<32x4x1024x8xf32>, tensor<f32>) -> tensor<32x4x1024x8xf32>
        %cst_60 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
        %323 = stablehlo.reduce(%321 init: %cst_60) applies stablehlo.add across dimensions = [] : (tensor<32x4x1024x8xf32>, tensor<f32>) -> tensor<32x4x1024x8xf32>
        %324 = stablehlo.add %iterArg_52, %322 : tensor<32x4x1024x8xf32>
        %325 = stablehlo.add %iterArg_51, %323 : tensor<32x4x1024x8xf32>
        %326 = stablehlo.dot_general %317, %iterArg_46, batching_dims = [0, 1] x [0, 1], contracting_dims = [3] x [2], precision = [DEFAULT, DEFAULT] : (tensor<32x4x1024x1024xf32>, tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %327 = stablehlo.custom_call @Sharding(%326) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
        %328 = stablehlo.add %248, %327 : tensor<32x4x1024x8xf32>
        %329 = stablehlo.multiply %iterArg_49, %c_53 : tensor<i32>
        %330 = stablehlo.compare  LT, %329, %c_54,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
        %331 = stablehlo.convert %329 : tensor<i32>
        %332 = stablehlo.add %331, %c_55 : tensor<i32>
        %333 = stablehlo.select %330, %332, %329 : tensor<i1>, tensor<i32>
        %334 = stablehlo.dynamic_update_slice %iterArg_50, %328, %c_56, %c_56, %333, %c_56 : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
        %c_61 = stablehlo.constant dense<1> : tensor<i32>
        %335 = stablehlo.add %iterArg_49, %c_61 : tensor<i32>
        stablehlo.return %iterArg_41, %iterArg_42, %iterArg_43, %iterArg_44, %iterArg_45, %iterArg_46, %iterArg_47, %iterArg_48, %335, %334, %325, %324 : tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024x8xf32>, tensor<32x1024xi32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>
      }
      %224 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %225 = stablehlo.compare  LT, %224, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %226 = stablehlo.convert %224 : tensor<i32>
      %227 = stablehlo.add %226, %c_38 : tensor<i32>
      %228 = stablehlo.select %225, %227, %224 : tensor<i1>, tensor<i32>
      %229 = stablehlo.dynamic_update_slice %iterArg_34, %223#10, %c_39, %c_39, %228, %c_39 : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %230 = stablehlo.multiply %iterArg_32, %c_36 : tensor<i32>
      %231 = stablehlo.compare  LT, %230, %c_37,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
      %232 = stablehlo.convert %230 : tensor<i32>
      %233 = stablehlo.add %232, %c_38 : tensor<i32>
      %234 = stablehlo.select %231, %233, %230 : tensor<i1>, tensor<i32>
      %235 = stablehlo.dynamic_update_slice %iterArg_35, %223#11, %c_39, %c_39, %234, %c_39 : (tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<i32>, tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<32x4x1024x8xf32>
      %c_40 = stablehlo.constant dense<1> : tensor<i32>
      %236 = stablehlo.add %iterArg_32, %c_40 : tensor<i32>
      stablehlo.return %iterArg, %iterArg_26, %iterArg_27, %iterArg_28, %iterArg_29, %iterArg_30, %iterArg_31, %236, %223#9, %229, %235 : tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024xf32>, tensor<32x4x1024xf32>, tensor<32x1024xi32>, tensor<i32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>, tensor<32x4x1024x8xf32>
    }
    %160 = stablehlo.custom_call @Sharding(%159#10) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %161 = call @_take_27(%35#1, %160) : (tensor<1xi32>, tensor<32x4x1024x8xf32>) -> tensor<32x3x4x1024x8xf32>
    %162 = stablehlo.custom_call @Sharding(%159#9) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %163 = call @_take_27(%34#1, %162) : (tensor<1xi32>, tensor<32x4x1024x8xf32>) -> tensor<32x3x4x1024x8xf32>
    %164 = stablehlo.add %161, %163 : tensor<32x3x4x1024x8xf32>
    %165 = stablehlo.broadcast_in_dim %cst_5, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %166 = stablehlo.divide %159#8, %165 : tensor<32x4x1024x8xf32>
    %167 = stablehlo.custom_call @Sharding(%166) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x4x1024x8xf32>) -> tensor<32x4x1024x8xf32>
    %168 = call @_take_27(%33#1, %167) : (tensor<1xi32>, tensor<32x4x1024x8xf32>) -> tensor<32x3x4x1024x8xf32>
    %169 = stablehlo.add %164, %168 : tensor<32x3x4x1024x8xf32>
    %170 = stablehlo.transpose %169, dims = [0, 3, 1, 2, 4] : (tensor<32x3x4x1024x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %171 = stablehlo.custom_call @Sharding(%170) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %cst_20 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %172 = stablehlo.reduce(%171 init: %cst_20) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x3x4x8xf32>, tensor<f32>) -> tensor<3x4x8xf32>
    %173 = stablehlo.custom_call @Sharding(%171) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %174 = stablehlo.custom_call @Sharding(%173) {backend_config = "", mhlo.sharding = "{maximal device=0}"} : (tensor<32x1024x3x4x8xf32>) -> tensor<32x1024x3x4x8xf32>
    %175 = stablehlo.dot_general %174, %22, contracting_dims = [0, 1] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x3x4x8xf32>, tensor<32x1024x32xf32>) -> tensor<3x4x8x32xf32>
    %176 = stablehlo.transpose %175, dims = [3, 0, 1, 2] : (tensor<3x4x8x32xf32>) -> tensor<32x3x4x8xf32>
    %177 = stablehlo.dot_general %174, %arg5, contracting_dims = [2, 3, 4] x [1, 2, 3], precision = [DEFAULT, DEFAULT] : (tensor<32x1024x3x4x8xf32>, tensor<32x3x4x8xf32>) -> tensor<32x1024x32xf32>
    %cst_21 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %178 = stablehlo.reduce(%177 init: %cst_21) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %179 = stablehlo.multiply %19, %177 : tensor<32x1024x32xf32>
    %180 = stablehlo.multiply %15, %179 : tensor<32x1024x32xf32>
    %181 = stablehlo.transpose %180, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_22 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %182 = stablehlo.reduce(%181 init: %cst_22) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %183 = stablehlo.multiply %182, %12 : tensor<32x1024xf32>
    %184 = call @_var_25(%6#1, %6#2, %6#3, %183) : (tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %185 = stablehlo.add %142, %184 : tensor<32x1024x32xf32>
    %186 = stablehlo.multiply %179, %17 : tensor<32x1024x32xf32>
    %187 = stablehlo.negate %186 : tensor<32x1024x32xf32>
    %188 = stablehlo.add %185, %186 : tensor<32x1024x32xf32>
    %189 = stablehlo.transpose %187, dims = [2, 0, 1] : (tensor<32x1024x32xf32>) -> tensor<32x32x1024xf32>
    %cst_23 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %190 = stablehlo.reduce(%189 init: %cst_23) applies stablehlo.add across dimensions = [0] : (tensor<32x32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %191 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %192 = stablehlo.divide %190, %191 : tensor<32x1024xf32>
    %193 = stablehlo.broadcast_in_dim %192, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %194 = stablehlo.add %188, %193 : tensor<32x1024x32xf32>
    %195 = stablehlo.multiply %177, %18 : tensor<32x1024x32xf32>
    %cst_24 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %196 = stablehlo.reduce(%195 init: %cst_24) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    %197 = stablehlo.multiply %125, %68 : tensor<32x1024x32xf32>
    %cst_25 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %198 = stablehlo.reduce(%197 init: %cst_25) applies stablehlo.add across dimensions = [0, 1] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32xf32>
    return %194, %196, %178, %176, %172, %148, %144, %198, %126, %124, %120, %103, %99 : tensor<32x1024x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x3x4x8xf32>, tensor<3x4x8xf32>, tensor<4x8x32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32x128xf32>, tensor<128xf32>, tensor<128x32xf32>, tensor<32xf32>
  }
  func.func private @_threefry_split_16(%arg0: tensor<2xui32>) -> tensor<4x2xui32> {
    %0 = stablehlo.slice %arg0 [0:1] : (tensor<2xui32>) -> tensor<1xui32>
    %1 = stablehlo.reshape %0 : (tensor<1xui32>) -> tensor<ui32>
    %2 = stablehlo.slice %arg0 [1:2] : (tensor<2xui32>) -> tensor<1xui32>
    %3 = stablehlo.reshape %2 : (tensor<1xui32>) -> tensor<ui32>
    %4 = stablehlo.iota dim = 0 : tensor<4xui64>
    %c = stablehlo.constant dense<1> : tensor<ui64>
    %5 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<ui64>) -> tensor<4xui64>
    %6 = stablehlo.multiply %5, %4 : tensor<4xui64>
    %c_0 = stablehlo.constant dense<32> : tensor<ui64>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui64>) -> tensor<4xui64>
    %8 = stablehlo.shift_right_logical %6, %7 : tensor<4xui64>
    %9 = stablehlo.convert %6 : (tensor<4xui64>) -> tensor<4xui32>
    %10 = stablehlo.convert %8 : (tensor<4xui64>) -> tensor<4xui32>
    %11:2 = call @threefry2x32_17(%1, %3, %10, %9) : (tensor<ui32>, tensor<ui32>, tensor<4xui32>, tensor<4xui32>) -> (tensor<4xui32>, tensor<4xui32>)
    %12 = stablehlo.broadcast_in_dim %11#0, dims = [0] : (tensor<4xui32>) -> tensor<4x1xui32>
    %13 = stablehlo.broadcast_in_dim %11#1, dims = [0] : (tensor<4xui32>) -> tensor<4x1xui32>
    %14 = stablehlo.concatenate %12, %13, dim = 1 : (tensor<4x1xui32>, tensor<4x1xui32>) -> tensor<4x2xui32>
    return %14 : tensor<4x2xui32>
  }
  func.func private @threefry2x32_17(%arg0: tensor<ui32>, %arg1: tensor<ui32>, %arg2: tensor<4xui32>, %arg3: tensor<4xui32>) -> (tensor<4xui32>, tensor<4xui32>) {
    %0 = stablehlo.xor %arg0, %arg1 : tensor<ui32>
    %c = stablehlo.constant dense<466688986> : tensor<ui32>
    %1 = stablehlo.xor %0, %c : tensor<ui32>
    %2 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %3 = stablehlo.add %arg2, %2 : tensor<4xui32>
    %4 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %5 = stablehlo.add %arg3, %4 : tensor<4xui32>
    %6 = stablehlo.add %3, %5 : tensor<4xui32>
    %c_0 = stablehlo.constant dense<13> : tensor<ui32>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %8 = stablehlo.shift_left %5, %7 : tensor<4xui32>
    %c_1 = stablehlo.constant dense<19> : tensor<ui32>
    %9 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %10 = stablehlo.shift_right_logical %5, %9 : tensor<4xui32>
    %11 = stablehlo.or %8, %10 : tensor<4xui32>
    %12 = stablehlo.xor %6, %11 : tensor<4xui32>
    %13 = stablehlo.add %6, %12 : tensor<4xui32>
    %c_2 = stablehlo.constant dense<15> : tensor<ui32>
    %14 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %15 = stablehlo.shift_left %12, %14 : tensor<4xui32>
    %c_3 = stablehlo.constant dense<17> : tensor<ui32>
    %16 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %17 = stablehlo.shift_right_logical %12, %16 : tensor<4xui32>
    %18 = stablehlo.or %15, %17 : tensor<4xui32>
    %19 = stablehlo.xor %13, %18 : tensor<4xui32>
    %20 = stablehlo.add %13, %19 : tensor<4xui32>
    %c_4 = stablehlo.constant dense<26> : tensor<ui32>
    %21 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %22 = stablehlo.shift_left %19, %21 : tensor<4xui32>
    %c_5 = stablehlo.constant dense<6> : tensor<ui32>
    %23 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %24 = stablehlo.shift_right_logical %19, %23 : tensor<4xui32>
    %25 = stablehlo.or %22, %24 : tensor<4xui32>
    %26 = stablehlo.xor %20, %25 : tensor<4xui32>
    %27 = stablehlo.add %20, %26 : tensor<4xui32>
    %28 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %29 = stablehlo.shift_left %26, %28 : tensor<4xui32>
    %30 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %31 = stablehlo.shift_right_logical %26, %30 : tensor<4xui32>
    %32 = stablehlo.or %29, %31 : tensor<4xui32>
    %33 = stablehlo.xor %27, %32 : tensor<4xui32>
    %34 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %35 = stablehlo.add %27, %34 : tensor<4xui32>
    %36 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %37 = stablehlo.add %33, %36 : tensor<4xui32>
    %c_6 = stablehlo.constant dense<1> : tensor<ui32>
    %38 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %39 = stablehlo.add %37, %38 : tensor<4xui32>
    %40 = stablehlo.add %35, %39 : tensor<4xui32>
    %41 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %42 = stablehlo.shift_left %39, %41 : tensor<4xui32>
    %43 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %44 = stablehlo.shift_right_logical %39, %43 : tensor<4xui32>
    %45 = stablehlo.or %42, %44 : tensor<4xui32>
    %46 = stablehlo.xor %40, %45 : tensor<4xui32>
    %47 = stablehlo.add %40, %46 : tensor<4xui32>
    %c_7 = stablehlo.constant dense<29> : tensor<ui32>
    %48 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %49 = stablehlo.shift_left %46, %48 : tensor<4xui32>
    %c_8 = stablehlo.constant dense<3> : tensor<ui32>
    %50 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %51 = stablehlo.shift_right_logical %46, %50 : tensor<4xui32>
    %52 = stablehlo.or %49, %51 : tensor<4xui32>
    %53 = stablehlo.xor %47, %52 : tensor<4xui32>
    %54 = stablehlo.add %47, %53 : tensor<4xui32>
    %c_9 = stablehlo.constant dense<16> : tensor<ui32>
    %55 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %56 = stablehlo.shift_left %53, %55 : tensor<4xui32>
    %57 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %58 = stablehlo.shift_right_logical %53, %57 : tensor<4xui32>
    %59 = stablehlo.or %56, %58 : tensor<4xui32>
    %60 = stablehlo.xor %54, %59 : tensor<4xui32>
    %61 = stablehlo.add %54, %60 : tensor<4xui32>
    %c_10 = stablehlo.constant dense<24> : tensor<ui32>
    %62 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %63 = stablehlo.shift_left %60, %62 : tensor<4xui32>
    %c_11 = stablehlo.constant dense<8> : tensor<ui32>
    %64 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %65 = stablehlo.shift_right_logical %60, %64 : tensor<4xui32>
    %66 = stablehlo.or %63, %65 : tensor<4xui32>
    %67 = stablehlo.xor %61, %66 : tensor<4xui32>
    %68 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %69 = stablehlo.add %61, %68 : tensor<4xui32>
    %70 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %71 = stablehlo.add %67, %70 : tensor<4xui32>
    %c_12 = stablehlo.constant dense<2> : tensor<ui32>
    %72 = stablehlo.broadcast_in_dim %c_12, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %73 = stablehlo.add %71, %72 : tensor<4xui32>
    %74 = stablehlo.add %69, %73 : tensor<4xui32>
    %75 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %76 = stablehlo.shift_left %73, %75 : tensor<4xui32>
    %77 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %78 = stablehlo.shift_right_logical %73, %77 : tensor<4xui32>
    %79 = stablehlo.or %76, %78 : tensor<4xui32>
    %80 = stablehlo.xor %74, %79 : tensor<4xui32>
    %81 = stablehlo.add %74, %80 : tensor<4xui32>
    %82 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %83 = stablehlo.shift_left %80, %82 : tensor<4xui32>
    %84 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %85 = stablehlo.shift_right_logical %80, %84 : tensor<4xui32>
    %86 = stablehlo.or %83, %85 : tensor<4xui32>
    %87 = stablehlo.xor %81, %86 : tensor<4xui32>
    %88 = stablehlo.add %81, %87 : tensor<4xui32>
    %89 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %90 = stablehlo.shift_left %87, %89 : tensor<4xui32>
    %91 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %92 = stablehlo.shift_right_logical %87, %91 : tensor<4xui32>
    %93 = stablehlo.or %90, %92 : tensor<4xui32>
    %94 = stablehlo.xor %88, %93 : tensor<4xui32>
    %95 = stablehlo.add %88, %94 : tensor<4xui32>
    %96 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %97 = stablehlo.shift_left %94, %96 : tensor<4xui32>
    %98 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %99 = stablehlo.shift_right_logical %94, %98 : tensor<4xui32>
    %100 = stablehlo.or %97, %99 : tensor<4xui32>
    %101 = stablehlo.xor %95, %100 : tensor<4xui32>
    %102 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %103 = stablehlo.add %95, %102 : tensor<4xui32>
    %104 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %105 = stablehlo.add %101, %104 : tensor<4xui32>
    %106 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %107 = stablehlo.add %105, %106 : tensor<4xui32>
    %108 = stablehlo.add %103, %107 : tensor<4xui32>
    %109 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %110 = stablehlo.shift_left %107, %109 : tensor<4xui32>
    %111 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %112 = stablehlo.shift_right_logical %107, %111 : tensor<4xui32>
    %113 = stablehlo.or %110, %112 : tensor<4xui32>
    %114 = stablehlo.xor %108, %113 : tensor<4xui32>
    %115 = stablehlo.add %108, %114 : tensor<4xui32>
    %116 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %117 = stablehlo.shift_left %114, %116 : tensor<4xui32>
    %118 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %119 = stablehlo.shift_right_logical %114, %118 : tensor<4xui32>
    %120 = stablehlo.or %117, %119 : tensor<4xui32>
    %121 = stablehlo.xor %115, %120 : tensor<4xui32>
    %122 = stablehlo.add %115, %121 : tensor<4xui32>
    %123 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %124 = stablehlo.shift_left %121, %123 : tensor<4xui32>
    %125 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %126 = stablehlo.shift_right_logical %121, %125 : tensor<4xui32>
    %127 = stablehlo.or %124, %126 : tensor<4xui32>
    %128 = stablehlo.xor %122, %127 : tensor<4xui32>
    %129 = stablehlo.add %122, %128 : tensor<4xui32>
    %130 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %131 = stablehlo.shift_left %128, %130 : tensor<4xui32>
    %132 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %133 = stablehlo.shift_right_logical %128, %132 : tensor<4xui32>
    %134 = stablehlo.or %131, %133 : tensor<4xui32>
    %135 = stablehlo.xor %129, %134 : tensor<4xui32>
    %136 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %137 = stablehlo.add %129, %136 : tensor<4xui32>
    %138 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %139 = stablehlo.add %135, %138 : tensor<4xui32>
    %c_13 = stablehlo.constant dense<4> : tensor<ui32>
    %140 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %141 = stablehlo.add %139, %140 : tensor<4xui32>
    %142 = stablehlo.add %137, %141 : tensor<4xui32>
    %143 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %144 = stablehlo.shift_left %141, %143 : tensor<4xui32>
    %145 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %146 = stablehlo.shift_right_logical %141, %145 : tensor<4xui32>
    %147 = stablehlo.or %144, %146 : tensor<4xui32>
    %148 = stablehlo.xor %142, %147 : tensor<4xui32>
    %149 = stablehlo.add %142, %148 : tensor<4xui32>
    %150 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %151 = stablehlo.shift_left %148, %150 : tensor<4xui32>
    %152 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %153 = stablehlo.shift_right_logical %148, %152 : tensor<4xui32>
    %154 = stablehlo.or %151, %153 : tensor<4xui32>
    %155 = stablehlo.xor %149, %154 : tensor<4xui32>
    %156 = stablehlo.add %149, %155 : tensor<4xui32>
    %157 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %158 = stablehlo.shift_left %155, %157 : tensor<4xui32>
    %159 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %160 = stablehlo.shift_right_logical %155, %159 : tensor<4xui32>
    %161 = stablehlo.or %158, %160 : tensor<4xui32>
    %162 = stablehlo.xor %156, %161 : tensor<4xui32>
    %163 = stablehlo.add %156, %162 : tensor<4xui32>
    %164 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %165 = stablehlo.shift_left %162, %164 : tensor<4xui32>
    %166 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %167 = stablehlo.shift_right_logical %162, %166 : tensor<4xui32>
    %168 = stablehlo.or %165, %167 : tensor<4xui32>
    %169 = stablehlo.xor %163, %168 : tensor<4xui32>
    %170 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %171 = stablehlo.add %163, %170 : tensor<4xui32>
    %172 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %173 = stablehlo.add %169, %172 : tensor<4xui32>
    %c_14 = stablehlo.constant dense<5> : tensor<ui32>
    %174 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<ui32>) -> tensor<4xui32>
    %175 = stablehlo.add %173, %174 : tensor<4xui32>
    return %171, %175 : tensor<4xui32>, tensor<4xui32>
  }
  func.func private @_var_18(%arg0: tensor<32x1024x32xf32>, %arg1: tensor<i32>) -> (tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>) {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %2 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024x1xf32>
    %3 = stablehlo.divide %1, %2 : tensor<32x1024x1xf32>
    %4 = stablehlo.broadcast_in_dim %3, dims = [0, 1, 2] : (tensor<32x1024x1xf32>) -> tensor<32x1024x32xf32>
    %5 = stablehlo.subtract %arg0, %4 : tensor<32x1024x32xf32>
    %6 = stablehlo.multiply %5, %5 : tensor<32x1024x32xf32>
    %cst_1 = stablehlo.constant dense<2.000000e+00> : tensor<f32>
    %7 = stablehlo.broadcast_in_dim %cst_1, dims = [] : (tensor<f32>) -> tensor<32x1024x32xf32>
    %8 = stablehlo.multiply %7, %5 : tensor<32x1024x32xf32>
    %9 = stablehlo.convert %arg1 : (tensor<i32>) -> tensor<f32>
    %10 = stablehlo.subtract %cst_0, %9 : tensor<f32>
    %cst_2 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %11 = stablehlo.reduce(%6 init: %cst_2) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %12 = stablehlo.broadcast_in_dim %10, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %13 = stablehlo.divide %11, %12 : tensor<32x1024xf32>
    %cst_3 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %14 = stablehlo.compare  GT, %10, %cst_3,  FLOAT : (tensor<f32>, tensor<f32>) -> tensor<i1>
    %cst_4 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %15 = call @_where_19(%14, %13, %cst_4) : (tensor<i1>, tensor<32x1024xf32>, tensor<f32>) -> tensor<32x1024xf32>
    return %15, %8, %10, %14 : tensor<32x1024xf32>, tensor<32x1024x32xf32>, tensor<f32>, tensor<i1>
  }
  func.func private @_where_19(%arg0: tensor<i1>, %arg1: tensor<32x1024xf32>, %arg2: tensor<f32>) -> tensor<32x1024xf32> {
    %0 = stablehlo.convert %arg2 : tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %2 = stablehlo.select %arg0, %arg1, %1 : tensor<i1>, tensor<32x1024xf32>
    return %2 : tensor<32x1024xf32>
  }
  func.func private @_threefry_split_20(%arg0: tensor<2xui32>) -> tensor<3x2xui32> {
    %0 = stablehlo.slice %arg0 [0:1] : (tensor<2xui32>) -> tensor<1xui32>
    %1 = stablehlo.reshape %0 : (tensor<1xui32>) -> tensor<ui32>
    %2 = stablehlo.slice %arg0 [1:2] : (tensor<2xui32>) -> tensor<1xui32>
    %3 = stablehlo.reshape %2 : (tensor<1xui32>) -> tensor<ui32>
    %4 = stablehlo.iota dim = 0 : tensor<3xui64>
    %c = stablehlo.constant dense<1> : tensor<ui64>
    %5 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<ui64>) -> tensor<3xui64>
    %6 = stablehlo.multiply %5, %4 : tensor<3xui64>
    %c_0 = stablehlo.constant dense<32> : tensor<ui64>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui64>) -> tensor<3xui64>
    %8 = stablehlo.shift_right_logical %6, %7 : tensor<3xui64>
    %9 = stablehlo.convert %6 : (tensor<3xui64>) -> tensor<3xui32>
    %10 = stablehlo.convert %8 : (tensor<3xui64>) -> tensor<3xui32>
    %11:2 = call @threefry2x32_21(%1, %3, %10, %9) : (tensor<ui32>, tensor<ui32>, tensor<3xui32>, tensor<3xui32>) -> (tensor<3xui32>, tensor<3xui32>)
    %12 = stablehlo.broadcast_in_dim %11#0, dims = [0] : (tensor<3xui32>) -> tensor<3x1xui32>
    %13 = stablehlo.broadcast_in_dim %11#1, dims = [0] : (tensor<3xui32>) -> tensor<3x1xui32>
    %14 = stablehlo.concatenate %12, %13, dim = 1 : (tensor<3x1xui32>, tensor<3x1xui32>) -> tensor<3x2xui32>
    return %14 : tensor<3x2xui32>
  }
  func.func private @threefry2x32_21(%arg0: tensor<ui32>, %arg1: tensor<ui32>, %arg2: tensor<3xui32>, %arg3: tensor<3xui32>) -> (tensor<3xui32>, tensor<3xui32>) {
    %0 = stablehlo.xor %arg0, %arg1 : tensor<ui32>
    %c = stablehlo.constant dense<466688986> : tensor<ui32>
    %1 = stablehlo.xor %0, %c : tensor<ui32>
    %2 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %3 = stablehlo.add %arg2, %2 : tensor<3xui32>
    %4 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %5 = stablehlo.add %arg3, %4 : tensor<3xui32>
    %6 = stablehlo.add %3, %5 : tensor<3xui32>
    %c_0 = stablehlo.constant dense<13> : tensor<ui32>
    %7 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %8 = stablehlo.shift_left %5, %7 : tensor<3xui32>
    %c_1 = stablehlo.constant dense<19> : tensor<ui32>
    %9 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %10 = stablehlo.shift_right_logical %5, %9 : tensor<3xui32>
    %11 = stablehlo.or %8, %10 : tensor<3xui32>
    %12 = stablehlo.xor %6, %11 : tensor<3xui32>
    %13 = stablehlo.add %6, %12 : tensor<3xui32>
    %c_2 = stablehlo.constant dense<15> : tensor<ui32>
    %14 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %15 = stablehlo.shift_left %12, %14 : tensor<3xui32>
    %c_3 = stablehlo.constant dense<17> : tensor<ui32>
    %16 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %17 = stablehlo.shift_right_logical %12, %16 : tensor<3xui32>
    %18 = stablehlo.or %15, %17 : tensor<3xui32>
    %19 = stablehlo.xor %13, %18 : tensor<3xui32>
    %20 = stablehlo.add %13, %19 : tensor<3xui32>
    %c_4 = stablehlo.constant dense<26> : tensor<ui32>
    %21 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %22 = stablehlo.shift_left %19, %21 : tensor<3xui32>
    %c_5 = stablehlo.constant dense<6> : tensor<ui32>
    %23 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %24 = stablehlo.shift_right_logical %19, %23 : tensor<3xui32>
    %25 = stablehlo.or %22, %24 : tensor<3xui32>
    %26 = stablehlo.xor %20, %25 : tensor<3xui32>
    %27 = stablehlo.add %20, %26 : tensor<3xui32>
    %28 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %29 = stablehlo.shift_left %26, %28 : tensor<3xui32>
    %30 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %31 = stablehlo.shift_right_logical %26, %30 : tensor<3xui32>
    %32 = stablehlo.or %29, %31 : tensor<3xui32>
    %33 = stablehlo.xor %27, %32 : tensor<3xui32>
    %34 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %35 = stablehlo.add %27, %34 : tensor<3xui32>
    %36 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %37 = stablehlo.add %33, %36 : tensor<3xui32>
    %c_6 = stablehlo.constant dense<1> : tensor<ui32>
    %38 = stablehlo.broadcast_in_dim %c_6, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %39 = stablehlo.add %37, %38 : tensor<3xui32>
    %40 = stablehlo.add %35, %39 : tensor<3xui32>
    %41 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %42 = stablehlo.shift_left %39, %41 : tensor<3xui32>
    %43 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %44 = stablehlo.shift_right_logical %39, %43 : tensor<3xui32>
    %45 = stablehlo.or %42, %44 : tensor<3xui32>
    %46 = stablehlo.xor %40, %45 : tensor<3xui32>
    %47 = stablehlo.add %40, %46 : tensor<3xui32>
    %c_7 = stablehlo.constant dense<29> : tensor<ui32>
    %48 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %49 = stablehlo.shift_left %46, %48 : tensor<3xui32>
    %c_8 = stablehlo.constant dense<3> : tensor<ui32>
    %50 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %51 = stablehlo.shift_right_logical %46, %50 : tensor<3xui32>
    %52 = stablehlo.or %49, %51 : tensor<3xui32>
    %53 = stablehlo.xor %47, %52 : tensor<3xui32>
    %54 = stablehlo.add %47, %53 : tensor<3xui32>
    %c_9 = stablehlo.constant dense<16> : tensor<ui32>
    %55 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %56 = stablehlo.shift_left %53, %55 : tensor<3xui32>
    %57 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %58 = stablehlo.shift_right_logical %53, %57 : tensor<3xui32>
    %59 = stablehlo.or %56, %58 : tensor<3xui32>
    %60 = stablehlo.xor %54, %59 : tensor<3xui32>
    %61 = stablehlo.add %54, %60 : tensor<3xui32>
    %c_10 = stablehlo.constant dense<24> : tensor<ui32>
    %62 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %63 = stablehlo.shift_left %60, %62 : tensor<3xui32>
    %c_11 = stablehlo.constant dense<8> : tensor<ui32>
    %64 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %65 = stablehlo.shift_right_logical %60, %64 : tensor<3xui32>
    %66 = stablehlo.or %63, %65 : tensor<3xui32>
    %67 = stablehlo.xor %61, %66 : tensor<3xui32>
    %68 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %69 = stablehlo.add %61, %68 : tensor<3xui32>
    %70 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %71 = stablehlo.add %67, %70 : tensor<3xui32>
    %c_12 = stablehlo.constant dense<2> : tensor<ui32>
    %72 = stablehlo.broadcast_in_dim %c_12, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %73 = stablehlo.add %71, %72 : tensor<3xui32>
    %74 = stablehlo.add %69, %73 : tensor<3xui32>
    %75 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %76 = stablehlo.shift_left %73, %75 : tensor<3xui32>
    %77 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %78 = stablehlo.shift_right_logical %73, %77 : tensor<3xui32>
    %79 = stablehlo.or %76, %78 : tensor<3xui32>
    %80 = stablehlo.xor %74, %79 : tensor<3xui32>
    %81 = stablehlo.add %74, %80 : tensor<3xui32>
    %82 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %83 = stablehlo.shift_left %80, %82 : tensor<3xui32>
    %84 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %85 = stablehlo.shift_right_logical %80, %84 : tensor<3xui32>
    %86 = stablehlo.or %83, %85 : tensor<3xui32>
    %87 = stablehlo.xor %81, %86 : tensor<3xui32>
    %88 = stablehlo.add %81, %87 : tensor<3xui32>
    %89 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %90 = stablehlo.shift_left %87, %89 : tensor<3xui32>
    %91 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %92 = stablehlo.shift_right_logical %87, %91 : tensor<3xui32>
    %93 = stablehlo.or %90, %92 : tensor<3xui32>
    %94 = stablehlo.xor %88, %93 : tensor<3xui32>
    %95 = stablehlo.add %88, %94 : tensor<3xui32>
    %96 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %97 = stablehlo.shift_left %94, %96 : tensor<3xui32>
    %98 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %99 = stablehlo.shift_right_logical %94, %98 : tensor<3xui32>
    %100 = stablehlo.or %97, %99 : tensor<3xui32>
    %101 = stablehlo.xor %95, %100 : tensor<3xui32>
    %102 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %103 = stablehlo.add %95, %102 : tensor<3xui32>
    %104 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %105 = stablehlo.add %101, %104 : tensor<3xui32>
    %106 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %107 = stablehlo.add %105, %106 : tensor<3xui32>
    %108 = stablehlo.add %103, %107 : tensor<3xui32>
    %109 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %110 = stablehlo.shift_left %107, %109 : tensor<3xui32>
    %111 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %112 = stablehlo.shift_right_logical %107, %111 : tensor<3xui32>
    %113 = stablehlo.or %110, %112 : tensor<3xui32>
    %114 = stablehlo.xor %108, %113 : tensor<3xui32>
    %115 = stablehlo.add %108, %114 : tensor<3xui32>
    %116 = stablehlo.broadcast_in_dim %c_7, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %117 = stablehlo.shift_left %114, %116 : tensor<3xui32>
    %118 = stablehlo.broadcast_in_dim %c_8, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %119 = stablehlo.shift_right_logical %114, %118 : tensor<3xui32>
    %120 = stablehlo.or %117, %119 : tensor<3xui32>
    %121 = stablehlo.xor %115, %120 : tensor<3xui32>
    %122 = stablehlo.add %115, %121 : tensor<3xui32>
    %123 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %124 = stablehlo.shift_left %121, %123 : tensor<3xui32>
    %125 = stablehlo.broadcast_in_dim %c_9, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %126 = stablehlo.shift_right_logical %121, %125 : tensor<3xui32>
    %127 = stablehlo.or %124, %126 : tensor<3xui32>
    %128 = stablehlo.xor %122, %127 : tensor<3xui32>
    %129 = stablehlo.add %122, %128 : tensor<3xui32>
    %130 = stablehlo.broadcast_in_dim %c_10, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %131 = stablehlo.shift_left %128, %130 : tensor<3xui32>
    %132 = stablehlo.broadcast_in_dim %c_11, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %133 = stablehlo.shift_right_logical %128, %132 : tensor<3xui32>
    %134 = stablehlo.or %131, %133 : tensor<3xui32>
    %135 = stablehlo.xor %129, %134 : tensor<3xui32>
    %136 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %137 = stablehlo.add %129, %136 : tensor<3xui32>
    %138 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %139 = stablehlo.add %135, %138 : tensor<3xui32>
    %c_13 = stablehlo.constant dense<4> : tensor<ui32>
    %140 = stablehlo.broadcast_in_dim %c_13, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %141 = stablehlo.add %139, %140 : tensor<3xui32>
    %142 = stablehlo.add %137, %141 : tensor<3xui32>
    %143 = stablehlo.broadcast_in_dim %c_0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %144 = stablehlo.shift_left %141, %143 : tensor<3xui32>
    %145 = stablehlo.broadcast_in_dim %c_1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %146 = stablehlo.shift_right_logical %141, %145 : tensor<3xui32>
    %147 = stablehlo.or %144, %146 : tensor<3xui32>
    %148 = stablehlo.xor %142, %147 : tensor<3xui32>
    %149 = stablehlo.add %142, %148 : tensor<3xui32>
    %150 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %151 = stablehlo.shift_left %148, %150 : tensor<3xui32>
    %152 = stablehlo.broadcast_in_dim %c_3, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %153 = stablehlo.shift_right_logical %148, %152 : tensor<3xui32>
    %154 = stablehlo.or %151, %153 : tensor<3xui32>
    %155 = stablehlo.xor %149, %154 : tensor<3xui32>
    %156 = stablehlo.add %149, %155 : tensor<3xui32>
    %157 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %158 = stablehlo.shift_left %155, %157 : tensor<3xui32>
    %159 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %160 = stablehlo.shift_right_logical %155, %159 : tensor<3xui32>
    %161 = stablehlo.or %158, %160 : tensor<3xui32>
    %162 = stablehlo.xor %156, %161 : tensor<3xui32>
    %163 = stablehlo.add %156, %162 : tensor<3xui32>
    %164 = stablehlo.broadcast_in_dim %c_5, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %165 = stablehlo.shift_left %162, %164 : tensor<3xui32>
    %166 = stablehlo.broadcast_in_dim %c_4, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %167 = stablehlo.shift_right_logical %162, %166 : tensor<3xui32>
    %168 = stablehlo.or %165, %167 : tensor<3xui32>
    %169 = stablehlo.xor %163, %168 : tensor<3xui32>
    %170 = stablehlo.broadcast_in_dim %1, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %171 = stablehlo.add %163, %170 : tensor<3xui32>
    %172 = stablehlo.broadcast_in_dim %arg0, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %173 = stablehlo.add %169, %172 : tensor<3xui32>
    %c_14 = stablehlo.constant dense<5> : tensor<ui32>
    %174 = stablehlo.broadcast_in_dim %c_14, dims = [] : (tensor<ui32>) -> tensor<3xui32>
    %175 = stablehlo.add %173, %174 : tensor<3xui32>
    return %171, %175 : tensor<3xui32>, tensor<3xui32>
  }
  func.func private @_take_22(%arg0: tensor<32x3x4x1024x8xf32>, %arg1: tensor<i32>) -> (tensor<32x4x1024x8xf32>, tensor<1xi32>) {
    %c = stablehlo.constant dense<0> : tensor<i32>
    %0 = stablehlo.compare  LT, %arg1, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %c_0 = stablehlo.constant dense<3> : tensor<i32>
    %1 = stablehlo.add %arg1, %c_0 : tensor<i32>
    %2 = call @_where_23(%0, %1, %arg1) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [] : (tensor<i32>) -> tensor<1xi32>
    %c_1 = stablehlo.constant dense<2> : tensor<1xi32>
    %4 = stablehlo.convert %3 : tensor<1xi32>
    %c_2 = stablehlo.constant dense<0> : tensor<i32>
    %5 = stablehlo.broadcast_in_dim %c_2, dims = [] : (tensor<i32>) -> tensor<1xi32>
    %6 = stablehlo.compare  GE, %4, %5,  SIGNED : (tensor<1xi32>, tensor<1xi32>) -> tensor<1xi1>
    %7 = stablehlo.compare  LE, %4, %c_1,  SIGNED : (tensor<1xi32>, tensor<1xi32>) -> tensor<1xi1>
    %8 = stablehlo.and %6, %7 : tensor<1xi1>
    %c_3 = stablehlo.constant dense<true> : tensor<i1>
    %9 = stablehlo.reduce(%8 init: %c_3) applies stablehlo.and across dimensions = [0] : (tensor<1xi1>, tensor<i1>) -> tensor<i1>
    %10 = "stablehlo.gather"(%arg0, %4) <{dimension_numbers = #stablehlo.gather<offset_dims = [0, 1, 2, 3], collapsed_slice_dims = [1], start_index_map = [1]>, indices_are_sorted = false, slice_sizes = array<i64: 32, 1, 4, 1024, 8>}> : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>) -> tensor<32x4x1024x8xf32>
    %11 = stablehlo.broadcast_in_dim %9, dims = [] : (tensor<i1>) -> tensor<32x4x1024x8xi1>
    %cst = stablehlo.constant dense<0x7FC00000> : tensor<f32>
    %12 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x4x1024x8xf32>
    %13 = stablehlo.select %11, %10, %12 : tensor<32x4x1024x8xi1>, tensor<32x4x1024x8xf32>
    return %13, %3 : tensor<32x4x1024x8xf32>, tensor<1xi32>
  }
  func.func private @_where_23(%arg0: tensor<i1>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<i32>
    return %0 : tensor<i32>
  }
  func.func private @_where_24(%arg0: tensor<32x4x1024x1024xi1>, %arg1: tensor<32x4x1024x1024xf32>, %arg2: tensor<f32>) -> tensor<32x4x1024x1024xf32> {
    %0 = stablehlo.convert %arg2 : tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x4x1024x1024xf32>
    %2 = stablehlo.select %arg0, %arg1, %1 : tensor<32x4x1024x1024xi1>, tensor<32x4x1024x1024xf32>
    return %2 : tensor<32x4x1024x1024xf32>
  }
  func.func private @_var_25(%arg0: tensor<32x1024x32xf32>, %arg1: tensor<f32>, %arg2: tensor<i1>, %arg3: tensor<32x1024xf32>) -> tensor<32x1024x32xf32> {
    %0 = call @_where_26(%arg2, %arg3) : (tensor<i1>, tensor<32x1024xf32>) -> tensor<32x1024xf32>
    %1 = stablehlo.broadcast_in_dim %arg1, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %2 = stablehlo.divide %0, %1 : tensor<32x1024xf32>
    %3 = stablehlo.broadcast_in_dim %2, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %4 = stablehlo.multiply %3, %arg0 : tensor<32x1024x32xf32>
    %5 = stablehlo.negate %4 : tensor<32x1024x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %6 = stablehlo.reduce(%5 init: %cst) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x32xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %7 = stablehlo.reshape %6 : (tensor<32x1024xf32>) -> tensor<32x1024x1xf32>
    %cst_0 = stablehlo.constant dense<3.200000e+01> : tensor<f32>
    %8 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<32x1024x1xf32>
    %9 = stablehlo.divide %7, %8 : tensor<32x1024x1xf32>
    %cst_1 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %10 = stablehlo.reduce(%9 init: %cst_1) applies stablehlo.add across dimensions = [2] : (tensor<32x1024x1xf32>, tensor<f32>) -> tensor<32x1024xf32>
    %11 = stablehlo.broadcast_in_dim %10, dims = [0, 1] : (tensor<32x1024xf32>) -> tensor<32x1024x32xf32>
    %12 = stablehlo.add %4, %11 : tensor<32x1024x32xf32>
    return %12 : tensor<32x1024x32xf32>
  }
  func.func private @_where_26(%arg0: tensor<i1>, %arg1: tensor<32x1024xf32>) -> tensor<32x1024xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<32x1024xf32>
    %1 = stablehlo.select %arg0, %arg1, %0 : tensor<i1>, tensor<32x1024xf32>
    return %1 : tensor<32x1024xf32>
  }
  func.func private @_take_27(%arg0: tensor<1xi32>, %arg1: tensor<32x4x1024x8xf32>) -> tensor<32x3x4x1024x8xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<32x3x4x1024x8xf32>
    %2 = "stablehlo.scatter"(%1, %arg0, %arg1) <{indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [0, 1, 2, 3], inserted_window_dims = [1], scatter_dims_to_operand_dims = [1]>, unique_indices = false}> ({
    ^bb0(%arg2: tensor<f32>, %arg3: tensor<f32>):
      %3 = stablehlo.add %arg2, %arg3 : tensor<f32>
      stablehlo.return %3 : tensor<f32>
    }) : (tensor<32x3x4x1024x8xf32>, tensor<1xi32>, tensor<32x4x1024x8xf32>) -> tensor<32x3x4x1024x8xf32>
    return %2 : tensor<32x3x4x1024x8xf32>
  }
  func.func private @_take_28(%arg0: tensor<1024x1xi32>, %arg1: tensor<1024x32xf32>) -> tensor<1024x32xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<1024x32xf32>
    %2 = "stablehlo.scatter"(%1, %arg0, %arg1) <{indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [1], inserted_window_dims = [0], scatter_dims_to_operand_dims = [0], index_vector_dim = 1>, unique_indices = false}> ({
    ^bb0(%arg2: tensor<f32>, %arg3: tensor<f32>):
      %3 = stablehlo.add %arg2, %arg3 : tensor<f32>
      stablehlo.return %3 : tensor<f32>
    }) : (tensor<1024x32xf32>, tensor<1024x1xi32>, tensor<1024x32xf32>) -> tensor<1024x32xf32>
    return %2 : tensor<1024x32xf32>
  }
  func.func private @_take_29(%arg0: tensor<32x1024x1xi32>, %arg1: tensor<32x1024x32xf32>) -> tensor<50257x32xf32> {
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %0 = stablehlo.broadcast_in_dim %cst, dims = [] : (tensor<f32>) -> tensor<f32>
    %1 = stablehlo.broadcast_in_dim %0, dims = [] : (tensor<f32>) -> tensor<50257x32xf32>
    %2 = "stablehlo.scatter"(%1, %arg0, %arg1) <{indices_are_sorted = false, scatter_dimension_numbers = #stablehlo.scatter<update_window_dims = [2], inserted_window_dims = [0], scatter_dims_to_operand_dims = [0], index_vector_dim = 2>, unique_indices = false}> ({
    ^bb0(%arg2: tensor<f32>, %arg3: tensor<f32>):
      %3 = stablehlo.add %arg2, %arg3 : tensor<f32>
      stablehlo.return %3 : tensor<f32>
    }) : (tensor<50257x32xf32>, tensor<32x1024x1xi32>, tensor<32x1024x32xf32>) -> tensor<50257x32xf32>
    return %2 : tensor<50257x32xf32>
  }
  func.func private @clip(%arg0: tensor<i32>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.convert %arg1 : tensor<i32>
    %1 = stablehlo.maximum %0, %arg0 : tensor<i32>
    %2 = stablehlo.convert %arg2 : tensor<i32>
    %3 = stablehlo.minimum %2, %1 : tensor<i32>
    return %3 : tensor<i32>
  }
  func.func private @_where_30(%arg0: tensor<i1>, %arg1: tensor<f32>, %arg2: tensor<f32>) -> tensor<f32> {
    %0 = stablehlo.convert %arg2 : tensor<f32>
    %1 = stablehlo.select %arg0, %arg1, %0 : tensor<i1>, tensor<f32>
    return %1 : tensor<f32>
  }
  func.func private @_where_31(%arg0: tensor<i1>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<i32>
    return %0 : tensor<i32>
  }
  func.func private @remainder(%arg0: tensor<i32>, %arg1: tensor<i32>) -> tensor<i32> {
    %c = stablehlo.constant dense<0> : tensor<i32>
    %0 = stablehlo.compare  EQ, %arg1, %c,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %c_0 = stablehlo.constant dense<1> : tensor<i32>
    %1 = call @_where_32(%0, %c_0, %arg1) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>
    %2 = stablehlo.remainder %arg0, %1 : tensor<i32>
    %c_1 = stablehlo.constant dense<0> : tensor<i32>
    %3 = stablehlo.compare  NE, %2, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %4 = stablehlo.compare  LT, %2, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %5 = stablehlo.compare  LT, %1, %c_1,  SIGNED : (tensor<i32>, tensor<i32>) -> tensor<i1>
    %6 = stablehlo.compare  NE, %4, %5,  UNSIGNED : (tensor<i1>, tensor<i1>) -> tensor<i1>
    %7 = stablehlo.and %6, %3 : tensor<i1>
    %8 = stablehlo.add %2, %1 : tensor<i32>
    %9 = stablehlo.select %7, %8, %2 : tensor<i1>, tensor<i32>
    return %9 : tensor<i32>
  }
  func.func private @_where_32(%arg0: tensor<i1>, %arg1: tensor<i32>, %arg2: tensor<i32>) -> tensor<i32> {
    %0 = stablehlo.select %arg0, %arg1, %arg2 : tensor<i1>, tensor<i32>
    return %0 : tensor<i32>
  }
  func.func private @norm(%arg0: tensor<2x32xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<2x32xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_33(%arg0: tensor<2x32x3x4x8xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x32x3x4x8xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1, 2, 3, 4] : (tensor<2x32x3x4x8xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_34(%arg0: tensor<2x3x4x8xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x3x4x8xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1, 2, 3] : (tensor<2x3x4x8xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_35(%arg0: tensor<2x4x8x32xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x4x8x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1, 2, 3] : (tensor<2x4x8x32xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_36(%arg0: tensor<2x32x128xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x32x128xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1, 2] : (tensor<2x32x128xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_37(%arg0: tensor<2x128xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x128xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<2x128xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_38(%arg0: tensor<2x128x32xf32>) -> tensor<2xf32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x128x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [1, 2] : (tensor<2x128x32xf32>, tensor<f32>) -> tensor<2xf32>
    %2 = stablehlo.sqrt %1 : tensor<2xf32>
    return %2 : tensor<2xf32>
  }
  func.func private @norm_39(%arg0: tensor<32xf32>) -> tensor<f32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [0] : (tensor<32xf32>, tensor<f32>) -> tensor<f32>
    %2 = stablehlo.sqrt %1 : tensor<f32>
    return %2 : tensor<f32>
  }
  func.func private @norm_40(%arg0: tensor<50257x32xf32>) -> tensor<f32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<50257x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [0, 1] : (tensor<50257x32xf32>, tensor<f32>) -> tensor<f32>
    %2 = stablehlo.sqrt %1 : tensor<f32>
    return %2 : tensor<f32>
  }
  func.func private @norm_41(%arg0: tensor<1024x32xf32>) -> tensor<f32> {
    %0 = stablehlo.multiply %arg0, %arg0 : tensor<1024x32xf32>
    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>
    %1 = stablehlo.reduce(%0 init: %cst) applies stablehlo.add across dimensions = [0, 1] : (tensor<1024x32xf32>, tensor<f32>) -> tensor<f32>
    %2 = stablehlo.sqrt %1 : tensor<f32>
    return %2 : tensor<f32>
  }
}
