{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\anaconda3\\envs\\levanter2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-22 17:30:14,345\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"extern/levanter/src\")\n",
    "\n",
    "from transformers import RobertaConfig as HFRobertaConfig\n",
    "from transformers import RobertaForMaskedLM as HFRobertaForMaskedLM\n",
    "from extern.levanter.src.levanter.models.roberta import RobertaConfig\n",
    "from extern.levanter.src.levanter.models.roberta import RobertaForMaskedLM\n",
    "\n",
    "import jax\n",
    "import jax.random as jrandom\n",
    "import jax.numpy as jnp\n",
    "import haliax as hax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\My_Documents\\bigbert\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 203/203 [00:10<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab(50265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\anaconda3\\envs\\levanter2\\lib\\site-packages\\haliax\\partitioning.py:116: RuntimeWarning: No resource mapping found. Not sharding.\n",
      "  warnings.warn(\"No resource mapping found. Not sharding.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "def load_weights_from_hf():\n",
    "    # Load the Hugging Face model\n",
    "    hf_model = HFRobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "    hf_config = HFRobertaConfig.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    hf_config.hidden_dropout_prob = 0\n",
    "    hf_config.attention_probs_dropout_prob = 0\n",
    "    # hf_config.pad_token_id = -1\n",
    "\n",
    "    lv_config = RobertaConfig.from_hf_config(hf_config)\n",
    "\n",
    "    converter = lv_config.hf_checkpoint_converter()\n",
    "\n",
    "    model = converter.load_pretrained(\n",
    "        lv_config.model_type,\n",
    "        lv_config,\n",
    "        axis_mapping=None, \n",
    "        dtype=\"float32\",  \n",
    "    )\n",
    "\n",
    "    print(converter.Vocab)\n",
    "    \n",
    "    #print(\"Weights loaded successfully.\")\n",
    "    return model, lv_config, hf_model, hf_config\n",
    "\n",
    "lv_model, lv_config, hf_model, hf_config = load_weights_from_hf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n",
      "50265\n",
      "514\n",
      "514\n"
     ]
    }
   ],
   "source": [
    "print(lv_config.vocab_size)\n",
    "print(hf_config.vocab_size)\n",
    "\n",
    "print(lv_config.max_position_embeddings)\n",
    "print(hf_config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_to_tensor(named_array):\n",
    "    out_tensor = torch.tensor(np.array(named_array.array))\n",
    "    return out_tensor\n",
    "\n",
    "def tensor_to_named(in_tensor, axes):\n",
    "    named_array = hax.NamedArray(np.array(in_tensor), axes)\n",
    "    return named_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outputs\n",
    "def check(my_out, hf_out, precision=1e-4):\n",
    "    acc = np.isclose(hf_out, my_out, rtol=precision, atol=precision).mean()\n",
    "    diff = np.abs(my_out - hf_out).mean()\n",
    "    return f\"Accuracy: {acc:.4f}, Avg Difference: {diff:.6f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = hax.Axis(\"batch\", 1)\n",
    "Pos = lv_config.Pos\n",
    "KeyPos = lv_config.KeyPos\n",
    "Vocab = hax.Axis(\"vocab\", tokenizer.vocab_size)\n",
    "\n",
    "key = jrandom.PRNGKey(42)\n",
    "key_var, key_model = jrandom.split(key, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = tokenizer(\"Mark <mask> is the CEO of Facebook, located in <mask> <mask>, California.\", return_tensors=\"pt\", padding='max_length', max_length=514)\n",
    "prompt = tokenizer(\"Paris is the <mask> of France.\", return_tensors=\"pt\", padding='max_length', max_length=514)\n",
    "# prompt = tokenizer(\"Mark Zuckerberg is the boss of Facebook, located in Palo Alto, California.\", return_tensors=\"pt\", padding='max_length', max_length=514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_prompt = {\"input_ids\": tensor_to_named(prompt[\"input_ids\"], (Batch, Pos)), \"attention_mask\": tensor_to_named(prompt[\"attention_mask\"], (Batch, KeyPos))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask_tensor = torch.ones(size = (Batch.size, Pos.size), dtype = int)\n",
    "# prompt[\"attention_mask\"] = attention_mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lv_prompt = {k: hax.NamedArray(np.array((prompt[k])), axes = (Batch, Pos)) for k in prompt.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = hax.random.randint(key_var, shape = (Batch, Pos), minval = lv_config.eos_token_id+1, maxval = lv_config.vocab_size)\n",
    "# attention_mask = hax.ones(shape = (Batch, Pos), dtype=int)\n",
    "\n",
    "# input_ids_tensor = named_to_tensor(input_ids)\n",
    "# attention_mask_tensor = named_to_tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = haliax.random.randint(jax.random.PRNGKey(42), shape = (haliax.Axis(\"batch\", 1), haliax.Axis(\"position\", 512)), minval = 4, maxval = 50265)\n",
    "# input_ids = torch.ones((1, 512), dtype=int) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_tensor = torch.randint(low = 5, high = 50265, size = 514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_tensor = torch.randint(low = lv_config.eos_token_id+1, high = lv_config.vocab_size, size = (Batch.size, Pos.size))\n",
    "# # input_ids_tensor[:, 0] = 0\n",
    "# # input_ids_tensor[:, (lv_config.max_position_embeddings // 2):] = 1\n",
    "# # input_ids_tensor[:, (lv_config.max_position_embeddings // 2)] = 2\n",
    "\n",
    "# # # input_ids_tensor = torch.ones((Batch.size, Pos.size), dtype=int) * 100\n",
    "\n",
    "# idx = torch.randint(low = 1, high=lv_config.max_position_embeddings, size = (1,))\n",
    "# # idx = lv_config.max_position_embeddings // 2\n",
    "\n",
    "# attention_mask_tensor = torch.ones(size = (Batch.size, KeyPos.size), dtype = int)\n",
    "# # attention_mask_tensor[:, idx:] = 0\n",
    "\n",
    "# attention_mask = tensor_to_named(attention_mask_tensor, (Batch, KeyPos))\n",
    "\n",
    "# # # attention_mask_tensor = torch.ones(size = (Batch.size, Pos.size), dtype = int)\n",
    "# # # attention_mask_tensor[:, idx:] = 0\n",
    "\n",
    "# # # attention_mask = tensor_to_named(attention_mask_tensor, (Batch, KeyPos))\n",
    "\n",
    "# input_ids = tensor_to_named(input_ids_tensor, (Batch, Pos))\n",
    "# prompt = {\"input_ids\": input_ids_tensor, \"attention_mask\": attention_mask_tensor}\n",
    "# lv_prompt = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "# # # prompt = {\"input_ids\": input_ids_tensor}\n",
    "# # # lv_prompt = {\"input_ids\": input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = {\"input_ids\": input_ids_tensor, \"attention_mask\": attention_mask_tensor}\n",
    "# lv_prompt = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_position_ids_from_input_ids(input_ids, past_key_values_length=0):\n",
    "#     mask = hax.not_equal(input_ids, lv_config.pad_token_id) * 1\n",
    "#     incremental_indices = (hax.cumsum(mask, axis=lv_config.Pos).astype(mask) + past_key_values_length) * mask\n",
    "#     incremental_indices -= mask.all(axis=Pos)\n",
    "#     return incremental_indices + lv_config.pad_token_id\n",
    "\n",
    "# def create_position_ids_from_input_ids(input_ids, past_key_values_length=0):\n",
    "#     return hax.arange(axis = Pos, start = 0, dtype=jnp.int32)\n",
    "\n",
    "def create_position_ids_from_input_ids(input_ids, PosInput, past_key_values_length=0):\n",
    "    mask = hax.not_equal(input_ids, lv_config.pad_token_id) * 1\n",
    "    incremental_indices = (hax.cumsum(mask, axis=PosInput).astype(mask) + past_key_values_length) * mask\n",
    "    incremental_indices -= mask.all(axis=PosInput) * lv_config.pad_token_id\n",
    "    return incremental_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict = hf_model.state_dict()\n",
    "# print(dict[\"roberta.embeddings.position_embeddings.weight\"].shape)\n",
    "# print(dict[\"roberta.embeddings.position_embeddings.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_ids = create_position_ids_from_input_ids(lv_prompt[\"input_ids\"], Pos)\n",
    "\n",
    "lv_prompt[\"position_ids\"] = position_ids\n",
    "prompt[\"position_ids\"] = torch.from_numpy(np.array(position_ids.array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000, Avg Difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(check(np.array(lv_prompt[\"input_ids\"].array), np.array(prompt[\"input_ids\"])))\n",
    "# print(check(np.array(lv_prompt[\"attention_mask\"].array), np.array(prompt[\"attention_mask\"])))\n",
    "# print(check(np.array(lv_prompt[\"position_ids\"].array), np.array(prompt[\"position_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,   287,     5,  8603, 13802, 50264,   109,    45,  5152,     6,\n",
      "             5,  2853,   364, 22448,  1790,     9,     5,  7155,   811,  2938,\n",
      "         14958,     5,  4286, 50264, 27099,  3069, 34337,    11,   645,     7,\n",
      "          2142,   106,    15, 10779,    14,    74,  3680,   146,  7155,   493,\n",
      "          2217, 50264,    11,     5,   997,     4,   616,    23,   498, 50264,\n",
      "          1364,     7, 50264,  2093,     6,   215,    25,    10, 50264,  5853,\n",
      "         29471, 50264, 50264,  4284,     6,    97,  3365,  1303,  1402,   453,\n",
      "         50264,     5, 41977,  1187,   372, 13250,     4,   509,   215,   919,\n",
      "             6, 50264,  7150,     6,  3374,    98, 33415,    14,    37,  4091,\n",
      "         50264,  1790,    39, 50264, 50264, 23487,    88,     5,  5546,     9,\n",
      "          2912,   424,  1571, 50264,     6,  7391,     7,     5,  5631,     9,\n",
      "           211,  9636,  7305, 50264,  1850, 50264,    49,   884,     6, 25000,\n",
      "          1180,     4,   497,     5,   276,    86,     6,  4785,   624,  7155,\n",
      "           811,  2938,  9539,   517,     7, 24300,     5,  8603, 13802,    11,\n",
      "           645,     7,  1744, 50264,   308,  3168,     4,   289,  9968,    30,\n",
      "           258,  4181,     8, 11058,     6,     8, 50264, 50264,     5,  2621,\n",
      "             9,    10, 40048,   624,    49,  5546, 50264, 50264, 41977,  1187,\n",
      "         12420,   517,     7,   489,  1235,  4299,   150,    23,     5,   276,\n",
      "            86,  1032,     7, 50264,     5,  7155,   811,   997,  1351,     4,\n",
      "           152,  1388, 50264,     5,  8603, 13802,    18, 20510,  1036,     6,\n",
      "         14658,  6466,  1694,     6,    54,    56,    57,  1682, 50264, 50264,\n",
      "          2237,     6,    16, 50264,     7,     5,   812,   343,     9, 10714,\n",
      "           571, 21645,    11,   645,     7,  1455,  1283, 31630,  1295,     5,\n",
      "         50264,  3878,     8, 13595,     5,   588, 40048,     6,     5,  7155,\n",
      "           811,  1292,    14,    56,  1238, 12255, 50264,  6213, 12231,     4,\n",
      "         50118, 50264,     0, 50264, 50264, 47408, 50118, 50264, 50264, 50264,\n",
      "         18089, 45994, 50118,     2,     0,  1596, 38996, 50264,    58,  2622,\n",
      "             6,   511, 50264,     9,     5,   177,    18,  1049,  2182, 37813,\n",
      "          5902,  3245,     8,   248, 50264,   102,     4,   252,    58,  2211,\n",
      "           267, 38183,   117,   468, 44068,  6374,   155,    35,  8603,   139,\n",
      "           295,  7387,   732,   967,  1439, 50264,   289,  1113,    36, 49902,\n",
      "         42393, 21402, 20024, 48018, 50033, 49080, 49587, 49432, 48947, 49017,\n",
      "         50264, 47111, 16948,  8384, 48885, 48247, 49045, 48537,  9085, 47780,\n",
      "         48018, 36484, 50264,     6, 50264,     4,   468, 44068,  6374, 50264,\n",
      "             5, 36954,   155,    35,    20, 27381,     9, 50264,  8603, 13802,\n",
      "         41080,   238, 50264,    30, 50264,  2160, 16819, 20483,   354,  6498,\n",
      "             8, 50264,   703,    11, 50264,  7267, 50264, 50264, 50264,  1538,\n",
      "         50264, 50264, 20526, 50264,  3066,  2678,   227,  1466,     8,  1125,\n",
      "           131,     8,  2211,   267, 38183,   117, 50264, 44068,  6374,   155,\n",
      "            35,   111, 50264,  7387,  1890,  1794,   118,   117, 20270, 13253,\n",
      "         10233, 50264,    12,    36, 49902, 42393, 21402, 20024, 48018, 50033,\n",
      "         49080, 49587, 50264, 48947, 49017, 50264,   111, 36484,  8906, 10470,\n",
      "         49045, 48583, 50264, 49126, 10809, 50264, 49902, 48732,    27, 49583,\n",
      "         50264,  6474,     4,   468, 44068,  6374,     9,     5, 36954,   155,\n",
      "           111,   133, 50264,     9,     5, 50264, 50264,   238, 22827,    30,\n",
      "         14688, 16819,  7303, 50264,     8,  2140,   703,    11,    10,   881,\n",
      "          3149, 50264, 10912,  1638,  6498, 20796,   225, 50264,  1125,     4,\n",
      "         50118,     2,     0, 45994,  8911, 45994, 50118, 50264,     0,   111,\n",
      "         10567,   256,  2482,  5982, 20681,     6,   644,  1105,     6, 44023,\n",
      "         50118,     2,     0,    20,  4046,  2751,  4152,    21,  8967,    11,\n",
      "         39947,    25,    41, 50264,  2726,   225,   337,     9,  8068,    60,\n",
      "         50264,    14,    24,    21]])\n"
     ]
    }
   ],
   "source": [
    "# input = torch.tensor([[    0,   287,     5,  8603, 13802, 50264,   109,    45,  5152,\n",
    "#            6,     5,  2853,   364, 22448,  1790,     9,     5,  7155,\n",
    "#          811,  2938, 14958,     5,  4286, 50264, 27099,  3069, 34337,\n",
    "#           11,   645,     7,  2142,   106,    15, 10779,    14,    74,\n",
    "#         3680,   146,  7155,   493,  2217, 50264,    11,     5,   997,\n",
    "#            4,   616,    23,   498, 50264,  1364,     7, 50264,  2093,\n",
    "#            6,   215,    25,    10, 50264,  5853, 29471, 50264, 50264,\n",
    "#         4284,     6,    97,  3365,  1303,  1402,   453, 50264,     5,\n",
    "#        41977,  1187,   372, 13250,     4,   509,   215,   919,     6,\n",
    "#        50264,  7150,     6,  3374,    98, 33415,    14,    37,  4091,\n",
    "#        50264,  1790,    39, 50264, 50264, 23487,    88,     5,  5546,\n",
    "#            9,  2912,   424,  1571, 50264,     6,  7391,     7,     5,\n",
    "#         5631,     9,   211,  9636,  7305, 50264,  1850, 50264,    49,\n",
    "#          884,     6, 25000,  1180,     4,   497,     5,   276,    86,\n",
    "#            6,  4785,   624,  7155,   811,  2938,  9539,   517,     7,\n",
    "#        24300,     5,  8603, 13802,    11,   645,     7,  1744, 50264,\n",
    "#          308,  3168,     4,   289,  9968,    30,   258,  4181,     8,\n",
    "#        11058,     6,     8, 50264, 50264,     5,  2621,     9,    10,\n",
    "#        40048,   624,    49,  5546, 50264, 50264, 41977,  1187, 12420,\n",
    "#          517,     7,   489,  1235,  4299,   150,    23,     5,   276,\n",
    "#           86,  1032,     7, 50264,     5,  7155,   811,   997,  1351,\n",
    "#            4,   152,  1388, 50264,     5,  8603, 13802,    18, 20510,\n",
    "#         1036,     6, 14658,  6466,  1694,     6,    54,    56,    57,\n",
    "#         1682, 50264, 50264,  2237,     6,    16, 50264,     7,     5,\n",
    "#          812,   343,     9, 10714,   571, 21645,    11,   645,     7,\n",
    "#         1455,  1283, 31630,  1295,     5, 50264,  3878,     8, 13595,\n",
    "#            5,   588, 40048,     6,     5,  7155,   811,  1292,    14,\n",
    "#           56,  1238, 12255, 50264,  6213, 12231,     4, 50118, 50264,\n",
    "#            0, 50264, 50264, 47408, 50118, 50264, 50264, 50264, 18089,\n",
    "#        45994, 50118,     2,     0,  1596, 38996, 50264,    58,  2622,\n",
    "#            6,   511, 50264,     9,     5,   177,    18,  1049,  2182,\n",
    "#        37813,  5902,  3245,     8,   248, 50264,   102,     4,   252,\n",
    "#           58,  2211,   267, 38183,   117,   468, 44068,  6374,   155,\n",
    "#           35,  8603,   139,   295,  7387,   732,   967,  1439, 50264,\n",
    "#          289,  1113,    36, 49902, 42393, 21402, 20024, 48018, 50033,\n",
    "#        49080, 49587, 49432, 48947, 49017, 50264, 47111, 16948,  8384,\n",
    "#        48885, 48247, 49045, 48537,  9085, 47780, 48018, 36484, 50264,\n",
    "#            6, 50264,     4,   468, 44068,  6374, 50264,     5, 36954,\n",
    "#          155,    35,    20, 27381,     9, 50264,  8603, 13802, 41080,\n",
    "#          238, 50264,    30, 50264,  2160, 16819, 20483,   354,  6498,\n",
    "#            8, 50264,   703,    11, 50264,  7267, 50264, 50264, 50264,\n",
    "#         1538, 50264, 50264, 20526, 50264,  3066,  2678,   227,  1466,\n",
    "#            8,  1125,   131,     8,  2211,   267, 38183,   117, 50264,\n",
    "#        44068,  6374,   155,    35,   111, 50264,  7387,  1890,  1794,\n",
    "#          118,   117, 20270, 13253, 10233, 50264,    12,    36, 49902,\n",
    "#        42393, 21402, 20024, 48018, 50033, 49080, 49587, 50264, 48947,\n",
    "#        49017, 50264,   111, 36484,  8906, 10470, 49045, 48583, 50264,\n",
    "#        49126, 10809, 50264, 49902, 48732,    27, 49583, 50264,  6474,\n",
    "#            4,   468, 44068,  6374,     9,     5, 36954,   155,   111,\n",
    "#          133, 50264,     9,     5, 50264, 50264,   238, 22827,    30,\n",
    "#        14688, 16819,  7303, 50264,     8,  2140,   703,    11,    10,\n",
    "#          881,  3149, 50264, 10912,  1638,  6498, 20796,   225, 50264,\n",
    "#         1125,     4, 50118,     2,     0, 45994,  8911, 45994, 50118,\n",
    "#        50264,     0,   111, 10567,   256,  2482,  5982, 20681,     6,\n",
    "#          644,  1105,     6, 44023, 50118,     2,     0,    20,  4046,\n",
    "#         2751,  4152,    21,  8967,    11, 39947,    25,    41, 50264,\n",
    "#         2726,   225,   337,     9,  8068,    60, 50264,    14,    24,\n",
    "#           21]])\n",
    "# print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_dicts(my_dict, hf_dict):\n",
    "#     print(my_dict.keys())\n",
    "#     print(hf_dict.keys())\n",
    "\n",
    "#     my_keys = set(my_dict)\n",
    "#     hf_keys = set(hf_dict)\n",
    "\n",
    "#     both = hf_keys.union(my_keys)\n",
    "\n",
    "#     correct_msg = \"Accuracy: 1.0000, Avg Difference: 0.000000\"\n",
    "\n",
    "#     for k in both:\n",
    "#         if k not in my_keys:\n",
    "#             print(f\"Key {k} not in my_keys!\")\n",
    "#             continue\n",
    "\n",
    "#         if k not in hf_keys:\n",
    "#             print(f\"Key {k} not in hf_keys!\")\n",
    "#             continue\n",
    "        \n",
    "#         check_str = check(my_dict[k], hf_dict[k])\n",
    "#         if check_str != correct_msg:\n",
    "#             print(check_str)\n",
    "\n",
    "# my_dict = lv_model.to_state_dict()\n",
    "# hf_dict = hf_model.state_dict()\n",
    "\n",
    "# my_dict = {k: np.array(my_dict[k]) for k in my_dict.keys()}\n",
    "# hf_dict = {k: np.array(hf_dict[k]) for k in hf_dict.keys()}\n",
    "\n",
    "# check_dicts(my_dict, hf_dict)\n",
    "\n",
    "# print(check(my_dict[\"lm_head.decoder.bias\"], hf_dict[\"lm_head.decoder.bias\"]))\n",
    "# print(check(my_dict[\"lm_head.decoder.bias\"], hf_dict[\"lm_head.bias\"]))\n",
    "# print(check(hf_dict[\"lm_head.decoder.bias\"], hf_dict[\"lm_head.bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(hf_config.bos_token_id)\n",
    "print(hf_config.pad_token_id)\n",
    "print(hf_config.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embeddings = hf_dict[\"roberta.embeddings.word_embeddings.weight\"]\n",
    "# input_ids = lv_prompt[\"input_ids\"]\n",
    "# input_ids_np = np.array(lv_prompt[\"input_ids\"].array)\n",
    "\n",
    "# input_embeds_np = word_embeddings[input_ids_np]\n",
    "# input_embeds_hax = hax.NamedArray(input_embeds_np, axes=(Batch, Pos, lv_config.Embed))\n",
    "\n",
    "# cond = (input_ids == lv_config.pad_token_id)\n",
    "# cond = hax.broadcast_to(cond, input_embeds_hax.axes)\n",
    "\n",
    "# input_embeds_hax = hax.where(\n",
    "#     cond,\n",
    "#     hax.zeros_like(input_embeds_hax),\n",
    "#     input_embeds_hax\n",
    "# )\n",
    "\n",
    "# input_embeds_torch = torch.from_numpy(np.array(input_embeds_hax.array))\n",
    "# new_lv_prompt = dict()\n",
    "# new_hf_prompt = dict()\n",
    "\n",
    "# new_lv_prompt[\"input_embeds\"] = input_embeds_hax\n",
    "# new_hf_prompt[\"inputs_embeds\"] = input_embeds_torch\n",
    "\n",
    "# new_lv_prompt[\"attention_mask\"] = lv_prompt[\"attention_mask\"]\n",
    "# new_hf_prompt[\"attention_mask\"] = prompt[\"attention_mask\"]\n",
    "\n",
    "# new_lv_prompt[\"position_ids\"] = lv_prompt[\"position_ids\"]\n",
    "# new_hf_prompt[\"position_ids\"] = prompt[\"position_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = hax.Axis(\"batch\", 1)\n",
    "# heads = hax.Axis(\"heads\", 12)\n",
    "# position = hax.Axis(\"position\", 514)\n",
    "# key_position = hax.Axis(\"key_position\", 514)\n",
    "\n",
    "# attention_scores = hax.ones({batch: batch.size, heads: heads.size, position: position.size, key_position: key_position.size})\n",
    "\n",
    "# attention_mask = lv_prompt[\"attention_mask\"]\n",
    "\n",
    "# attention_mask = (attention_mask == 0) * -1e12\n",
    "\n",
    "# attention_mask = attention_mask.rename({\"position\": \"key_position\"})\n",
    "# # print(attention_mask)\n",
    "# print(attention_mask.axes)\n",
    "\n",
    "# attention = attention_scores + attention_mask\n",
    "\n",
    "# print(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_result = lv_model(**lv_prompt)\n",
    "hf_result = hf_model(**prompt)\n",
    "\n",
    "# lv_result = lv_model(**new_lv_prompt)\n",
    "# hf_result = hf_model(**new_hf_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_result_logits = torch.from_numpy(np.array(lv_result.array))\n",
    "hf_result_logits = hf_result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lv_logits vs hf_logits: Accuracy: 1.0000, Avg Difference: 0.000005\n",
      "lv_tokens vs hf_tokens: Accuracy: 1.0000, Avg Difference: 0.000000\n",
      "Accuracy: 0.0117, Avg Difference: 158.542802\n",
      "Accuracy: 0.0117, Avg Difference: 158.542802\n"
     ]
    }
   ],
   "source": [
    "print(f\"lv_logits vs hf_logits: {check(np.array(lv_result_logits), np.array(hf_result_logits.detach()))}\")\n",
    "print(f\"lv_tokens vs hf_tokens: {check(np.array(lv_result_logits.argmax(dim=-1)), np.array(hf_result_logits.argmax(dim=-1).detach()))}\")\n",
    "print(check(np.array(lv_result_logits.argmax(dim=-1)), np.array(prompt[\"input_ids\"])))\n",
    "print(check(np.array(hf_result_logits.argmax(dim=-1).detach()), np.array(prompt[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from levanter.models.lm_model import MaskedLmExample\n",
    "\n",
    "# example = MaskedLmExample.masked_lm(tokens=lv_result.argmax(\"vocab\")[{\"batch\": 0}], targets=lv_prompt[\"input_ids\"][{\"batch\": 0}], mask_token_id=tokenizer.mask_token_id, attn_mask=lv_prompt[\"attention_mask\"][{\"batch\": 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedArray(array=Array(15.134689, dtype=float32), axes=())"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from levanter.models.lm_model import MaskedLmExample\n",
    "\n",
    "mask_prob = 0.15\n",
    "mask_token_id = tokenizer.mask_token_id\n",
    "noise_prob = 0.1\n",
    "\n",
    "QPos = Pos\n",
    "KPos = KeyPos\n",
    "\n",
    "def _create_mlm_example(tokens, key):\n",
    "    tokens_array = tokens.array\n",
    "    targets = tokens_array.copy()\n",
    "\n",
    "    if mask_prob > 0:\n",
    "        this_key, key = jax.random.split(key)\n",
    "        mask_shape = tokens_array.shape\n",
    "        mask = jax.random.bernoulli(this_key, mask_prob, mask_shape)\n",
    "\n",
    "        rand = jax.random.uniform(this_key, mask_shape)\n",
    "        mask_token = jnp.where(rand < 0.8, mask_token_id, tokens_array)\n",
    "        random_tokens = jax.random.randint(this_key, mask_shape, 0, tokens_array.max() + 1)\n",
    "        mask_token = jnp.where((rand >= 0.8) & (rand < 0.8 + noise_prob), random_tokens, mask_token)\n",
    "        masked_tokens = jnp.where(mask, mask_token, tokens_array)\n",
    "\n",
    "        # Set targets to the original tokens where mask is True, otherwise set to mask_token_id\n",
    "        targets = jnp.where(mask, tokens_array, mask_token_id)\n",
    "\n",
    "        masked_tokens_named = hax.named(masked_tokens, QPos)\n",
    "        targets_named = hax.named(targets, QPos)\n",
    "\n",
    "        attn_mask_shape = (tokens_array.shape[0], tokens_array.shape[0])\n",
    "        attn_mask = hax.named(jnp.ones(attn_mask_shape, dtype=jnp.bool_), (QPos, KPos))\n",
    "\n",
    "        example = MaskedLmExample.masked_lm(tokens=masked_tokens_named, targets=targets_named, mask_token_id=mask_token_id, attn_mask=attn_mask)\n",
    "    else:\n",
    "        targets_named = hax.named(targets, QPos)\n",
    "        attn_mask_shape = (tokens_array.shape[0], tokens_array.shape[0])\n",
    "        attn_mask = hax.named(jnp.ones(attn_mask_shape, dtype=jnp.bool_), (QPos, KPos))\n",
    "\n",
    "        example = MaskedLmExample.masked_lm(tokens=tokens, targets=targets_named, mask_token_id=mask_token_id, attn_mask=attn_mask)\n",
    "\n",
    "    return example\n",
    "\n",
    "example = _create_mlm_example(lv_prompt[\"input_ids\"][{\"batch\": 0}], key_model)\n",
    "lv_model.compute_loss(example, key=key_model, reduction=hax.mean, reduction_axis=Pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check(named_to_tensor(example.tokens * 1.), named_to_tensor(lv_prompt[\"input_ids\"]* 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(named_to_tensor(example.tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from haliax.nn import cross_entropy_loss\n",
    "# import torch.types\n",
    "\n",
    "# lv_logits = lv_model(example.tokens, example.attn_mask, position_ids=lv_prompt[\"position_ids\"], key=key)\n",
    "# lv_logits = lv_logits.astype(jnp.float32)\n",
    "\n",
    "# hf_logits = hf_model(**{\"input_ids\" : named_to_tensor(example.tokens)[None, :], \"attention_mask\" : named_to_tensor(example.attn_mask)[None, :], \"position_ids\" : prompt[\"position_ids\"]}).logits\n",
    "# hf_logits = tensor_to_named(hf_logits.detach().numpy(), (Batch, Pos, Vocab))\n",
    "\n",
    "# targets = example.targets\n",
    "# target_y = hax.nn.one_hot(targets, Vocab, dtype=lv_logits.dtype)\n",
    "\n",
    "# # jnp.dtype(\"long\")\n",
    "\n",
    "# lv_on_lv_loss = cross_entropy_loss(\n",
    "#     lv_logits, Vocab, target_y, hax.mean, reduction_axis=Pos, where=example.loss_mask\n",
    "# )\n",
    "\n",
    "# hf_on_lv_loss = cross_entropy_loss(\n",
    "#     hf_logits, Vocab, target_y, hax.mean, reduction_axis=Pos, where=example.loss_mask\n",
    "# )\n",
    "\n",
    "# # lv_loss = cross_entropy_loss(\n",
    "# #     logits, Vocab, target_y, hax.mean, reduction_axis=Pos\n",
    "# # )\n",
    "# # target_y_torch = named_to_tensor(target_y)\n",
    "\n",
    "# targets_torch = named_to_tensor(example.targets)\n",
    "# # targets_torch = named_to_tensor(example.targets.astype(jnp.dtype(\"longlong\")))\n",
    "\n",
    "# targets_torch = targets_torch * named_to_tensor(example.loss_mask)\n",
    "# targets_torch[targets_torch == 0] = -100\n",
    "# targets_torch = torch.tensor(targets_torch, dtype=torch.long)\n",
    "\n",
    "# lv_on_torch_loss = torch.nn.functional.cross_entropy(named_to_tensor(lv_logits)[0], targets_torch)\n",
    "# hf_on_torch_loss = torch.nn.functional.cross_entropy(named_to_tensor(hf_logits)[0], targets_torch)\n",
    "\n",
    "# print(lv_on_lv_loss)\n",
    "# print(hf_on_lv_loss)\n",
    "# print(lv_on_torch_loss)\n",
    "# print(hf_on_torch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0, 1409,    5, 3497,    9, 1470,    4,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv_result_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_fn = ['</s>Markham is the city of California, located in San Diego, California</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']\n",
    "\n",
    "no_ids = ['</s>Markham is the city of California, located in San Diego, California</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']\n",
    "\n",
    "arange = [\"</s>Mark</s> is the CEO of Facebook, located in San Angeles, California</s></s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s> cast</s></s></s></s></s></s></s></s> cast cast cast cast</s></s></s></s></s></s></s></s> cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast</s> cast cast cast</s></s></s></s></s></s> cast cast cast cast</s></s></s></s></s></s></s></s> cast</s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s> cast cast</s></s></s> cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast</s></s></s></s></s></s> chance cast cast cast cast cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast cast cast cast cast</s></s></s></s></s></s></s></s> cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s> cast cast cast cast cast cast cast</s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s></s></s></s></s> chance cast cast cast cast cast cast cast cast chance cast cast cast cast cast cast</s> cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast chance chance cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s></s></s></s></s> cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast cast</s></s></s></s></s></s></s></s></s> cast chance chance cast cast cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> chance cast</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> cast cast cast cast cast cast cast cast chance chance</s>\"]\n",
    "\n",
    "arange_no_offset = \"nan\"\n",
    "\n",
    "old_fn_no_offset = ['<s><s>You are the age of America, located in the States, California</s></s> Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim Crim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_fn_hf = ['<s>Mark Zuckerberg is the CEO of Facebook, located in San Alto, California.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']\n",
    "\n",
    "no_ids_hf = ['<s>Mark Zuckerberg is the CEO of Facebook, located in San Alto, California.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']\n",
    "\n",
    "arange_hf = ['<s></s><s>is the CEO of Facebook, located in San Francisco, California.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>. Facebook.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']\n",
    "\n",
    "arange_no_offset = \"error\"\n",
    "\n",
    "old_fn_no_offset_hf = ['<s><s>Facebook is the CEO of Facebook, located in San Francisco, California.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 514, 50265])\n",
      "torch.Size([1, 514, 50265])\n"
     ]
    }
   ],
   "source": [
    "print(lv_result_logits.shape)\n",
    "print(hf_result_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>Paris is the<mask> of France.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(lv_prompt[\"input_ids\"].array, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>Paris is the<mask> of France.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(prompt[\"input_ids\"], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s><s>by the Republic of France.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(lv_result_logits.argmax(dim=-1), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s><s>by the Republic of France.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(hf_result_logits.argmax(dim=-1), skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# unmasker = pipeline('fill-mask', model='roberta-base')\n",
    "# unmasker(\"The man worked as a <mask>.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[33.8544, -4.0704, 21.6643,  ...,  1.8860,  4.2439, 11.9759],\n",
       "         [33.8159, -4.0739, 21.6653,  ...,  1.8778,  4.2321, 11.9650],\n",
       "         [ 3.1134, -4.0773,  9.1893,  ..., -5.3634, -5.5656,  2.3893],\n",
       "         ...,\n",
       "         [12.4162, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713],\n",
       "         [12.4162, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713],\n",
       "         [12.4162, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv_result_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[33.8543, -4.0704, 21.6644,  ...,  1.8860,  4.2438, 11.9759],\n",
       "         [33.8159, -4.0739, 21.6653,  ...,  1.8778,  4.2321, 11.9650],\n",
       "         [ 3.1134, -4.0773,  9.1893,  ..., -5.3634, -5.5656,  2.3893],\n",
       "         ...,\n",
       "         [12.4163, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713],\n",
       "         [12.4163, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713],\n",
       "         [12.4163, -4.4055, 29.7767,  ..., -1.2404, -4.1871,  8.8713]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NamedArray(array=Array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), axes=(Axis(name='batch', size=1), Axis(name='position', size=514)))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0, 1409,    5, 3497,    9, 1470,    4,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv_result_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0, 1409,    5, 3497,    9, 1470,    4,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "            2,    2,    2,    2,    2,    2,    2,    2,    2,    2]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 32826,    16,     5, 50264,     9,  1470,     4,     2,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(prompt[\"input_ids\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "levanter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
